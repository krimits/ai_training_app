import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import make_classification, make_blobs
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix
import seaborn as sns
import time

st.set_page_config(layout='wide', page_title='AI Training â€” Î Î»Î®ÏÎ·Ï‚ Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·', page_icon='ğŸ¤–')

# Helper function Î³Î¹Î± Î´Î¹Î±Î´ÏÎ±ÏƒÏ„Î¹ÎºÎ¬ concept explanations
def concept_explainer(term, definition, details="", examples=""):
    """Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ Î­Î½Î± Î´Î¹Î±Î´ÏÎ±ÏƒÏ„Î¹ÎºÏŒ expander Î³Î¹Î± ÎµÎ¾Î®Î³Î·ÏƒÎ· ÏŒÏÏ‰Î½"""
    with st.expander(f"â„¹ï¸ **{term}** - ÎšÎ¬Î½Ï„Îµ ÎºÎ»Î¹Îº Î³Î¹Î± Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎ±"):
        st.markdown(f"**ğŸ“– ÎŸÏÎ¹ÏƒÎ¼ÏŒÏ‚:**\n{definition}")
        if details:
            st.markdown(f"\n**ğŸ” Î›ÎµÏ€Ï„Î¿Î¼Î­ÏÎµÎ¹ÎµÏ‚:**\n{details}")
        if examples:
            st.markdown(f"\n**ğŸ’¡ Î Î±ÏÎ±Î´ÎµÎ¯Î³Î¼Î±Ï„Î±:**\n{examples}")

# Helper function Î³Î¹Î± Google Colab links
def colab_button(notebook_name, colab_url, description=""):
    """Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ ÎºÎ¿Ï…Î¼Ï€Î¯ Î³Î¹Î± Î¬Î½Î¿Î¹Î³Î¼Î± Google Colab notebook"""
    col1, col2 = st.columns([3, 1])
    with col1:
        st.markdown(f"**ğŸ““ {notebook_name}**")
        if description:
            st.caption(description)
    with col2:
        st.markdown(f"""
        <a href="{colab_url}" target="_blank">
            <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
        </a>
        """, unsafe_allow_html=True)

def section_title(t): 
    st.markdown(f'## ğŸ“Œ {t}')

def subsection_title(t):
    st.markdown(f'### {t}')

def show_quiz(q):
    st.write('**Î•ÏÏÏ„Î·ÏƒÎ·:**', q['question'])
    if q['type'] == 'mcq':
        choice = st.radio('Î•Ï€Î¹Î»Î¿Î³Î­Ï‚:', q['options'], key=q['id'], label_visibility='visible')
        if st.button('Î¥Ï€Î¿Î²Î¿Î»Î® Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·Ï‚', key=q['id']+'_btn'):
            if choice == q['answer']:
                st.success('âœ… Î£Ï‰ÏƒÏ„ÏŒ! ' + q.get('explain',''))
                st.balloons()
            else:
                st.error('âŒ Î›Î¬Î¸Î¿Ï‚. ' + q.get('explain',''))
    elif q['type'] == 'tf':
        choice = st.radio('Î•Ï€Î¹Î»Î­Î¾Ï„Îµ:', ['Î£Ï‰ÏƒÏ„ÏŒ','Î›Î¬Î¸Î¿Ï‚'], key=q['id'], label_visibility='visible')
        if st.button('Î¥Ï€Î¿Î²Î¿Î»Î®', key=q['id']+'_btn'):
            ans = 'Î£Ï‰ÏƒÏ„ÏŒ' if q['answer']==True else 'Î›Î¬Î¸Î¿Ï‚'
            if choice==ans:
                st.success('âœ… Î£Ï‰ÏƒÏ„ÏŒ! ' + q.get('explain',''))
                st.balloons()
            else:
                st.error('âŒ Î›Î¬Î¸Î¿Ï‚. ' + q.get('explain',''))

st.title('ğŸ¤– AI Training â€” Î Î»Î®ÏÎ·Ï‚ Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· ÏƒÏ„Î·Î½ Î¤ÎµÏ‡Î½Î·Ï„Î® ÎÎ¿Î·Î¼Î¿ÏƒÏÎ½Î·')
st.markdown('### Î•Ï†Î±ÏÎ¼Î¿Î³Î­Ï‚ Î¤ÎµÏ‡Î½Î·Ï„Î®Ï‚ ÎÎ¿Î·Î¼Î¿ÏƒÏÎ½Î·Ï‚ ÎºÎ±Î¹ ChatGPT ÏƒÎµ ÎšÏÎ¯ÏƒÎ¹Î¼Î¿Ï…Ï‚ Î¤Î¿Î¼ÎµÎ¯Ï‚')
st.markdown('---')

tabs = st.tabs(['ğŸ“š Î ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿','ğŸ Î Î±ÏÎ±Î´ÎµÎ¯Î³Î¼Î±Ï„Î± Python','ğŸ”¬ Î•Î¾Î¿Î¼Î¿Î¹ÏÏƒÎµÎ¹Ï‚ AI','âœ… ÎšÎ¿Ï…Î¯Î¶','ğŸ’¡ Î”Î¹Î±Î´ÏÎ±ÏƒÏ„Î¹ÎºÎ­Ï‚ Î‘ÏƒÎºÎ®ÏƒÎµÎ¹Ï‚','ğŸ¤– AI Chatbot','ğŸ“– Î ÏŒÏÎ¿Î¹'])

with tabs[0]:
    section_title('1.1 Î•Î¹ÏƒÎ±Î³Ï‰Î³Î® â€” Î¤Î¹ ÎµÎ¯Î½Î±Î¹ Î· Î¤ÎµÏ‡Î½Î·Ï„Î® ÎÎ¿Î·Î¼Î¿ÏƒÏÎ½Î·')
    
    col1, col2 = st.columns([2, 1])
    with col1:
        st.markdown("""
        #### ÎŸÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÎºÎ±Î¹ Î“ÎµÎ½Î¹ÎºÎ¬
        Î— **Î¤ÎµÏ‡Î½Î·Ï„Î® ÎÎ¿Î·Î¼Î¿ÏƒÏÎ½Î· (Artificial Intelligence - AI)** ÎµÎ¯Î½Î±Î¹ Î¿ ÎºÎ»Î¬Î´Î¿Ï‚ Ï„Î·Ï‚ ÎµÏ€Î¹ÏƒÏ„Î®Î¼Î·Ï‚ Ï„Ï‰Î½ Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÏ„ÏÎ½ 
        Ï€Î¿Ï… Î±ÏƒÏ‡Î¿Î»ÎµÎ¯Ï„Î±Î¹ Î¼Îµ Ï„Î· Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÏƒÏ…ÏƒÏ„Î·Î¼Î¬Ï„Ï‰Î½ Î¹ÎºÎ±Î½ÏÎ½ Î½Î± ÎµÎºÏ„ÎµÎ»Î¿ÏÎ½ ÎµÏÎ³Î±ÏƒÎ¯ÎµÏ‚ Ï€Î¿Ï… Ï€Î±ÏÎ±Î´Î¿ÏƒÎ¹Î±ÎºÎ¬ Î±Ï€Î±Î¹Ï„Î¿ÏÎ½ 
        Î±Î½Î¸ÏÏÏ€Î¹Î½Î· Î½Î¿Î·Î¼Î¿ÏƒÏÎ½Î·.
        
        **Î’Î±ÏƒÎ¹ÎºÎ­Ï‚ ÎšÎ±Ï„Î·Î³Î¿ÏÎ¯ÎµÏ‚:**
        """)
        
    with col2:
        st.info("""
        **ğŸ’¡ Î“Î½Ï‰ÏÎ¯Î¶Î±Ï„Îµ ÏŒÏ„Î¹:**
        
        Î— AI Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯Ï„Î±Î¹ ÏƒÎµ:
        - Smartphones (Siri, Alexa)
        - Î‘Ï…Ï„ÏŒÎ½Î¿Î¼Î± Î¿Ï‡Î®Î¼Î±Ï„Î±
        - Î™Î±Ï„ÏÎ¹ÎºÎ­Ï‚ Î´Î¹Î±Î³Î½ÏÏƒÎµÎ¹Ï‚
        - ÎŸÎ¹ÎºÎ¿Î½Î¿Î¼Î¹ÎºÎ­Ï‚ Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚
        - Î•Î¾Ï…Ï€Î·ÏÎ­Ï„Î·ÏƒÎ· Ï€ÎµÎ»Î±Ï„ÏÎ½
        """)
    
    # Expandable sections for each AI category
    with st.expander('ğŸ§  **Machine Learning (ML)** - ÎœÎ·Ï‡Î±Î½Î­Ï‚ Ï€Î¿Ï… Î¼Î±Î¸Î±Î¯Î½Î¿Ï…Î½ Î±Ï€ÏŒ Î´ÎµÎ´Î¿Î¼Î­Î½Î±', expanded=False):
        st.markdown("""
        ### Î¤Î¹ ÎµÎ¯Î½Î±Î¹ Ï„Î¿ Machine Learning;
        
        Î¤Î¿ **Machine Learning** ÎµÎ¯Î½Î±Î¹ Î­Î½Î±Ï‚ ÎºÎ»Î¬Î´Î¿Ï‚ Ï„Î·Ï‚ AI Ï€Î¿Ï… ÎµÏ€Î¹Ï„ÏÎ­Ï€ÎµÎ¹ ÏƒÏ„Î¿Ï…Ï‚ Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÏ„Î­Ï‚ Î½Î± Î¼Î±Î¸Î±Î¯Î½Î¿Ï…Î½ Î±Ï€ÏŒ Î´ÎµÎ´Î¿Î¼Î­Î½Î± 
        Ï‡Ï‰ÏÎ¯Ï‚ Î½Î± Ï€ÏÎ¿Î³ÏÎ±Î¼Î¼Î±Ï„Î¯Î¶Î¿Î½Ï„Î±Î¹ ÏÎ·Ï„Î¬ Î³Î¹Î± ÎºÎ¬Î¸Îµ ÎµÏÎ³Î±ÏƒÎ¯Î±.
        
        ---
        """)
        
        st.markdown("#### ğŸ“š Î¤ÏÏ€Î¿Î¹ ÎœÎ¬Î¸Î·ÏƒÎ·Ï‚")
        st.markdown("*ÎšÎ¬Î½Ï„Îµ ÎºÎ»Î¹Îº ÏƒÎµ ÎºÎ¬Î¸Îµ Ï„ÏÏ€Î¿ Î³Î¹Î± Î±Î½Î±Î»Ï…Ï„Î¹ÎºÎ® ÎµÎ¾Î®Î³Î·ÏƒÎ·:*")
        
        # SUPERVISED LEARNING
        concept_explainer(
            "ğŸ¯ Supervised Learning (Î•Ï€Î¹Î²Î»ÎµÏ€ÏŒÎ¼ÎµÎ½Î· ÎœÎ¬Î¸Î·ÏƒÎ·)",
            """
            Î— **Supervised Learning** ÎµÎ¯Î½Î±Î¹ Î· Ï€Î¹Î¿ ÏƒÏ…Î½Î·Î¸Î¹ÏƒÎ¼Î­Î½Î· ÎºÎ±Ï„Î·Î³Î¿ÏÎ¯Î± ML ÏŒÏ€Î¿Ï… Ï„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ Î¼Î±Î¸Î±Î¯Î½ÎµÎ¹ Î±Ï€ÏŒ 
            **labeled data** (Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î¼Îµ ÎµÏ„Î¹ÎºÎ­Ï„ÎµÏ‚). ÎšÎ¬Î¸Îµ Ï€Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î± ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·Ï‚ Î­Ï‡ÎµÎ¹ input features ÎºÎ±Î¹ 
            Ï„Î¿ Î±Î½Ï„Î¯ÏƒÏ„Î¿Î¹Ï‡Î¿ output (label/target).
            """,
            """
            ### ğŸ“ Î ÏÏ‚ Î›ÎµÎ¹Ï„Î¿Ï…ÏÎ³ÎµÎ¯:
            
            **Î’Î®Î¼Î± 1**: Î Î±ÏÎ­Ï‡Î¿Ï…Î¼Îµ ÏƒÏ„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ Î¶ÎµÏÎ³Î· (input, output)
            ```
            Î Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î±: (Î£Ï€Î¯Ï„Î¹ 100Ï„Î¼ Î¼Îµ 3 Î´Ï‰Î¼Î¬Ï„Î¹Î±) â†’ 200,000â‚¬
            ```
            
            **Î’Î®Î¼Î± 2**: Î¤Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ Î¼Î±Î¸Î±Î¯Î½ÎµÎ¹ Ï„Î· ÏƒÏ‡Î­ÏƒÎ· input-output
            
            **Î’Î®Î¼Î± 3**: Î ÏÎ¿Î²Î»Î­Ï€ÎµÎ¹ outputs Î³Î¹Î± Î½Î­Î±, Î¬Î³Î½Ï‰ÏƒÏ„Î± inputs
            
            ---
            
            ### ğŸ“Š Î”ÏÎ¿ ÎšÏÏÎ¹Î¿Î¹ Î¤ÏÏ€Î¿Î¹:
            
            #### 1ï¸âƒ£ **Classification (Î¤Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ·)**
            - **Î£Ï„ÏŒÏ‡Î¿Ï‚**: Î ÏÏŒÎ²Î»ÎµÏˆÎ· Î´Î¹Î±ÎºÏÎ¹Ï„Î®Ï‚ ÎºÎ±Ï„Î·Î³Î¿ÏÎ¯Î±Ï‚
            - **Output**: ÎšÎ±Ï„Î·Î³Î¿ÏÎ¯Î±/Class (Ï€.Ï‡. "Î£ÎºÏÎ»Î¿Ï‚", "Î“Î¬Ï„Î±")
            - **Î Î±ÏÎ±Î´ÎµÎ¯Î³Î¼Î±Ï„Î±**:
              - Email spam detection (Spam/Not Spam)
              - Medical diagnosis (Î¥Î³Î¹Î®Ï‚/Î†ÏÏÏ‰ÏƒÏ„Î¿Ï‚)
              - Sentiment analysis (Positive/Negative/Neutral)
              - Face recognition (Î ÏÏŒÏƒÏ‰Ï€Î¿ A, B, C...)
            
            **Î‘Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Î¹ Classification:**
            - **Logistic Regression**: Î“Î¹Î± binary classification
            - **Decision Trees**: Tree-based decisions
            - **Random Forest**: Ensemble of trees
            - **Support Vector Machines (SVM)**: Finds optimal boundary
            - **Neural Networks**: Multi-layer learning
            - **Naive Bayes**: Probabilistic classifier
            - **K-Nearest Neighbors (KNN)**: Distance-based
            
            #### 2ï¸âƒ£ **Regression (Î Î±Î»Î¹Î½Î´ÏÏŒÎ¼Î·ÏƒÎ·)**
            - **Î£Ï„ÏŒÏ‡Î¿Ï‚**: Î ÏÏŒÎ²Î»ÎµÏˆÎ· ÏƒÏ…Î½ÎµÏ‡Î¿ÏÏ‚ Î±ÏÎ¹Î¸Î¼Î·Ï„Î¹ÎºÎ®Ï‚ Ï„Î¹Î¼Î®Ï‚
            - **Output**: Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ (Ï€.Ï‡. 250,000â‚¬, 25 Ï‡ÏÎ¿Î½ÏÎ½)
            - **Î Î±ÏÎ±Î´ÎµÎ¯Î³Î¼Î±Ï„Î±**:
              - House price prediction
              - Stock market forecasting
              - Temperature prediction
              - Sales forecasting
              - Age estimation from photos
            
            **Î‘Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Î¹ Regression:**
            - **Linear Regression**: Î“ÏÎ±Î¼Î¼Î¹ÎºÎ® ÏƒÏ‡Î­ÏƒÎ·
            - **Polynomial Regression**: ÎœÎ·-Î³ÏÎ±Î¼Î¼Î¹ÎºÎ® ÏƒÏ‡Î­ÏƒÎ·
            - **Ridge/Lasso Regression**: ÎœÎµ regularization
            - **Decision Tree Regression**: Tree-based
            - **Random Forest Regression**: Ensemble
            - **Support Vector Regression (SVR)**
            - **Neural Network Regression**
            
            ---
            
            ### âš™ï¸ Î’Î±ÏƒÎ¹ÎºÎ¬ Î£Ï„Î¿Î¹Ï‡ÎµÎ¯Î±:
            
            **Training Data (Î•ÎºÏ€Î±Î¹Î´ÎµÏ…Ï„Î¹ÎºÎ¬ Î”ÎµÎ´Î¿Î¼Î­Î½Î±):**
            - X (features/inputs): Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬
            - y (labels/targets): Î£Ï„ÏŒÏ‡Î¿Î¹/Î•Ï„Î¹ÎºÎ­Ï„ÎµÏ‚
            - Î Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î±: X = [Î¼Î­Î³ÎµÎ¸Î¿Ï‚, Î´Ï‰Î¼Î¬Ï„Î¹Î±, Ï„Î¿Ï€Î¿Î¸ÎµÏƒÎ¯Î±], y = [Ï„Î¹Î¼Î®]
            
            **Loss Function (Î£Ï…Î½Î¬ÏÏ„Î·ÏƒÎ· ÎšÏŒÏƒÏ„Î¿Ï…Ï‚):**
            - ÎœÎµÏ„ÏÎ¬ Ï€ÏŒÏƒÎ¿ ÎºÎ¿Î½Ï„Î¬ ÎµÎ¯Î½Î±Î¹ Î¿Î¹ Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚ ÏƒÏ„Î·Î½ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏŒÏ„Î·Ï„Î±
            - Classification: Cross-Entropy Loss
            - Regression: Mean Squared Error (MSE)
            
            **Optimization (Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ·):**
            - **Gradient Descent**: Î’ÏÎ¯ÏƒÎºÎµÎ¹ minimum Ï„Î·Ï‚ loss function
            - Î•Î½Î·Î¼ÎµÏÏÎ½ÎµÎ¹ Ï€Î±ÏÎ±Î¼Î­Ï„ÏÎ¿Ï…Ï‚ Î³Î¹Î± ÎºÎ±Î»ÏÏ„ÎµÏÎµÏ‚ Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚
            
            ---
            
            ### ğŸ“ˆ ÎœÎµÏ„ÏÎ¹ÎºÎ­Ï‚ Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·Ï‚:
            
            **Î“Î¹Î± Classification:**
            - **Accuracy**: Î Î¿ÏƒÎ¿ÏƒÏ„ÏŒ ÏƒÏ‰ÏƒÏ„ÏÎ½ Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÏ‰Î½
            - **Precision**: Î‘Ï€ÏŒ ÏŒÏƒÎ± Ï€ÏÎ¿Î²Î»Î­ÏˆÎ±Î¼Îµ Î¸ÎµÏ„Î¹ÎºÎ¬, Ï€ÏŒÏƒÎ± Î®Ï„Î±Î½ ÏƒÏ‰ÏƒÏ„Î¬
            - **Recall**: Î‘Ï€ÏŒ ÏŒÏƒÎ± ÎµÎ¯Î½Î±Î¹ Î¸ÎµÏ„Î¹ÎºÎ¬, Ï€ÏŒÏƒÎ± Î²ÏÎ®ÎºÎ±Î¼Îµ
            - **F1-Score**: Î‘ÏÎ¼Î¿Î½Î¹ÎºÏŒÏ‚ Î¼Î­ÏƒÎ¿Ï‚ Precision & Recall
            - **Confusion Matrix**: Î Î¯Î½Î±ÎºÎ±Ï‚ ÏƒÏ‰ÏƒÏ„ÏÎ½/Î»Î¬Î¸Î¿Ï‚ Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÏ‰Î½
            - **ROC-AUC**: Area Under the ROC Curve
            
            **Î“Î¹Î± Regression:**
            - **MAE** (Mean Absolute Error): ÎœÎ­ÏƒÎ¿ Î±Ï€ÏŒÎ»Ï…Ï„Î¿ Î»Î¬Î¸Î¿Ï‚
            - **MSE** (Mean Squared Error): ÎœÎ­ÏƒÎ¿ Ï„ÎµÏ„ÏÎ±Î³Ï‰Î½Î¹ÎºÏŒ Î»Î¬Î¸Î¿Ï‚
            - **RMSE** (Root MSE): Î¡Î¯Î¶Î± Ï„Î¿Ï… MSE
            - **RÂ² Score**: Î ÏŒÏƒÎ¿ ÎºÎ±Î»Î¬ ÎµÎ¾Î·Î³ÎµÎ¯Ï„Î±Î¹ Î· Î´Î¹Î±ÎºÏÎ¼Î±Î½ÏƒÎ·
            
            ---
            
            ### ğŸ’¼ Real-World Applications:
            
            **Business:**
            - Customer churn prediction
            - Lead scoring
            - Price optimization
            - Demand forecasting
            
            **Healthcare:**
            - Disease diagnosis Î±Ï€ÏŒ symptoms
            - Patient risk stratification
            - Drug response prediction
            
            **Finance:**
            - Credit scoring
            - Fraud detection
            - Stock price prediction
            - Loan default prediction
            
            **E-commerce:**
            - Product recommendations
            - Dynamic pricing
            - Inventory management
            
            ---
            
            ### âš ï¸ Î ÏÎ¿ÎºÎ»Î®ÏƒÎµÎ¹Ï‚:
            
            - **Labeled Data Requirement**: Î§ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹ Ï€Î¿Î»Î»Î¬ labeled examples (Î±ÎºÏÎ¹Î²ÏŒ!)
            - **Overfitting**: ÎœÎ±Î¸Î±Î¯Î½ÎµÎ¹ Ï„Î¿ noise Î±Î½Ï„Î¯ Î³Î¹Î± patterns
            - **Class Imbalance**: Î†Î½Î¹ÏƒÎµÏ‚ ÎºÎ±Ï„Î·Î³Î¿ÏÎ¯ÎµÏ‚ (Ï€.Ï‡. 99% ÎºÎ±Î½Î¿Î½Î¹ÎºÎ¬, 1% Î±Ï€Î¬Ï„Î·)
            - **Feature Engineering**: Î•Ï€Î¹Î»Î¿Î³Î® ÏƒÏ‰ÏƒÏ„ÏÎ½ features ÎµÎ¯Î½Î±Î¹ ÎºÏÎ¯ÏƒÎ¹Î¼Î·
            """,
            """
            **Î ÏŒÏ„Îµ Î½Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÎµÏ„Îµ:**
            - âœ… ÎˆÏ‡ÎµÏ„Îµ labeled data
            - âœ… ÎÎ­ÏÎµÏ„Îµ Ï„Î¹ Î¸Î­Î»ÎµÏ„Îµ Î½Î± Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÏ„Îµ (clear target)
            - âœ… Î˜Î­Î»ÎµÏ„Îµ interpretable results
            - âœ… ÎˆÏ‡ÎµÏ„Îµ Î±ÏÎºÎµÏ„Î¬ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î³Î¹Î± training
            
            **Î Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î± Code (Python):**
            ```python
            from sklearn.model_selection import train_test_split
            from sklearn.ensemble import RandomForestClassifier
            
            # Split data
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
            
            # Train model
            model = RandomForestClassifier(n_estimators=100)
            model.fit(X_train, y_train)
            
            # Predict
            predictions = model.predict(X_test)
            accuracy = model.score(X_test, y_test)
            ```
            """
        )
        
        # UNSUPERVISED LEARNING
        concept_explainer(
            "ğŸ” Unsupervised Learning (ÎœÎ· Î•Ï€Î¹Î²Î»ÎµÏ€ÏŒÎ¼ÎµÎ½Î· ÎœÎ¬Î¸Î·ÏƒÎ·)",
            """
            Î— **Unsupervised Learning** Î¼Î±Î¸Î±Î¯Î½ÎµÎ¹ Î±Ï€ÏŒ **unlabeled data** (Ï‡Ï‰ÏÎ¯Ï‚ ÎµÏ„Î¹ÎºÎ­Ï„ÎµÏ‚). Î¤Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ 
            Ï€ÏÎ¿ÏƒÏ€Î±Î¸ÎµÎ¯ Î½Î± Î±Î½Î±ÎºÎ±Î»ÏÏˆÎµÎ¹ ÎºÏÏ…Ï†Î¬ patterns, Î´Î¿Î¼Î­Ï‚ ÎºÎ±Î¹ ÏƒÏ‡Î­ÏƒÎµÎ¹Ï‚ ÏƒÏ„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î±Ï…Ï„ÏŒÎ½Î¿Î¼Î±.
            """,
            """
            ### ğŸ“ Î ÏÏ‚ Î›ÎµÎ¹Ï„Î¿Ï…ÏÎ³ÎµÎ¯:
            
            **Î”ÎµÎ½ Î­Ï‡Î¿Ï…Î¼Îµ labels** - ÎœÏŒÎ½Î¿ inputs!
            ```
            Î Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î±: ÎˆÏ‡Î¿Ï…Î¼Îµ 10,000 Ï†Ï‰Ï„Î¿Î³ÏÎ±Ï†Î¯ÎµÏ‚ Î±Î»Î»Î¬ Î´ÎµÎ½ Î¾Î­ÏÎ¿Ï…Î¼Îµ Ï„Î¹ Î´ÎµÎ¯Ï‡Î½Î¿Ï…Î½
            ```
            
            Î¤Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ **Î±Ï…Ï„ÏŒÎ½Î¿Î¼Î±** Î±Î½Î±ÎºÎ±Î»ÏÏ€Ï„ÎµÎ¹:
            - ÎŸÎ¼Î¬Î´ÎµÏ‚ Ï€Î±ÏÏŒÎ¼Î¿Î¹Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ (clusters)
            - ÎšÏÏ…Ï†Î­Ï‚ Î´Î¹Î±ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚
            - Anomalies (Î±ÏƒÏ…Î½Î®Î¸Î¹ÏƒÏ„Î± patterns)
            
            ---
            
            ### ğŸ“Š ÎšÏÏÎ¹Î¿Î¹ Î¤ÏÏ€Î¿Î¹:
            
            #### 1ï¸âƒ£ **Clustering (ÎŸÎ¼Î±Î´Î¿Ï€Î¿Î¯Î·ÏƒÎ·)**
            - **Î£Ï„ÏŒÏ‡Î¿Ï‚**: ÎŸÎ¼Î±Î´Î¿Ï€Î¿Î¯Î·ÏƒÎ· Ï€Î±ÏÏŒÎ¼Î¿Î¹Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
            - **Output**: Cluster assignments
            
            **Î‘Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Î¹ Clustering:**
            
            **K-Means:**
            - Î¤Î¿ Ï€Î¹Î¿ Î´Î·Î¼Î¿Ï†Î¹Î»Î­Ï‚
            - Î§Ï‰ÏÎ¯Î¶ÎµÎ¹ Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÏƒÎµ K clusters
            - Î“ÏÎ®Î³Î¿ÏÎ¿ ÎºÎ±Î¹ Î±Ï€Î¿Î´Î¿Ï„Î¹ÎºÏŒ
            - Î Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î±: ÎŸÎ¼Î±Î´Î¿Ï€Î¿Î¯Î·ÏƒÎ· Ï€ÎµÎ»Î±Ï„ÏÎ½
            
            **Hierarchical Clustering:**
            - Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ dendrogram (Î´Î­Î½Ï„ÏÎ¿)
            - Î”ÎµÎ½ Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹ Î½Î± Î¿ÏÎ¯ÏƒÎµÎ¹Ï‚ K ÎµÎº Ï„Ï‰Î½ Ï€ÏÎ¿Ï„Î­ÏÏ‰Î½
            - Î Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î±: Î¤Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ· ÎµÎ¹Î´ÏÎ½ (biology)
            
            **DBSCAN:**
            - Density-based clustering
            - Î’ÏÎ¯ÏƒÎºÎµÎ¹ clusters Î±Ï…Î¸Î±Î¯ÏÎµÏ„Î¿Ï… ÏƒÏ‡Î®Î¼Î±Ï„Î¿Ï‚
            - Î‘Î½Î¹Ï‡Î½ÎµÏÎµÎ¹ outliers
            - Î Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î±: Î“ÎµÏ‰Î³ÏÎ±Ï†Î¹ÎºÎ® Î±Î½Î¬Î»Ï…ÏƒÎ·
            
            **Gaussian Mixture Models (GMM):**
            - Probabilistic clustering
            - Soft assignments (Ï€Î¹Î¸Î±Î½ÏŒÏ„Î·Ï„ÎµÏ‚)
            
            **Î•Ï†Î±ÏÎ¼Î¿Î³Î­Ï‚ Clustering:**
            - Customer segmentation (marketing)
            - Image segmentation
            - Document clustering
            - Anomaly detection
            - Gene expression analysis
            
            #### 2ï¸âƒ£ **Dimensionality Reduction (ÎœÎµÎ¯Ï‰ÏƒÎ· Î”Î¹Î±ÏƒÏ„Î¬ÏƒÎµÏ‰Î½)**
            - **Î£Ï„ÏŒÏ‡Î¿Ï‚**: ÎœÎµÎ¯Ï‰ÏƒÎ· Î±ÏÎ¹Î¸Î¼Î¿Ï features Î´Î¹Î±Ï„Î·ÏÏÎ½Ï„Î±Ï‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯Î±
            - **Output**: ÎœÎµÎ¹Ï‰Î¼Î­Î½ÎµÏ‚ Î´Î¹Î±ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚
            
            **Î‘Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Î¹:**
            
            **PCA (Principal Component Analysis):**
            - Î’ÏÎ¯ÏƒÎºÎµÎ¹ principal components (ÎºÏÏÎ¹ÎµÏ‚ Î´Î¹ÎµÏ…Î¸ÏÎ½ÏƒÎµÎ¹Ï‚ Î´Î¹Î±ÎºÏÎ¼Î±Î½ÏƒÎ·Ï‚)
            - Linear transformation
            - Î Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î±: Î‘Ï€ÏŒ 1000 features â†’ 50 features
            
            **t-SNE (t-Distributed Stochastic Neighbor Embedding):**
            - Î“Î¹Î± visualization (2D/3D)
            - Î”Î¹Î±Ï„Î·ÏÎµÎ¯ local structure
            - Î‘ÏÎ³ÏŒ Î³Î¹Î± Î¼ÎµÎ³Î¬Î»Î± datasets
            
            **UMAP (Uniform Manifold Approximation and Projection):**
            - Î Î¹Î¿ Î³ÏÎ®Î³Î¿ÏÎ¿ Î±Ï€ÏŒ t-SNE
            - ÎšÎ±Î»ÏÏ„ÎµÏÎ¿ Î³Î¹Î± Î¼ÎµÎ³Î¬Î»Î± datasets
            
            **Autoencoders:**
            - Neural network-based
            - ÎœÎ±Î¸Î±Î¯Î½ÎµÎ¹ compressed representation
            
            **Î•Ï†Î±ÏÎ¼Î¿Î³Î­Ï‚:**
            - Feature extraction
            - Data visualization
            - Noise reduction
            - Compression
            
            #### 3ï¸âƒ£ **Association Rule Learning**
            - **Î£Ï„ÏŒÏ‡Î¿Ï‚**: Î’ÏÎµÏ‚ ÏƒÏ‡Î­ÏƒÎµÎ¹Ï‚ Î¼ÎµÏ„Î±Î¾Ï items
            - **Output**: Rules (IF...THEN)
            
            **Î‘Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Î¹:**
            - **Apriori**: Market basket analysis
            - **FP-Growth**: Faster than Apriori
            
            **Î Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î±:**
            ```
            IF (Î±Î³Î¿ÏÎ¬Î¶ÎµÎ¹ ÏˆÏ‰Î¼Î¯ AND Î±Î³Î¿ÏÎ¬Î¶ÎµÎ¹ Î²Î¿ÏÏ„Ï…ÏÎ¿) 
            THEN (Ï€Î¹Î¸Î±Î½ÏŒÎ½ Î½Î± Î±Î³Î¿ÏÎ¬ÏƒÎµÎ¹ ÎºÎ±Î¹ Î¼Î±ÏÎ¼ÎµÎ»Î¬Î´Î±)
            ```
            
            **Î•Ï†Î±ÏÎ¼Î¿Î³Î­Ï‚:**
            - Market basket analysis (e-commerce)
            - Recommendation systems
            - Web usage mining
            
            #### 4ï¸âƒ£ **Anomaly Detection (Î‘Î½Î¯Ï‡Î½ÎµÏ…ÏƒÎ· Î‘Î½Ï‰Î¼Î±Î»Î¹ÏÎ½)**
            - **Î£Ï„ÏŒÏ‡Î¿Ï‚**: Î’ÏÎµÏ‚ Î±ÏƒÏ…Î½Î®Î¸Î¹ÏƒÏ„Î±/outlier data points
            
            **Î‘Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Î¹:**
            - **Isolation Forest**
            - **One-Class SVM**
            - **Local Outlier Factor (LOF)**
            
            **Î•Ï†Î±ÏÎ¼Î¿Î³Î­Ï‚:**
            - Fraud detection
            - System health monitoring
            - Quality control
            
            ---
            
            ### ğŸ“ˆ Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·:
            
            **Clustering Metrics:**
            - **Silhouette Score**: Î ÏŒÏƒÎ¿ ÎºÎ±Î»Î¬ Ï‡Ï‰ÏÎ¯Î¶Î¿Î½Ï„Î±Î¹ Ï„Î± clusters (-1 to 1)
            - **Davies-Bouldin Index**: ÎœÎ¹ÎºÏÏŒÏ„ÎµÏÎ¿ = ÎºÎ±Î»ÏÏ„ÎµÏÎ±
            - **Calinski-Harabasz Score**: ÎœÎµÎ³Î±Î»ÏÏ„ÎµÏÎ¿ = ÎºÎ±Î»ÏÏ„ÎµÏÎ±
            - **Inertia**: Î•ÏƒÏ‰Ï„ÎµÏÎ¹ÎºÎ® Î´Î¹Î±ÏƒÏ€Î¿ÏÎ¬ clusters
            
            **Dimensionality Reduction:**
            - **Explained Variance Ratio**: Î ÏŒÏƒÎ· Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯Î± Î´Î¹Î±Ï„Î·ÏÎµÎ¯Ï„Î±Î¹
            - **Reconstruction Error**: Î ÏŒÏƒÎ¿ ÎºÎ±Î»Î¬ Î¼Ï€Î¿ÏÎ¿ÏÎ¼Îµ Î½Î± Î±Î½Î±ÎºÎ±Ï„Î±ÏƒÎºÎµÏ…Î¬ÏƒÎ¿Ï…Î¼Îµ Ï„Î± original data
            
            ---
            
            ### ğŸ’¼ Real-World Applications:
            
            **Marketing:**
            - Customer segmentation (Î¿Î¼Î±Î´Î¿Ï€Î¿Î¯Î·ÏƒÎ· Ï€ÎµÎ»Î±Ï„ÏÎ½ ÏƒÎµ segments)
            - Market basket analysis (Ï„Î¹ Î±Î³Î¿ÏÎ¬Î¶Î¿Ï…Î½ Î¼Î±Î¶Î¯)
            
            **Healthcare:**
            - Patient stratification
            - Disease subtype discovery
            - Gene expression analysis
            
            **Finance:**
            - Fraud detection (Î±Î½Ï‰Î¼Î±Î»Î¯ÎµÏ‚ ÏƒÎµ ÏƒÏ…Î½Î±Î»Î»Î±Î³Î­Ï‚)
            - Portfolio optimization
            
            **Social Media:**
            - Community detection
            - Topic modeling
            - Trend analysis
            
            **Manufacturing:**
            - Defect detection
            - Process monitoring
            
            ---
            
            ### âš ï¸ Î ÏÎ¿ÎºÎ»Î®ÏƒÎµÎ¹Ï‚:
            
            - **Evaluation is Tricky**: Î”ÏÏƒÎºÎ¿Î»Î¿ Î½Î± Î±Î¾Î¹Î¿Î»Î¿Î³Î®ÏƒÎµÎ¹Ï‚ Ï‡Ï‰ÏÎ¯Ï‚ ground truth
            - **Parameter Tuning**: (Ï€.Ï‡. Ï€ÏŒÏƒÎ± clusters Î½Î± Î´Î¹Î±Î»Î­Î¾ÎµÎ¹Ï‚;)
            - **Interpretability**: Î¤Î¹ ÏƒÎ·Î¼Î±Î¯Î½ÎµÎ¹ Ï„Î¿ ÎºÎ¬Î¸Îµ cluster;
            - **Scalability**: ÎœÎµÏÎ¹ÎºÎ¿Î¯ Î±Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Î¹ Î±ÏÎ³Î¿Î¯ Î³Î¹Î± big data
            """,
            """
            **Î ÏŒÏ„Îµ Î½Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÎµÏ„Îµ:**
            - âœ… Î”Î•Î Î­Ï‡ÎµÏ„Îµ labels (Î® ÎµÎ¯Î½Î±Î¹ Î±ÎºÏÎ¹Î²ÏŒ Î½Î± Ï„Î± Ï†Ï„Î¹Î¬Î¾ÎµÏ„Îµ)
            - âœ… Î˜Î­Î»ÎµÏ„Îµ exploratory analysis
            - âœ… Î¨Î¬Ï‡Î½ÎµÏ„Îµ hidden patterns
            - âœ… Preprocessing Î³Î¹Î± supervised learning
            
            **Î Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î± Code (K-Means):**
            ```python
            from sklearn.cluster import KMeans
            import matplotlib.pyplot as plt
            
            # Fit K-Means
            kmeans = KMeans(n_clusters=3, random_state=42)
            clusters = kmeans.fit_predict(X)
            
            # Visualize
            plt.scatter(X[:, 0], X[:, 1], c=clusters, cmap='viridis')
            plt.scatter(kmeans.cluster_centers_[:, 0], 
                       kmeans.cluster_centers_[:, 1], 
                       c='red', marker='X', s=200)
            plt.show()
            ```
            
            **Î Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î± Code (PCA):**
            ```python
            from sklearn.decomposition import PCA
            
            # Reduce from 100 features to 10
            pca = PCA(n_components=10)
            X_reduced = pca.fit_transform(X)
            
            # Check explained variance
            print(f"Explained variance: {pca.explained_variance_ratio_.sum():.2%}")
            ```
            """
        )
        
        # REINFORCEMENT LEARNING
        concept_explainer(
            "ğŸ® Reinforcement Learning (Î•Î½Î¹ÏƒÏ‡Ï…Ï„Î¹ÎºÎ® ÎœÎ¬Î¸Î·ÏƒÎ·)",
            """
            Î— **Reinforcement Learning** ÎµÎ¯Î½Î±Î¹ Î­Î½Î± Ï€Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î± Î¼Î¬Î¸Î·ÏƒÎ·Ï‚ ÏŒÏ€Î¿Ï… Î­Î½Î±Ï‚ **agent** (Ï€ÏÎ¬ÎºÏ„Î¿ÏÎ±Ï‚) 
            Î¼Î±Î¸Î±Î¯Î½ÎµÎ¹ Î½Î± Ï€Î±Î¯ÏÎ½ÎµÎ¹ Î±Ï€Î¿Ï†Î¬ÏƒÎµÎ¹Ï‚ Î±Î»Î»Î·Î»ÎµÏ€Î¹Î´ÏÏÎ½Ï„Î±Ï‚ Î¼Îµ Î­Î½Î± **environment** (Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½) Î¼Î­ÏƒÏ‰ Î´Î¿ÎºÎ¹Î¼Î®Ï‚ 
            ÎºÎ±Î¹ Î»Î¬Î¸Î¿Ï…Ï‚, Î¼Îµ ÏƒÏ„ÏŒÏ‡Î¿ Ï„Î· **Î¼ÎµÎ³Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Ï„Ï‰Î½ rewards** (Î±Î½Ï„Î±Î¼Î¿Î¹Î²ÏÎ½).
            """,
            """
            ### ğŸ“ Î ÏÏ‚ Î›ÎµÎ¹Ï„Î¿Ï…ÏÎ³ÎµÎ¯:
            
            **Î’Î±ÏƒÎ¹ÎºÎ® Î™Î´Î­Î±**: Trial and Error + Rewards
            
            ```
            Agent (Ï€.Ï‡. ÏÎ¿Î¼Ï€ÏŒÏ„) â†’ Action â†’ Environment
                                        â†“
                             State & Reward â† Environment
                                        â†“
                            Agent Î¼Î±Î¸Î±Î¯Î½ÎµÎ¹ Ï„Î¹ ÎµÎ¯Î½Î±Î¹ ÎºÎ±Î»ÏŒ/ÎºÎ±ÎºÏŒ
            ```
            
            **Î”Î¹Î±Ï†Î¿ÏÎ¬ Î±Ï€ÏŒ Supervised:**
            - Supervised: "Î‘Ï…Ï„ÏŒ ÎµÎ¯Î½Î±Î¹ Ï„Î¿ ÏƒÏ‰ÏƒÏ„ÏŒ" (explicit labels)
            - RL: "Î‘Ï…Ï„ÏŒ ÎµÎ¯Î½Î±Î¹ ÎºÎ±Î»ÏŒ/ÎºÎ±ÎºÏŒ" (rewards/penalties)
            
            ---
            
            ### ğŸ§© Î’Î±ÏƒÎ¹ÎºÎ¬ Î£Ï„Î¿Î¹Ï‡ÎµÎ¯Î±:
            
            #### 1. **Agent (Î ÏÎ¬ÎºÏ„Î¿ÏÎ±Ï‚)**
            - Î¤Î¿ "ÏŒÎ½" Ï€Î¿Ï… Î¼Î±Î¸Î±Î¯Î½ÎµÎ¹ ÎºÎ±Î¹ Ï€Î±Î¯ÏÎ½ÎµÎ¹ Î±Ï€Î¿Ï†Î¬ÏƒÎµÎ¹Ï‚
            - Î Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î±: Î¡Î¿Î¼Ï€ÏŒÏ„, AI Ï€Î±Î¯ÎºÏ„Î·Ï‚, trading bot
            
            #### 2. **Environment (Î ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½)**
            - ÎŸ ÎºÏŒÏƒÎ¼Î¿Ï‚ Î¼Îµ Ï„Î¿Î½ Î¿Ï€Î¿Î¯Î¿ Î±Î»Î»Î·Î»ÎµÏ€Î¹Î´ÏÎ¬ Î¿ agent
            - Î Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î±: Î£ÎºÎ±ÎºÎ¹Î­ÏÎ±, Ï€Î±Î¹Ï‡Î½Î¯Î´Î¹ video game, Ï‡ÏÎ·Î¼Î±Ï„Î¹ÏƒÏ„Î®ÏÎ¹Î¿
            
            #### 3. **State (ÎšÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ·)**
            - Î— Ï„ÏÎ­Ï‡Î¿Ï…ÏƒÎ± ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ· Ï„Î¿Ï… Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½Ï„Î¿Ï‚
            - Î Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î±: Î˜Î­ÏƒÎµÎ¹Ï‚ ÎºÎ¿Î¼Î¼Î±Ï„Î¹ÏÎ½ ÏƒÏ„Î¿ ÏƒÎºÎ¬ÎºÎ¹
            
            #### 4. **Action (Î•Î½Î­ÏÎ³ÎµÎ¹Î±)**
            - Î¤Î¹ Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± ÎºÎ¬Î½ÎµÎ¹ Î¿ agent
            - Î Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î±: ÎœÎµÏ„Î±ÎºÎ¯Î½Î·ÏƒÎ· Ï€Î¹Î¿Î½Î¹Î¿Ï, Ï€Î®Î´Î·Î¼Î±, Î±Î³Î¿ÏÎ¬ Î¼ÎµÏ„Î¿Ï‡Î®Ï‚
            
            #### 5. **Reward (Î‘Î½Ï„Î±Î¼Î¿Î¹Î²Î®)**
            - Î‘ÏÎ¹Î¸Î¼Î·Ï„Î¹ÎºÏŒ signal Ï€Î¿Ï… Î»Î­ÎµÎ¹ Ï€ÏŒÏƒÎ¿ ÎºÎ±Î»Î® Î®Ï„Î±Î½ Î· action
            - Positive: ÎšÎ±Î»ÏŒ (+1, +10, +100)
            - Negative: ÎšÎ±ÎºÏŒ (-1, -10, -100)
            - Zero: ÎŸÏ…Î´Î­Ï„ÎµÏÎ¿
            
            #### 6. **Policy (Î Î¿Î»Î¹Ï„Î¹ÎºÎ®) Ï€**
            - Î— ÏƒÏ„ÏÎ±Ï„Î·Î³Î¹ÎºÎ® Ï„Î¿Ï… agent: State â†’ Action
            - "Î¤Î¹ action Î½Î± ÎºÎ¬Î½Ï‰ ÏƒÎµ ÎºÎ¬Î¸Îµ state"
            
            #### 7. **Value Function V(s)**
            - Î ÏŒÏƒÎ¿ "ÎºÎ±Î»ÏŒ" ÎµÎ¯Î½Î±Î¹ Î­Î½Î± state Î¼Î±ÎºÏÎ¿Ï€ÏÏŒÎ¸ÎµÏƒÎ¼Î±
            - Î›Î±Î¼Î²Î¬Î½ÎµÎ¹ Ï…Ï€ÏŒÏˆÎ· Î¼ÎµÎ»Î»Î¿Î½Ï„Î¹ÎºÎ¬ rewards
            
            #### 8. **Q-Function Q(s,a)**
            - Î ÏŒÏƒÎ¿ "ÎºÎ±Î»Î®" ÎµÎ¯Î½Î±Î¹ Î¼Î¹Î± action ÏƒÎµ Î­Î½Î± state
            - Q(state, action) = Expected future reward
            
            ---
            
            ### ğŸ¯ Î¤ÏÏ€Î¿Î¹ RL:
            
            #### **Model-Free RL** (Î”ÎµÎ½ Î­Ï‡ÎµÎ¹ Î¼Î¿Î½Ï„Î­Î»Î¿ Ï„Î¿Ï… environment)
            - ÎœÎ±Î¸Î±Î¯Î½ÎµÎ¹ Î±Ï€ÎµÏ…Î¸ÎµÎ¯Î±Ï‚ Î±Ï€ÏŒ experience
            - Î Î¹Î¿ ÎºÎ¿Î¹Î½ÏŒ ÏƒÏ„Î·Î½ Ï€ÏÎ¬Î¾Î·
            
            #### **Model-Based RL** (ÎˆÏ‡ÎµÎ¹ Î¼Î¿Î½Ï„Î­Î»Î¿ Ï„Î¿Ï… environment)
            - ÎœÎ±Î¸Î±Î¯Î½ÎµÎ¹ Ï€ÏÏ‚ Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³ÎµÎ¯ Ï„Î¿ environment
            - ÎœÏ€Î¿ÏÎµÎ¯ Î½Î± ÏƒÏ‡ÎµÎ´Î¹Î¬Î¶ÎµÎ¹ Î¼Ï€ÏÎ¿ÏƒÏ„Î¬ (planning)
            
            ---
            
            ### âš™ï¸ ÎšÏÏÎ¹Î¿Î¹ Î‘Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Î¹:
            
            #### 1ï¸âƒ£ **Q-Learning** (Value-Based)
            
            **Î™Î´Î­Î±**: ÎœÎ¬Î¸Îµ Ï„Î·Î½ Q-function (quality of actions)
            
            **Update Rule:**
            ```
            Q(s,a) â† Q(s,a) + Î±[r + Î³Â·max(Q(s',a')) - Q(s,a)]
            ```
            
            ÎŒÏ€Î¿Ï…:
            - Î±: Learning rate (Ï€ÏŒÏƒÎ¿ Î³ÏÎ®Î³Î¿ÏÎ± Î¼Î±Î¸Î±Î¯Î½ÎµÎ¹)
            - Î³ (gamma): Discount factor (Ï€ÏŒÏƒÎ¿ ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÎ¬ ÎµÎ¯Î½Î±Î¹ future rewards)
            - r: Reward Ï€Î¿Ï… Î­Î»Î±Î²Îµ
            - s': Next state
            
            **Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬:**
            - Off-policy (Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Î¼Î¬Î¸ÎµÎ¹ Î±Ï€ÏŒ Î¬Î»Î»Î¿Ï…Ï‚ agents)
            - Convergence guaranteed (Ï…Ï€ÏŒ Ï€ÏÎ¿Ï‹Ï€Î¿Î¸Î­ÏƒÎµÎ¹Ï‚)
            - ÎšÎ»Î±ÏƒÎ¹ÎºÏŒÏ‚ Î±Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Ï‚
            
            **Î•Ï†Î±ÏÎ¼Î¿Î³Î­Ï‚:**
            - Grid world navigation
            - Simple games
            
            #### 2ï¸âƒ£ **Deep Q-Networks (DQN)** (Deep RL)
            
            **Î™Î´Î­Î±**: Î§ÏÎ®ÏƒÎ· Neural Network Î³Î¹Î± Q-function
            
            **Innovations:**
            - **Experience Replay**: Î‘Ï€Î¿Î¸Î·ÎºÎµÏÎµÎ¹ (s,a,r,s') ÎºÎ±Î¹ Ï„Î± replay
            - **Target Network**: Î£Ï„Î±Î¸ÎµÏÎ¿Ï€Î¿Î¯Î·ÏƒÎ· training
            
            **Î•Ï€Î¹Ï„ÎµÏÎ³Î¼Î±Ï„Î±:**
            - DeepMind's Atari games (2013)
            - Superhuman performance ÏƒÎµ Ï€Î¿Î»Î»Î¬ games
            
            #### 3ï¸âƒ£ **Policy Gradients** (Policy-Based)
            
            **Î™Î´Î­Î±**: ÎœÎ¬Î¸Îµ Î±Ï€ÎµÏ…Î¸ÎµÎ¯Î±Ï‚ Ï„Î·Î½ policy Ï€(a|s)
            
            **Î‘Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Î¹:**
            - **REINFORCE**: Î’Î±ÏƒÎ¹ÎºÏŒÏ‚ policy gradient
            - **Actor-Critic**: Î£Ï…Î½Î´Ï…Î±ÏƒÎ¼ÏŒÏ‚ value + policy
            - **A3C** (Asynchronous Advantage Actor-Critic): Î Î±ÏÎ¬Î»Î»Î·Î»Î¿Î¹ agents
            - **PPO** (Proximal Policy Optimization): State-of-the-art, stable
            - **TRPO** (Trust Region Policy Optimization)
            
            **Î Î»ÎµÎ¿Î½ÎµÎºÏ„Î®Î¼Î±Ï„Î±:**
            - Î”Î¿Ï…Î»ÎµÏÎµÎ¹ ÏƒÎµ continuous action spaces
            - Stochastic policies (Ï€Î¹Î¸Î±Î½Î¿Ï„Î¹ÎºÎ­Ï‚)
            
            #### 4ï¸âƒ£ **Advanced Algorithms**
            
            **DDPG** (Deep Deterministic Policy Gradient):
            - Î“Î¹Î± continuous control
            - Î¡Î¿Î¼Ï€Î¿Ï„Î¹ÎºÎ® manipulation
            
            **SAC** (Soft Actor-Critic):
            - Maximum entropy RL
            - Î Î¿Î»Ï stable
            
            **AlphaGo/AlphaZero:**
            - Monte Carlo Tree Search + Deep RL
            - Superhuman Go playing
            
            ---
            
            ### ğŸ“ˆ Exploration vs Exploitation:
            
            **Î”Î¯Î»Î·Î¼Î¼Î±**: ÎÎ± Î´Î¿ÎºÎ¹Î¼Î¬ÏƒÏ‰ Î½Î­Î± (explore) Î® Î½Î± ÎºÎ¬Î½Ï‰ Ï„Î¿ Î³Î½Ï‰ÏƒÏ„ÏŒ ÎºÎ±Î»ÏŒ (exploit);
            
            **Strategies:**
            - **Îµ-greedy**: ÎœÎµ Ï€Î¹Î¸Î±Î½ÏŒÏ„Î·Ï„Î± Îµ ÎºÎ¬Î½Îµ random action
            - **Softmax**: Probabilistic selection
            - **Upper Confidence Bound (UCB)**: Optimistic exploration
            
            ---
            
            ### ğŸ’¼ Real-World Applications:
            
            **Gaming:**
            - AlphaGo (Go)
            - OpenAI Five (Dota 2)
            - AlphaStar (StarCraft II)
            - Game AI characters
            
            **Robotics:**
            - Robotic manipulation (Ï€Î¹Î¬ÏƒÎ¹Î¼Î¿ Î±Î½Ï„Î¹ÎºÎµÎ¹Î¼Î­Î½Ï‰Î½)
            - Locomotion (Ï€ÎµÏÏ€Î¬Ï„Î·Î¼Î±)
            - Autonomous navigation
            - Assembly tasks
            
            **Autonomous Vehicles:**
            - Path planning
            - Adaptive cruise control
            - Parking
            
            **Finance:**
            - Trading strategies
            - Portfolio management
            - Dynamic pricing
            
            **Healthcare:**
            - Treatment optimization
            - Personalized medicine
            - Drug dosing
            
            **Recommender Systems:**
            - YouTube recommendations
            - News feed optimization
            - Ad placement
            
            **Energy:**
            - Data center cooling (Google)
            - Smart grid management
            - Building HVAC control
            
            **Natural Language:**
            - Dialogue systems
            - Neural architecture search
            - Machine translation improvements
            
            ---
            
            ### ğŸ“Š Challenges:
            
            #### **Sample Efficiency**
            - Î§ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹ Î ÎŸÎ›Î›Î‘ Î´ÎµÎ¯Î³Î¼Î±Ï„Î± (millions!)
            - Î‘ÏÎ³Î® ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·
            - Î›ÏÏƒÎ·: Transfer learning, sim-to-real
            
            #### **Reward Engineering**
            - Î”ÏÏƒÎºÎ¿Î»Î¿ Î½Î± Î¿ÏÎ¯ÏƒÎµÎ¹Ï‚ ÏƒÏ‰ÏƒÏ„Î¬ rewards
            - Reward hacking (agent Î²ÏÎ¯ÏƒÎºÎµÎ¹ shortcuts)
            - Î›ÏÏƒÎ·: Inverse RL, reward shaping
            
            #### **Stability**
            - Training Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± diverge
            - Sensitive ÏƒÎµ hyperparameters
            - Î›ÏÏƒÎ·: PPO, SAC (Ï€Î¹Î¿ stable algorithms)
            
            #### **Credit Assignment**
            - Î Î¿Î¹Î± action Î®Ï„Î±Î½ Ï…Ï€ÎµÏÎ¸Ï…Î½Î· Î³Î¹Î± Ï„Î¿ reward;
            - Temporal credit assignment problem
            
            #### **Exploration**
            - Î ÏÏ‚ Î½Î± explore Î±Ï€Î¿Î´Î¿Ï„Î¹ÎºÎ¬;
            - Sparse rewards (Î»Î¯Î³Î± rewards)
            
            ---
            
            ### ğŸ› ï¸ Frameworks & Tools:
            
            **OpenAI Gym:**
            - Standard RL environments
            - Atari, MuJoCo, Robotics
            
            **Stable Baselines3:**
            - Reliable RL implementations
            - PPO, A2C, SAC, TD3, DQN
            
            **Ray RLlib:**
            - Scalable RL
            - Distributed training
            
            **TF-Agents:**
            - TensorFlow RL library
            
            **PyTorch RL:**
            - Î Î¿Î»Î»Î­Ï‚ implementations
            """,
            """
            **Î ÏŒÏ„Îµ Î½Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÎµÏ„Îµ:**
            - âœ… ÎˆÏ‡ÎµÏ„Îµ sequential decision problem
            - âœ… ÎœÏ€Î¿ÏÎµÎ¯Ï„Îµ Î½Î± Î¿ÏÎ¯ÏƒÎµÏ„Îµ rewards
            - âœ… ÎˆÏ‡ÎµÏ„Îµ simulator (Î® real environment)
            - âœ… Î§ÏÎµÎ¹Î¬Î¶ÎµÏƒÏ„Îµ adaptive behavior
            - âœ… Î¤Î¿ problem Î­Ï‡ÎµÎ¹ long-term consequences
            
            **Î Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î± Code (Q-Learning):**
            ```python
            import numpy as np
            
            # Initialize Q-table
            Q = np.zeros([n_states, n_actions])
            alpha = 0.1  # learning rate
            gamma = 0.99  # discount factor
            
            for episode in range(1000):
                state = env.reset()
                done = False
                
                while not done:
                    # Îµ-greedy action selection
                    if np.random.random() < epsilon:
                        action = env.action_space.sample()  # explore
                    else:
                        action = np.argmax(Q[state, :])  # exploit
                    
                    # Take action
                    next_state, reward, done, _ = env.step(action)
                    
                    # Q-learning update
                    Q[state, action] = Q[state, action] + alpha * (
                        reward + gamma * np.max(Q[next_state, :]) - Q[state, action]
                    )
                    
                    state = next_state
            ```
            
            **Î Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î± Code (PPO Î¼Îµ Stable-Baselines3):**
            ```python
            from stable_baselines3 import PPO
            import gym
            
            # Create environment
            env = gym.make('CartPole-v1')
            
            # Train PPO agent
            model = PPO('MlpPolicy', env, verbose=1)
            model.learn(total_timesteps=10000)
            
            # Test trained agent
            obs = env.reset()
            for i in range(1000):
                action, _states = model.predict(obs)
                obs, reward, done, info = env.step(action)
                env.render()
                if done:
                    obs = env.reset()
            ```
            """
        )
        
        st.markdown("---")
        st.markdown("""
        #### ğŸ” Î’Î±ÏƒÎ¹ÎºÎ¬ Î£Ï„Î¬Î´Î¹Î± ML Pipeline
        
        1. **Data Collection** (Î£Ï…Î»Î»Î¿Î³Î® Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½)
           - Î£Ï…Î³ÎºÎ­Î½Ï„ÏÏ‰ÏƒÎ· ÏƒÏ‡ÎµÏ„Î¹ÎºÏÎ½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
           - Î Î¿Î¹ÏŒÏ„Î·Ï„Î± > Î Î¿ÏƒÏŒÏ„Î·Ï„Î±
        
        2. **Data Preprocessing** (Î ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±)
           - ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
           - Î§ÎµÎ¹ÏÎ¹ÏƒÎ¼ÏŒÏ‚ missing values
           - Normalization/Standardization
           - Feature Engineering
        
        3. **Model Selection** (Î•Ï€Î¹Î»Î¿Î³Î® ÎœÎ¿Î½Ï„Î­Î»Î¿Ï…)
           - Î•Ï€Î¹Î»Î¿Î³Î® ÎºÎ±Ï„Î¬Î»Î»Î·Î»Î¿Ï… Î±Î»Î³Î¿ÏÎ¯Î¸Î¼Î¿Ï…
           - Î¥Ï€ÎµÏÏ€Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹ (hyperparameters)
        
        4. **Training** (Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·)
           - Fit Ï„Î¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï… ÏƒÏ„Î± training data
           - Optimization (Ï€.Ï‡. Gradient Descent)
        
        5. **Evaluation** (Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·)
           - ÎœÎµÏ„ÏÎ¹ÎºÎ­Ï‚: Accuracy, Precision, Recall, F1-Score
           - Cross-validation
           - Confusion Matrix
        
        6. **Deployment** (Î Î±ÏÎ±Î³Ï‰Î³Î®)
           - Î˜Î­ÏƒÎ· ÏƒÎµ production
           - Monitoring ÎºÎ±Î¹ maintenance
        
        #### ğŸ’¼ Î ÏÎ±ÎºÏ„Î¹ÎºÎ­Ï‚ Î•Ï†Î±ÏÎ¼Î¿Î³Î­Ï‚
        
        - **E-commerce**: Î ÏÎ¿Ï„Î¬ÏƒÎµÎ¹Ï‚ Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Ï‰Î½ (Amazon, Netflix)
        - **Finance**: Credit scoring, fraud detection
        - **Healthcare**: Î”Î¹Î¬Î³Î½Ï‰ÏƒÎ· Î±ÏƒÎ¸ÎµÎ½ÎµÎ¹ÏÎ½, drug discovery
        - **Marketing**: Customer segmentation, churn prediction
        - **Manufacturing**: Predictive maintenance, quality control
        
        #### ğŸ“Š Î”Î·Î¼Î¿Ï†Î¹Î»ÎµÎ¯Ï‚ Î’Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎµÏ‚ Python
        
        - **scikit-learn**: Î“ÎµÎ½Î¹ÎºÎ¿Ï ÏƒÎºÎ¿Ï€Î¿Ï ML
        - **XGBoost**: Gradient boosting
        - **LightGBM**: Fast gradient boosting
        - **CatBoost**: Categorical features handling
        
        #### âš ï¸ Î ÏÎ¿ÎºÎ»Î®ÏƒÎµÎ¹Ï‚
        
        - **Overfitting**: Î¤Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ Î¼Î±Î¸Î±Î¯Î½ÎµÎ¹ "Î±Ï€' Î­Î¾Ï‰" Ï„Î± training data
        - **Underfitting**: Î¤Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ ÎµÎ¯Î½Î±Î¹ Ï€Î¿Î»Ï Î±Ï€Î»ÏŒ
        - **Bias in Data**: ÎœÎµÏÎ¿Î»Î·ÏˆÎ¯Î± ÏƒÏ„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±
        - **Feature Engineering**: Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÏƒÏ‰ÏƒÏ„ÏÎ½ features
        """)
    
    with st.expander('ğŸŒ **Deep Learning** - ÎÎµÏ…ÏÏ‰Î½Î¹ÎºÎ¬ Î´Î¯ÎºÏ„Ï…Î± Î¼Îµ Ï€Î¿Î»Î»Î¬ ÎµÏ€Î¯Ï€ÎµÎ´Î±', expanded=False):
        st.markdown("""
        ### Î¤Î¹ ÎµÎ¯Î½Î±Î¹ Ï„Î¿ Deep Learning;
        
        Î¤Î¿ **Deep Learning** ÎµÎ¯Î½Î±Î¹ Ï…Ï€Î¿ÎºÎ±Ï„Î·Î³Î¿ÏÎ¯Î± Ï„Î¿Ï… Machine Learning Ï€Î¿Ï… Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯ **Î½ÎµÏ…ÏÏ‰Î½Î¹ÎºÎ¬ Î´Î¯ÎºÏ„Ï…Î±** 
        Î¼Îµ Ï€Î¿Î»Î»Î¬ ÎºÏÏ…Ï†Î¬ ÎµÏ€Î¯Ï€ÎµÎ´Î± (layers) Î³Î¹Î± Î½Î± Î¼Î¬Î¸ÎµÎ¹ Ï€Î¿Î»ÏÏ€Î»Î¿ÎºÎµÏ‚ Î±Î½Î±Ï€Î±ÏÎ±ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚ Î±Ï€ÏŒ Î´ÎµÎ´Î¿Î¼Î­Î½Î±.
        
        #### ğŸ§¬ Î‘ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ­Ï‚ Neural Networks
        
        **1. Feedforward Neural Networks (FNN)**
        - Î¤Î¿ Ï€Î¹Î¿ Î²Î±ÏƒÎ¹ÎºÏŒ Ï„ÏÏ€Î¿ Î½ÎµÏ…ÏÏ‰Î½Î¹ÎºÎ¿Ï Î´Î¹ÎºÏ„ÏÎ¿Ï…
        - Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯Î± ÏÎ­ÎµÎ¹ Ï€ÏÎ¿Ï‚ Ï„Î± ÎµÎ¼Ï€ÏÏŒÏ‚ (input â†’ hidden â†’ output)
        - Î§ÏÎ®ÏƒÎ·: Tabular data, Î±Ï€Î»Î® classification/regression
        
        **2. Convolutional Neural Networks (CNN)**
        - Î•Î¹Î´Î¹ÎºÎµÏ…Î¼Î­Î½Î± Î³Î¹Î± **ÎµÎ¹ÎºÏŒÎ½ÎµÏ‚** ÎºÎ±Î¹ spatial data
        - Convolution layers ÎµÎ¾Î¬Î³Î¿Ï…Î½ features
        - Pooling layers Î¼ÎµÎ¹ÏÎ½Î¿Ï…Î½ Î´Î¹Î±ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚
        - Î Î±ÏÎ±Î´ÎµÎ¯Î³Î¼Î±Ï„Î±: ResNet, VGG, Inception, EfficientNet
        - Î•Ï†Î±ÏÎ¼Î¿Î³Î­Ï‚: 
          - Image classification
          - Object detection (YOLO, Faster R-CNN)
          - Face recognition
          - Medical imaging
        
        **3. Recurrent Neural Networks (RNN)**
        - Î“Î¹Î± **sequential data** (ÎºÎµÎ¯Î¼ÎµÎ½Î¿, Ï‡ÏÎ¿Î½Î¿ÏƒÎµÎ¹ÏÎ­Ï‚)
        - ÎˆÏ‡Î¿Ï…Î½ "Î¼Î½Î®Î¼Î·" Ï€ÏÎ¿Î·Î³Î¿ÏÎ¼ÎµÎ½Ï‰Î½ states
        - Î Î±ÏÎ±Î´ÎµÎ¯Î³Î¼Î±Ï„Î±: LSTM, GRU
        - Î•Ï†Î±ÏÎ¼Î¿Î³Î­Ï‚:
          - Natural Language Processing
          - Speech recognition
          - Time series prediction
          - Music generation
        
        **4. Transformer Architecture**
        - **Î•Ï€Î±Î½Î¬ÏƒÏ„Î±ÏƒÎ· ÏƒÏ„Î¿ NLP** (2017)
        - Self-attention mechanism
        - Î Î±ÏÎ¬Î»Î»Î·Î»Î· ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± (Î³ÏÎ·Î³Î¿ÏÏŒÏ„ÎµÏÎ¿ Î±Ï€ÏŒ RNN)
        - Î Î±ÏÎ±Î´ÎµÎ¯Î³Î¼Î±Ï„Î±: BERT, GPT, T5, Vision Transformer (ViT)
        - Î•Ï†Î±ÏÎ¼Î¿Î³Î­Ï‚:
          - Language models (ChatGPT, Claude)
          - Machine translation
          - Text summarization
          - Question answering
        
        **5. Generative Adversarial Networks (GANs)**
        - Î”ÏÎ¿ Î´Î¯ÎºÏ„Ï…Î± "Ï€Î±Î»ÎµÏÎ¿Ï…Î½" (Generator vs Discriminator)
        - Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÏÎµÎ±Î»Î¹ÏƒÏ„Î¹ÎºÏÎ½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
        - Î•Ï†Î±ÏÎ¼Î¿Î³Î­Ï‚:
          - Image generation (StyleGAN, BigGAN)
          - DeepFakes
          - Data augmentation
          - Art creation
        
        **6. Autoencoders**
        - Î£Ï…Î¼Ï€Î¯ÎµÏƒÎ· ÎºÎ±Î¹ Î±Ï€Î¿ÏƒÏ…Î¼Ï€Î¯ÎµÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
        - ÎœÎ¬Î¸Î·ÏƒÎ· latent representations
        - Î¤ÏÏ€Î¿Î¹: VAE (Variational Autoencoders)
        - Î•Ï†Î±ÏÎ¼Î¿Î³Î­Ï‚:
          - Dimensionality reduction
          - Anomaly detection
          - Denoising
          - Image compression
        
        #### ğŸ¯ Î’Î±ÏƒÎ¹ÎºÎ¬ Concepts
        
        **Activation Functions:**
        - ReLU (Rectified Linear Unit): f(x) = max(0, x)
        - Sigmoid: f(x) = 1/(1+e^(-x))
        - Tanh: f(x) = (e^x - e^(-x))/(e^x + e^(-x))
        - Softmax: Î³Î¹Î± classification
        
        **Optimization Algorithms:**
        - SGD (Stochastic Gradient Descent)
        - Adam (Adaptive Moment Estimation)
        - RMSprop
        - AdaGrad
        
        **Regularization Techniques:**
        - Dropout: Î‘Ï€ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¯Î·ÏƒÎ· Ï„Ï…Ï‡Î±Î¯Ï‰Î½ neurons
        - L1/L2 Regularization
        - Batch Normalization
        - Early Stopping
        
        #### ğŸ’» Frameworks
        
        - **TensorFlow**: Google's framework
        - **PyTorch**: Facebook's framework (ÎµÏÎµÏ…Î½Î·Ï„Î¹ÎºÏŒ favorite)
        - **Keras**: High-level API (Ï„ÏÏÎ± Î¼Î­ÏÎ¿Ï‚ Ï„Î¿Ï… TensorFlow)
        - **JAX**: High-performance computing
        
        #### ğŸš€ Cutting-Edge Applications
        
        - **Computer Vision**: Self-driving cars, medical imaging
        - **NLP**: ChatGPT, Google Translate, sentiment analysis
        - **Speech**: Siri, Alexa, speech-to-text
        - **Gaming**: AlphaGo, OpenAI Five (Dota 2)
        - **Science**: Protein folding (AlphaFold), drug discovery
        
        #### âš¡ Î‘Ï€Î±Î¹Ï„Î®ÏƒÎµÎ¹Ï‚
        
        - **Hardware**: GPU/TPU (NVIDIA, Google Cloud)
        - **Data**: ÎœÎµÎ³Î¬Î»Î± datasets (Ï‡Î¹Î»Î¹Î¬Î´ÎµÏ‚-ÎµÎºÎ±Ï„Î¿Î¼Î¼ÏÏÎ¹Î± Î´ÎµÎ¯Î³Î¼Î±Ï„Î±)
        - **Time**: Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Ï€Î¬ÏÎµÎ¹ ÏÏÎµÏ‚/Î¼Î­ÏÎµÏ‚
        - **Expertise**: Î“Î½ÏÏƒÎ· hyperparameters, architectures
        """)
    
    with st.expander('ğŸ’¬ **Natural Language Processing (NLP)** - Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î¦Ï…ÏƒÎ¹ÎºÎ®Ï‚ Î“Î»ÏÏƒÏƒÎ±Ï‚', expanded=False):
        st.markdown("""
        ### Î¤Î¹ ÎµÎ¯Î½Î±Î¹ Ï„Î¿ NLP;
        
        Î¤Î¿ **Natural Language Processing** ÎµÎ¯Î½Î±Î¹ Î¿ ÎºÎ»Î¬Î´Î¿Ï‚ Ï„Î·Ï‚ AI Ï€Î¿Ï… Î±ÏƒÏ‡Î¿Î»ÎµÎ¯Ï„Î±Î¹ Î¼Îµ Ï„Î·Î½ Î±Î»Î»Î·Î»ÎµÏ€Î¯Î´ÏÎ±ÏƒÎ· 
        Î¼ÎµÏ„Î±Î¾Ï Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÏ„ÏÎ½ ÎºÎ±Î¹ Î±Î½Î¸ÏÏÏ€Î¹Î½Î·Ï‚ Î³Î»ÏÏƒÏƒÎ±Ï‚.
        
        #### ğŸ“ Î’Î±ÏƒÎ¹ÎºÎ­Ï‚ Î•ÏÎ³Î±ÏƒÎ¯ÎµÏ‚ NLP
        
        **1. Text Classification**
        - Sentiment Analysis (Î±Î½Î¬Î»Ï…ÏƒÎ· ÏƒÏ…Î½Î±Î¹ÏƒÎ¸Î®Î¼Î±Ï„Î¿Ï‚)
        - Spam Detection
        - Topic Classification
        - Intent Detection (chatbots)
        
        **2. Named Entity Recognition (NER)**
        - Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒÏ‚ Î¿Î½Î¿Î¼Î¬Ï„Ï‰Î½, Ï„ÏŒÏ€Ï‰Î½, Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¹ÏÎ½
        - Î•Î¾Î±Î³Ï‰Î³Î® Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯Î±Ï‚ Î±Ï€ÏŒ ÎºÎµÎ¯Î¼ÎµÎ½Î¿
        
        **3. Machine Translation**
        - ÎœÎµÏ„Î¬Ï†ÏÎ±ÏƒÎ· Î¼ÎµÏ„Î±Î¾Ï Î³Î»Ï‰ÏƒÏƒÏÎ½
        - Google Translate, DeepL
        - Neural Machine Translation (NMT)
        
        **4. Question Answering**
        - Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ· ÏƒÎµ ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚
        - Reading comprehension
        - ChatGPT, Bing Chat
        
        **5. Text Summarization**
        - Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î· ÏƒÏÎ½Î¿ÏˆÎ· ÎºÎµÎ¹Î¼Î­Î½Ï‰Î½
        - Extractive vs Abstractive
        
        **6. Text Generation**
        - Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÎºÎµÎ¹Î¼Î­Î½Î¿Ï…
        - GPT models, content creation
        - Story writing, code generation
        
        **7. Speech Recognition**
        - Speech-to-text
        - Siri, Google Assistant, Alexa
        
        **8. Part-of-Speech Tagging**
        - Î¤Î±Ï…Ï„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î¼ÎµÏÏÎ½ Ï„Î¿Ï… Î»ÏŒÎ³Î¿Ï…
        - Î£ÏÎ½Ï„Î±Î¾Î· ÎºÎ±Î¹ Î³ÏÎ±Î¼Î¼Î±Ï„Î¹ÎºÎ® Î±Î½Î¬Î»Ï…ÏƒÎ·
        
        #### ğŸ”¤ Î’Î±ÏƒÎ¹ÎºÎ¬ Î£Ï„Î¬Î´Î¹Î± NLP Pipeline
        
        **1. Tokenization**
        - Î”Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÎºÎµÎ¹Î¼Î­Î½Î¿Ï… ÏƒÎµ tokens (Î»Î­Î¾ÎµÎ¹Ï‚, Ï€ÏÎ¿Ï„Î¬ÏƒÎµÎ¹Ï‚)
        - Word tokenization, sentence tokenization
        
        **2. Text Cleaning**
        - Lowercase conversion
        - Î‘Ï†Î±Î¯ÏÎµÏƒÎ· ÏƒÎ·Î¼ÎµÎ¯Ï‰Î½ ÏƒÏ„Î¯Î¾Î·Ï‚
        - Î‘Ï†Î±Î¯ÏÎµÏƒÎ· stop words (the, and, is...)
        
        **3. Stemming / Lemmatization**
        - Stemming: running â†’ run (Î±Ï†Î±Î¯ÏÎµÏƒÎ· ÎºÎ±Ï„Î±Î»Î®Î¾ÎµÏ‰Î½)
        - Lemmatization: better â†’ good (Î³ÏÎ±Î¼Î¼Î±Ï„Î¹ÎºÎ® Î¼Î¿ÏÏ†Î®)
        
        **4. Feature Extraction**
        - **Bag of Words (BoW)**: Î£Ï…Ï‡Î½ÏŒÏ„Î·Ï„Î± Î»Î­Î¾ÎµÏ‰Î½
        - **TF-IDF**: Term Frequency - Inverse Document Frequency
        - **Word Embeddings**: Word2Vec, GloVe, FastText
        - **Contextualized Embeddings**: BERT, ELMo
        
        **5. Model Training**
        - Traditional ML: Naive Bayes, SVM, Random Forest
        - Deep Learning: RNN, LSTM, Transformers
        
        #### ğŸ¤– Î£ÏÎ³Ï‡ÏÎ¿Î½Î± NLP Models
        
        **Pre-trained Language Models:**
        
        - **BERT** (Bidirectional Encoder Representations from Transformers)
          - ÎšÎ±Ï„Î±Î½ÏŒÎ·ÏƒÎ· context Î±Ï€ÏŒ Î´ÏÎ¿ ÎºÎ±Ï„ÎµÏ…Î¸ÏÎ½ÏƒÎµÎ¹Ï‚
          - Fine-tuning Î³Î¹Î± specific tasks
        
        - **GPT** (Generative Pre-trained Transformer)
          - GPT-3, GPT-4: ÎœÎ¿Î½Ï„Î­Î»Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î±Ï‚ ÎºÎµÎ¹Î¼Î­Î½Î¿Ï…
          - ChatGPT: Conversational AI
        
        - **T5** (Text-to-Text Transfer Transformer)
          - ÎŒÎ»ÎµÏ‚ Î¿Î¹ ÎµÏÎ³Î±ÏƒÎ¯ÎµÏ‚ Ï‰Ï‚ text-to-text
        
        - **RoBERTa**: Optimized BERT
        
        - **XLNet**: Permutation language modeling
        
        - **ELECTRA**: Efficient pre-training
        
        #### ğŸŒ Multilingual NLP
        
        - **mBERT**: Multilingual BERT
        - **XLM-R**: Cross-lingual modeling
        - Î¥Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· 100+ Î³Î»Ï‰ÏƒÏƒÏÎ½
        
        #### ğŸ’¼ Î•Ï†Î±ÏÎ¼Î¿Î³Î­Ï‚
        
        - **Chatbots**: Î•Î¾Ï…Ï€Î·ÏÎ­Ï„Î·ÏƒÎ· Ï€ÎµÎ»Î±Ï„ÏÎ½ 24/7
        - **Virtual Assistants**: Siri, Alexa, Google Assistant
        - **Content Moderation**: Î¦Î¹Î»Ï„ÏÎ¬ÏÎ¹ÏƒÎ¼Î± toxic content
        - **Email Filtering**: Spam detection
        - **Social Media**: Sentiment analysis, trend detection
        - **Healthcare**: Clinical notes analysis
        - **Legal**: Contract analysis, document review
        - **Finance**: News analysis, earnings calls
        
        #### ğŸ“š Î’Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎµÏ‚ Python
        
        - **NLTK**: Natural Language Toolkit (traditional)
        - **spaCy**: Industrial-strength NLP
        - **Transformers (Hugging Face)**: Pre-trained models
        - **Gensim**: Topic modeling, word embeddings
        - **TextBlob**: Simple NLP tasks
        
        #### ğŸ¯ Î ÏÎ¿ÎºÎ»Î®ÏƒÎµÎ¹Ï‚
        
        - **Ambiguity**: Î Î¿Î»Ï…ÏƒÎ·Î¼Î¯Î± Î»Î­Î¾ÎµÏ‰Î½
        - **Context**: ÎšÎ±Ï„Î±Î½ÏŒÎ·ÏƒÎ· Ï€Î»Î±Î¹ÏƒÎ¯Î¿Ï…
        - **Sarcasm/Irony**: Î”ÏÏƒÎºÎ¿Î»Î¿ Î½Î± Î±Î½Î¹Ï‡Î½ÎµÏ…Î¸ÎµÎ¯
        - **Cultural Nuances**: Î Î¿Î»Î¹Ï„Î¹ÏƒÎ¼Î¹ÎºÎ­Ï‚ Î´Î¹Î±Ï†Î¿ÏÎ­Ï‚
        - **Low-resource Languages**: Î›Î¯Î³Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î³Î¹Î± ÎºÎ¬Ï€Î¿Î¹ÎµÏ‚ Î³Î»ÏÏƒÏƒÎµÏ‚
        """)
    
    with st.expander('ğŸ‘ï¸ **Computer Vision** - ÎŒÏÎ±ÏƒÎ· Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÏ„ÏÎ½', expanded=False):
        st.markdown("""
        ### Î¤Î¹ ÎµÎ¯Î½Î±Î¹ Î· Computer Vision;
        
        Î— **Computer Vision** ÎµÎ¯Î½Î±Î¹ Î¿ ÎºÎ»Î¬Î´Î¿Ï‚ Ï„Î·Ï‚ AI Ï€Î¿Ï… ÎµÏ€Î¹Ï„ÏÎ­Ï€ÎµÎ¹ ÏƒÏ„Î¿Ï…Ï‚ Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÏ„Î­Ï‚ Î½Î± "Î²Î»Î­Ï€Î¿Ï…Î½" 
        ÎºÎ±Î¹ Î½Î± ÎºÎ±Ï„Î±Î½Î¿Î¿ÏÎ½ Ï„Î¿ Ï€ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿ ÎµÎ¹ÎºÏŒÎ½Ï‰Î½ ÎºÎ±Î¹ Î²Î¯Î½Ï„ÎµÎ¿.
        
        #### ğŸ¯ Î’Î±ÏƒÎ¹ÎºÎ­Ï‚ Î•ÏÎ³Î±ÏƒÎ¯ÎµÏ‚ Computer Vision
        
        **1. Image Classification**
        - Î¤Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ· ÎµÎ¹ÎºÏŒÎ½Ï‰Î½ ÏƒÎµ ÎºÎ±Ï„Î·Î³Î¿ÏÎ¯ÎµÏ‚
        - Î Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î±: Î“Î¬Ï„Î± vs Î£ÎºÏÎ»Î¿Ï‚
        - Datasets: ImageNet (1000 ÎºÎ±Ï„Î·Î³Î¿ÏÎ¯ÎµÏ‚)
        - Models: ResNet, VGG, Inception, EfficientNet
        
        **2. Object Detection**
        - Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒÏ‚ Î±Î½Ï„Î¹ÎºÎµÎ¹Î¼Î­Î½Ï‰Î½ ÏƒÎµ ÎµÎ¹ÎºÏŒÎ½Î±
        - Bounding boxes + classification
        - Real-time detection
        - Algorithms:
          - **YOLO** (You Only Look Once): Real-time
          - **Faster R-CNN**: High accuracy
          - **SSD**: Single Shot Detector
          - **RetinaNet**: Focal loss
        
        **3. Semantic Segmentation**
        - Î¤Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ· ÎºÎ¬Î¸Îµ pixel ÏƒÎµ ÎºÎ±Ï„Î·Î³Î¿ÏÎ¯Î±
        - Pixel-level understanding
        - Models: U-Net, DeepLab, SegNet
        - Î•Ï†Î±ÏÎ¼Î¿Î³Î­Ï‚: Autonomous driving, medical imaging
        
        **4. Instance Segmentation**
        - Î”Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÎµÏ€Î¹Î¼Î­ÏÎ¿Ï…Ï‚ instances
        - Mask R-CNN
        - Î£Ï…Î½Î´Ï…Î±ÏƒÎ¼ÏŒÏ‚ detection + segmentation
        
        **5. Face Recognition**
        - Î‘Î½Î±Î³Î½ÏÏÎ¹ÏƒÎ· Ï€ÏÎ¿ÏƒÏÏ€Î¿Ï…
        - Face detection â†’ Face alignment â†’ Face recognition
        - Models: FaceNet, DeepFace, ArcFace
        - Î•Ï†Î±ÏÎ¼Î¿Î³Î­Ï‚: Security, photo tagging, authentication
        
        **6. Pose Estimation**
        - Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒÏ‚ keypoints Ï„Î¿Ï… ÏƒÏÎ¼Î±Ï„Î¿Ï‚
        - Skeleton detection
        - Models: OpenPose, PoseNet
        - Î•Ï†Î±ÏÎ¼Î¿Î³Î­Ï‚: Sports analysis, AR/VR, fitness apps
        
        **7. Image Generation**
        - Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î½Î­Ï‰Î½ ÎµÎ¹ÎºÏŒÎ½Ï‰Î½
        - GANs, Diffusion Models
        - Î Î±ÏÎ±Î´ÎµÎ¯Î³Î¼Î±Ï„Î±:
          - **StyleGAN**: Î¡ÎµÎ±Î»Î¹ÏƒÏ„Î¹ÎºÎ¬ Ï€ÏÏŒÏƒÏ‰Ï€Î±
          - **DALL-E**: Text-to-image
          - **Stable Diffusion**: Open-source generation
          - **Midjourney**: Artistic images
        
        **8. Video Analysis**
        - Action recognition
        - Video classification
        - Tracking objects ÏƒÎµ Î²Î¯Î½Ï„ÎµÎ¿
        - Activity detection
        
        #### ğŸ—ï¸ Î‘ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ­Ï‚ CNN Î³Î¹Î± Computer Vision
        
        **Classic Architectures:**
        - **LeNet-5** (1998): Î ÏÏÏ„Î¿ CNN Î³Î¹Î± MNIST
        - **AlexNet** (2012): ImageNet winner, ReLU, dropout
        - **VGG** (2014): Î Î¿Î»Ï Î²Î±Î¸Ï Î´Î¯ÎºÏ„Ï…Î¿ (16-19 layers)
        - **GoogleNet/Inception** (2014): Inception modules
        
        **Modern Architectures:**
        - **ResNet** (2015): Residual connections, 50-152 layers
        - **DenseNet** (2017): Dense connections
        - **EfficientNet** (2019): Optimal scaling
        - **Vision Transformer (ViT)** (2020): Transformers for images
        - **Swin Transformer** (2021): Hierarchical transformers
        
        #### ğŸ” Î’Î±ÏƒÎ¹ÎºÎ¬ Concepts
        
        **Convolution:**
        - Filters/Kernels ÎµÎ¾Î¬Î³Î¿Ï…Î½ features
        - Edge detection, texture, patterns
        - Spatial hierarchy (low â†’ high level features)
        
        **Pooling:**
        - Max pooling, Average pooling
        - ÎœÎµÎ¯Ï‰ÏƒÎ· Î´Î¹Î±ÏƒÏ„Î¬ÏƒÎµÏ‰Î½
        - Translation invariance
        
        **Data Augmentation:**
        - Rotation, flipping, cropping
        - Color jittering
        - Mixup, CutMix
        - Î‘ÏÎ¾Î·ÏƒÎ· dataset artificially
        
        **Transfer Learning:**
        - Pre-trained models ÏƒÎµ ImageNet
        - Fine-tuning Î³Î¹Î± specific task
        - Feature extraction
        
        #### ğŸ’¼ Î•Ï†Î±ÏÎ¼Î¿Î³Î­Ï‚ ÏƒÏ„Î·Î½ Î ÏÎ¬Î¾Î·
        
        **Î‘Ï…Ï„ÏŒÎ½Î¿Î¼Î± ÎŸÏ‡Î®Î¼Î±Ï„Î±:**
        - Lane detection
        - Object detection (Ï€ÎµÎ¶Î¿Î¯, Î¿Ï‡Î®Î¼Î±Ï„Î±)
        - Traffic sign recognition
        - Depth estimation
        
        **Healthcare:**
        - X-ray analysis
        - CT/MRI scan interpretation
        - Skin cancer detection
        - Retinal disease diagnosis
        - COVID-19 detection
        
        **Retail:**
        - Visual search (ÎµÏÏÎµÏƒÎ· Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Ï‰Î½ Î±Ï€ÏŒ Ï†Ï‰Ï„ÏŒ)
        - Cashier-less stores (Amazon Go)
        - Inventory management
        
        **Security:**
        - Surveillance systems
        - Anomaly detection
        - Facial recognition Î³Î¹Î± access control
        
        **Agriculture:**
        - Crop monitoring
        - Disease detection ÏƒÎµ Ï†Ï…Ï„Î¬
        - Yield prediction
        
        **Manufacturing:**
        - Quality inspection
        - Defect detection
        - Assembly verification
        
        **Social Media:**
        - Auto-tagging Ï†Ï‰Ï„Î¿Î³ÏÎ±Ï†Î¹ÏÎ½
        - Content moderation
        - Filters ÎºÎ±Î¹ effects (Snapchat, Instagram)
        
        #### ğŸ› ï¸ Tools ÎºÎ±Î¹ Frameworks
        
        **Deep Learning:**
        - TensorFlow, PyTorch
        - Keras
        - ONNX (model interchange)
        
        **Computer Vision Libraries:**
        - **OpenCV**: Traditional CV algorithms
        - **Pillow (PIL)**: Image processing
        - **scikit-image**: Image algorithms
        - **Detectron2**: Facebook's CV library
        - **MMDetection**: Toolbox for object detection
        
        **Pre-trained Models:**
        - **Torchvision**: PyTorch models
        - **Keras Applications**: TensorFlow models
        - **Timm**: PyTorch Image Models
        
        #### ğŸ“Š ÎœÎµÏ„ÏÎ¹ÎºÎ­Ï‚ Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·Ï‚
        
        - **Classification**: Accuracy, Precision, Recall, F1
        - **Object Detection**: mAP (mean Average Precision), IoU
        - **Segmentation**: Dice coefficient, IoU
        - **Image Generation**: FID (FrÃ©chet Inception Distance), IS (Inception Score)
        
        #### ğŸš§ Î ÏÎ¿ÎºÎ»Î®ÏƒÎµÎ¹Ï‚
        
        - **Lighting conditions**: Î¦Ï‰Ï„Î¹ÏƒÎ¼ÏŒÏ‚ ÎµÏ€Î·ÏÎµÎ¬Î¶ÎµÎ¹ Ï€Î¿Î¹ÏŒÏ„Î·Ï„Î±
        - **Occlusions**: Î‘Î½Ï„Î¹ÎºÎµÎ¯Î¼ÎµÎ½Î± ÎºÏÏ…Î¼Î¼Î­Î½Î±
        - **Scale variance**: Î‘Î½Ï„Î¹ÎºÎµÎ¯Î¼ÎµÎ½Î± ÏƒÎµ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¬ Î¼ÎµÎ³Î­Î¸Î·
        - **Real-time processing**: Î§ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹ Ï„Î±Ï‡ÏÏ„Î·Ï„Î±
        - **3D understanding**: Î‘Ï€ÏŒ 2D ÎµÎ¹ÎºÏŒÎ½ÎµÏ‚
        """)
    
    with st.expander('ğŸ¤– **Robotics** - Î¡Î¿Î¼Ï€Î¿Ï„Î¹ÎºÎ® ÎºÎ±Î¹ Î‘Ï…Ï„Î¿Î½Î¿Î¼Î¯Î±', expanded=False):
        st.markdown("""
        ### Î¤Î¹ ÎµÎ¯Î½Î±Î¹ Î· Robotics Î¼Îµ AI;
        
        Î— **Robotics** ÏƒÏ…Î½Î´Ï…Î¬Î¶ÎµÎ¹ AI, Î¼Î·Ï‡Î±Î½Î¹ÎºÎ®, ÎºÎ±Î¹ Ï†Ï…ÏƒÎ¹ÎºÎ® Î³Î¹Î± Ï„Î· Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÏÎ¿Î¼Ï€ÏŒÏ„ Ï€Î¿Ï… Î¼Ï€Î¿ÏÎ¿ÏÎ½ 
        Î½Î± Î±Î»Î»Î·Î»ÎµÏ€Î¹Î´ÏÎ¿ÏÎ½ Î¼Îµ Ï„Î¿ Ï†Ï…ÏƒÎ¹ÎºÏŒ ÎºÏŒÏƒÎ¼Î¿ ÎºÎ±Î¹ Î½Î± ÎµÎºÏ„ÎµÎ»Î¿ÏÎ½ ÎµÏÎ³Î±ÏƒÎ¯ÎµÏ‚ Î±Ï…Ï„ÏŒÎ½Î¿Î¼Î±.
        
        #### ğŸ¯ Î’Î±ÏƒÎ¹ÎºÎ¬ Î ÎµÎ´Î¯Î± AI ÏƒÏ„Î· Î¡Î¿Î¼Ï€Î¿Ï„Î¹ÎºÎ®
        
        **1. Perception (Î‘Î½Ï„Î¯Î»Î·ÏˆÎ·)**
        - **Computer Vision**: ÎšÎ¬Î¼ÎµÏÎµÏ‚ Î³Î¹Î± Î±Î½Î±Î³Î½ÏÏÎ¹ÏƒÎ· Î±Î½Ï„Î¹ÎºÎµÎ¹Î¼Î­Î½Ï‰Î½
        - **Sensor Fusion**: Î£Ï…Î½Î´Ï…Î±ÏƒÎ¼ÏŒÏ‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î±Ï€ÏŒ Ï€Î¿Î»Î»Î±Ï€Î»Î¿ÏÏ‚ Î±Î¹ÏƒÎ¸Î·Ï„Î®ÏÎµÏ‚
        - **Depth Sensing**: LiDAR, RGB-D ÎºÎ¬Î¼ÎµÏÎµÏ‚
        - **Object Recognition**: Î¤Î¹ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ ÏƒÏ„Î¿ Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½;
        - **Scene Understanding**: ÎšÎ±Ï„Î±Î½ÏŒÎ·ÏƒÎ· Ï€Î»Î±Î¹ÏƒÎ¯Î¿Ï…
        
        **2. Localization & Mapping (Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒÏ‚ & Î§Î±ÏÏ„Î¿Î³ÏÎ¬Ï†Î·ÏƒÎ·)**
        - **SLAM** (Simultaneous Localization and Mapping)
          - Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï‡Î¬ÏÏ„Î· ÎµÎ½Ï Ï„Î¿ ÏÎ¿Î¼Ï€ÏŒÏ„ ÎºÎ¹Î½ÎµÎ¯Ï„Î±Î¹
          - Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒÏ‚ Î¸Î­ÏƒÎ·Ï‚ ÏƒÏ„Î¿Î½ Ï‡Î¬ÏÏ„Î·
        - **GPS Navigation**: Outdoor ÎµÎ½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒÏ‚
        - **Visual Odometry**: Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ ÎºÎ¯Î½Î·ÏƒÎ·Ï‚ Î±Ï€ÏŒ ÎµÎ¹ÎºÏŒÎ½ÎµÏ‚
        - **Sensor-based Localization**: IMU, wheel encoders
        
        **3. Motion Planning (Î£Ï‡ÎµÎ´Î¹Î±ÏƒÎ¼ÏŒÏ‚ ÎšÎ¯Î½Î·ÏƒÎ·Ï‚)**
        - **Path Planning**: Î•ÏÏÎµÏƒÎ· Î´Î¹Î±Î´ÏÎ¿Î¼Î®Ï‚ Î±Ï€ÏŒ A ÏƒÎµ B
        - **Trajectory Optimization**: Î’Î­Î»Ï„Î¹ÏƒÏ„Î· Ï„ÏÎ¿Ï‡Î¹Î¬
        - **Obstacle Avoidance**: Î‘Ï€Î¿Ï†Ï…Î³Î® ÎµÎ¼Ï€Î¿Î´Î¯Ï‰Î½
        - **Algorithms**:
          - A* (A-star): Graph search
          - RRT (Rapidly-exploring Random Trees)
          - Dijkstra
          - Dynamic Window Approach
        
        **4. Control (ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚)**
        - **PID Controllers**: Proportional-Integral-Derivative
        - **Model Predictive Control (MPC)**
        - **Adaptive Control**: Î ÏÎ¿ÏƒÎ±ÏÎ¼Î¿Î³Î® ÏƒÎµ Î±Î»Î»Î±Î³Î­Ï‚
        - **Reinforcement Learning**: ÎœÎ¬Î¸Î·ÏƒÎ· optimal Ï€Î¿Î»Î¹Ï„Î¹ÎºÎ®Ï‚
        
        **5. Manipulation (Î§ÎµÎ¹ÏÎ¹ÏƒÎ¼ÏŒÏ‚)**
        - **Grasping**: Î Î¹Î¬ÏƒÎ¹Î¼Î¿ Î±Î½Ï„Î¹ÎºÎµÎ¹Î¼Î­Î½Ï‰Î½
        - **Pick and Place**: ÎœÎµÏ„Î±Ï†Î¿ÏÎ¬ Î±Î½Ï„Î¹ÎºÎµÎ¹Î¼Î­Î½Ï‰Î½
        - **Inverse Kinematics**: Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ joint angles
        - **Force Control**: ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î´ÏÎ½Î±Î¼Î·Ï‚ ÎµÏ€Î±Ï†Î®Ï‚
        
        **6. Human-Robot Interaction (HRI)**
        - **Speech Recognition**: Î¦Ï‰Î½Î·Ï„Î¹ÎºÎ­Ï‚ ÎµÎ½Ï„Î¿Î»Î­Ï‚
        - **Gesture Recognition**: Î‘Î½Î±Î³Î½ÏÏÎ¹ÏƒÎ· Ï‡ÎµÎ¹ÏÎ¿Î½Î¿Î¼Î¹ÏÎ½
        - **Emotion Detection**: Î‘Î½Î¯Ï‡Î½ÎµÏ…ÏƒÎ· ÏƒÏ…Î½Î±Î¹ÏƒÎ¸Î·Î¼Î¬Ï„Ï‰Î½
        - **Collaborative Robotics**: Cobots Ï€Î¿Ï… Î´Î¿Ï…Î»ÎµÏÎ¿Ï…Î½ Î¼Îµ Î±Î½Î¸ÏÏÏ€Î¿Ï…Ï‚
        
        #### ğŸš— Î‘Ï…Ï„ÏŒÎ½Î¿Î¼Î± ÎŸÏ‡Î®Î¼Î±Ï„Î± (Autonomous Vehicles)
        
        **Î•Ï€Î¯Ï€ÎµÎ´Î± Î‘Ï…Ï„Î¿Î½Î¿Î¼Î¯Î±Ï‚:**
        - **Level 0**: ÎšÎ±Î¼Î¯Î± Î±Ï…Ï„Î¿Î¼Î±Ï„Î¿Ï€Î¿Î¯Î·ÏƒÎ·
        - **Level 1**: Driver assistance (cruise control)
        - **Level 2**: Partial automation (Tesla Autopilot)
        - **Level 3**: Conditional automation
        - **Level 4**: High automation (ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½ÎµÏ‚ ÏƒÏ…Î½Î¸Î®ÎºÎµÏ‚)
        - **Level 5**: Full automation (Ï€Î±Î½Ï„Î¿Ï)
        
        **Î¤ÎµÏ‡Î½Î¿Î»Î¿Î³Î¯ÎµÏ‚:**
        - **Sensors**: ÎšÎ¬Î¼ÎµÏÎµÏ‚, LiDAR, Radar, Ultrasonic
        - **Perception**: Object detection, lane detection, traffic sign recognition
        - **Prediction**: Î ÏÏŒÎ²Î»ÎµÏˆÎ· ÏƒÏ…Î¼Ï€ÎµÏÎ¹Ï†Î¿ÏÎ¬Ï‚ Î¬Î»Î»Ï‰Î½ Î¿Ï‡Î·Î¼Î¬Ï„Ï‰Î½/Ï€ÎµÎ¶ÏÎ½
        - **Planning**: Route planning, behavior planning
        - **Control**: Steering, throttle, brakes
        
        **Î•Ï„Î±Î¹ÏÎµÎ¯ÎµÏ‚:**
        - Waymo (Google), Tesla, Cruise (GM), Argo AI, Zoox (Amazon)
        
        #### ğŸ­ Industrial Robotics (Î’Î¹Î¿Î¼Î·Ï‡Î±Î½Î¹ÎºÎ¬ Î¡Î¿Î¼Ï€ÏŒÏ„)
        
        **Î¤ÏÏ€Î¿Î¹:**
        - **Robotic Arms**: Manipulation, assembly
        - **AGVs** (Automated Guided Vehicles): ÎœÎµÏ„Î±Ï†Î¿ÏÎ¬ Ï…Î»Î¹ÎºÏÎ½
        - **Collaborative Robots (Cobots)**: Î•ÏÎ³Î±ÏƒÎ¯Î± Î¼Îµ Î±Î½Î¸ÏÏÏ€Î¿Ï…Ï‚
        - **Delta Robots**: Î¥ÏˆÎ·Î»Î® Ï„Î±Ï‡ÏÏ„Î·Ï„Î±, pick-and-place
        
        **Î•Ï†Î±ÏÎ¼Î¿Î³Î­Ï‚:**
        - Î£Ï…Î½Î±ÏÎ¼Î¿Î»ÏŒÎ³Î·ÏƒÎ· (Automotive industry)
        - Welding, painting
        - Packaging
        - Quality inspection
        - Material handling
        
        **AI Enhancements:**
        - Computer Vision Î³Î¹Î± inspection
        - Reinforcement Learning Î³Î¹Î± Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ·
        - Predictive maintenance
        
        #### ğŸ  Service Robotics (Î¡Î¿Î¼Ï€ÏŒÏ„ Î¥Ï€Î·ÏÎµÏƒÎ¹ÏÎ½)
        
        **Household:**
        - **Vacuum Cleaners**: Roomba, Roborock
        - **Lawn Mowers**: Husqvarna, Worx
        - **Companion Robots**: Pepper, Jibo
        
        **Healthcare:**
        - **Surgical Robots**: Da Vinci Surgical System
        - **Rehabilitation Robots**: Î’Î¿Î®Î¸ÎµÎ¹Î± ÏƒÎµ Î±ÏƒÎ¸ÎµÎ½ÎµÎ¯Ï‚
        - **Disinfection Robots**: UV-C Î³Î¹Î± Î±Ï€Î¿Î»ÏÎ¼Î±Î½ÏƒÎ·
        - **Delivery Robots**: Î¦Î¬ÏÎ¼Î±ÎºÎ±, Î³ÎµÏÎ¼Î±Ï„Î± ÏƒÎµ Î½Î¿ÏƒÎ¿ÎºÎ¿Î¼ÎµÎ¯Î±
        
        **Hospitality:**
        - Î¡Î¿Î¼Ï€ÏŒÏ„ ÏÎµÏƒÎµÏˆÎ¹ÏŒÎ½ ÏƒÎµ Î¾ÎµÎ½Î¿Î´Î¿Ï‡ÎµÎ¯Î±
        - Delivery robots ÏƒÎµ ÎµÏƒÏ„Î¹Î±Ï„ÏŒÏÎ¹Î±
        - Cleaning robots
        
        #### ğŸš Drones (UAVs - Unmanned Aerial Vehicles)
        
        **Î•Ï†Î±ÏÎ¼Î¿Î³Î­Ï‚:**
        - **Photography/Videography**: Aerial shots
        - **Delivery**: Amazon Prime Air, Zipline (Î¹Î±Ï„ÏÎ¹ÎºÎ¬)
        - **Agriculture**: Crop monitoring, spraying
        - **Inspection**: ÎšÏ„Î¯ÏÎ¹Î±, Î³Î­Ï†Ï…ÏÎµÏ‚, Ï€Ï…Î»ÏÎ½ÎµÏ‚
        - **Search and Rescue**: Î•ÏÏÎµÏƒÎ· Î±Î³Î½Î¿Î¿Ï…Î¼Î­Î½Ï‰Î½
        - **Military**: Surveillance, combat
        
        **AI Capabilities:**
        - Autonomous flight
        - Obstacle avoidance
        - Object tracking
        - Swarm intelligence (drone swarms)
        
        #### ğŸ¤ Social Robots
        
        **Î Î±ÏÎ±Î´ÎµÎ¯Î³Î¼Î±Ï„Î±:**
        - **Pepper**: Humanoid robot Î³Î¹Î± interaction
        - **NAO**: Î•ÎºÏ€Î±Î¹Î´ÎµÏ…Ï„Î¹ÎºÏŒ ÏÎ¿Î¼Ï€ÏŒÏ„
        - **Sophia**: Î‘Ï€ÏŒ Hanson Robotics
        - **Paro**: Therapeutic seal robot
        
        **Capabilities:**
        - Facial recognition
        - Emotion detection
        - Natural language interaction
        - Educational content delivery
        
        #### ğŸ§  Key AI Techniques ÏƒÏ„Î· Î¡Î¿Î¼Ï€Î¿Ï„Î¹ÎºÎ®
        
        **1. Reinforcement Learning**
        - ÎœÎ¬Î¸Î·ÏƒÎ· Ï€Î¿Î»Î¹Ï„Î¹ÎºÏÎ½ Î±Ï€ÏŒ trial-and-error
        - Sim-to-real transfer
        - Î Î±ÏÎ±Î´ÎµÎ¯Î³Î¼Î±Ï„Î±: Grasping, locomotion
        
        **2. Imitation Learning**
        - ÎœÎ¬Î¸Î·ÏƒÎ· Î±Ï€ÏŒ demonstrations
        - Learning from human experts
        
        **3. Multi-Agent Systems**
        - Î£Ï…Î½Ï„Î¿Î½Î¹ÏƒÎ¼ÏŒÏ‚ Ï€Î¿Î»Î»Î±Ï€Î»ÏÎ½ ÏÎ¿Î¼Ï€ÏŒÏ„
        - Swarm robotics
        
        **4. Sim-to-Real**
        - Training ÏƒÎµ simulation
        - Transfer ÏƒÎµ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏŒ ÎºÏŒÏƒÎ¼Î¿
        - Domain randomization
        
        #### ğŸ› ï¸ Platforms ÎºÎ±Î¹ Tools
        
        **Simulation:**
        - **Gazebo**: Robot simulation
        - **V-REP/CoppeliaSim**: Robot simulator
        - **PyBullet**: Physics simulation
        - **CARLA**: Autonomous driving simulator
        - **AirSim**: Drone and vehicle simulator
        
        **Frameworks:**
        - **ROS** (Robot Operating System): Middleware
        - **ROS 2**: Next-gen ROS
        - **OpenCV**: Computer vision
        - **PCL**: Point Cloud Library (3D data)
        
        **Hardware:**
        - **Raspberry Pi**: Low-cost computing
        - **NVIDIA Jetson**: Edge AI computing
        - **Arduino**: Microcontroller Î³Î¹Î± actuators/sensors
        
        #### ğŸš§ Î ÏÎ¿ÎºÎ»Î®ÏƒÎµÎ¹Ï‚
        
        - **Real-world Uncertainty**: Unpredictable Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½Ï„Î±
        - **Safety**: Î‘ÏƒÏ†Î¬Î»ÎµÎ¹Î± Î±Î½Î¸ÏÏÏ€Ï‰Î½
        - **Generalization**: Î›ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¯Î± ÏƒÎµ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¬ Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½Ï„Î±
        - **Power Consumption**: Battery life
        - **Cost**: Î‘ÎºÏÎ¹Î²Î¬ sensors ÎºÎ±Î¹ hardware
        - **Ethics**: Î‘Ï…Ï„Î¿Î½Î¿Î¼Î¯Î± ÎºÎ±Î¹ ÎµÏ…Î¸ÏÎ½Î·
        
        #### ğŸ”® ÎœÎ­Î»Î»Î¿Î½ Ï„Î·Ï‚ Î¡Î¿Î¼Ï€Î¿Ï„Î¹ÎºÎ®Ï‚
        
        - **General-purpose Robots**: Î¡Î¿Î¼Ï€ÏŒÏ„ Ï€Î¿Ï… ÎºÎ¬Î½Î¿Ï…Î½ Ï€Î¿Î»Î»Î­Ï‚ ÎµÏÎ³Î±ÏƒÎ¯ÎµÏ‚
        - **Soft Robotics**: Î•Ï…Î­Î»Î¹ÎºÏ„Î±, Î±ÏƒÏ†Î±Î»Î® Ï…Î»Î¹ÎºÎ¬
        - **Bio-inspired Robotics**: ÎœÎ¯Î¼Î·ÏƒÎ· Ï†ÏÏƒÎ·Ï‚
        - **Nanorobots**: Î™Î±Ï„ÏÎ¹ÎºÎ­Ï‚ ÎµÏ†Î±ÏÎ¼Î¿Î³Î­Ï‚ ÏƒÎµ ÎºÏ…Ï„Ï„Î±ÏÎ¹ÎºÏŒ ÎµÏ€Î¯Ï€ÎµÎ´Î¿
        - **Space Exploration**: Î¡Î¿Î¼Ï€ÏŒÏ„ Î³Î¹Î± exploration Î¬Î»Î»Ï‰Î½ Ï€Î»Î±Î½Î·Ï„ÏÎ½
        """)
    
    st.markdown('---')
    
    st.markdown('---')
    section_title('1.2 ÎšÏÏÎ¹Î± Î”Î¿Î¼Î¹ÎºÎ¬ Î£Ï„Î¿Î¹Ï‡ÎµÎ¯Î± Ï„Î·Ï‚ Î¤ÎµÏ‡Î½Î·Ï„Î®Ï‚ ÎÎ¿Î·Î¼Î¿ÏƒÏÎ½Î·Ï‚')
    
    st.markdown("ÎšÎ¬Î½Ï„Îµ ÎºÎ»Î¹Îº ÏƒÎµ ÎºÎ¬Î¸Îµ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î¿ Î³Î¹Î± Î½Î± Î¼Î¬Î¸ÎµÏ„Îµ Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎ±:")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown("### ğŸ“Š Î”ÎµÎ´Î¿Î¼Î­Î½Î±")
        concept_explainer(
            "Î”ÎµÎ´Î¿Î¼Î­Î½Î± (Data)",
            "Î¤Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÎµÎ¯Î½Î±Î¹ Î· **Î¸ÎµÎ¼ÎµÎ»Î¹ÏÎ´Î·Ï‚ Î²Î¬ÏƒÎ·** ÎºÎ¬Î¸Îµ AI ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î¿Ï‚. Î§Ï‰ÏÎ¯Ï‚ Ï€Î¿Î¹Î¿Ï„Î¹ÎºÎ¬ Î´ÎµÎ´Î¿Î¼Î­Î½Î±, Î±ÎºÏŒÎ¼Î± ÎºÎ±Î¹ Î¿ ÎºÎ±Î»ÏÏ„ÎµÏÎ¿Ï‚ Î±Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Ï‚ Î¸Î± Î±Ï€Î¿Ï„ÏÏ‡ÎµÎ¹.",
            """
            **Î¤ÏÏ€Î¿Î¹ Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½:**
            - **Structured Data**: Î Î¯Î½Î±ÎºÎµÏ‚, Î²Î¬ÏƒÎµÎ¹Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ (Ï€.Ï‡. CSV, SQL)
            - **Unstructured Data**: ÎšÎµÎ¯Î¼ÎµÎ½Î¿, ÎµÎ¹ÎºÏŒÎ½ÎµÏ‚, Î²Î¯Î½Ï„ÎµÎ¿, Î®Ï‡Î¿Ï‚
            - **Semi-structured Data**: JSON, XML
            
            **Î Î¿Î¹ÏŒÏ„Î·Ï„Î± Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½:**
            - **Accuracy**: Î‘ÎºÏÎ¯Î²ÎµÎ¹Î± ÎºÎ±Î¹ Î¿ÏÎ¸ÏŒÏ„Î·Ï„Î±
            - **Completeness**: Î Î»Î·ÏÏŒÏ„Î·Ï„Î± (Ï‡Ï‰ÏÎ¯Ï‚ missing values)
            - **Consistency**: Î£Ï…Î½Î­Ï€ÎµÎ¹Î± Î¼ÎµÏ„Î±Î¾Ï Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÏÎ½ Ï€Î·Î³ÏÎ½
            - **Timeliness**: Î•Ï€Î¹ÎºÎ±Î¹ÏÏŒÏ„Î·Ï„Î±
            - **Relevance**: Î£Ï‡ÎµÏ„Î¹ÎºÏŒÏ„Î·Ï„Î± Î¼Îµ Ï„Î¿ Ï€ÏÏŒÎ²Î»Î·Î¼Î±
            
            **Data Pipeline:**
            1. **Collection**: Î£Ï…Î»Î»Î¿Î³Î® Î±Ï€ÏŒ Ï€Î·Î³Î­Ï‚
            2. **Cleaning**: ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ (Î±Ï†Î±Î¯ÏÎµÏƒÎ· duplicates, outliers)
            3. **Preprocessing**: Normalization, transformation
            4. **Augmentation**: Î¤ÎµÏ‡Î½Î·Ï„Î® Î±ÏÎ¾Î·ÏƒÎ· dataset
            5. **Storage**: Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· (Data Lakes, Warehouses)
            """,
            """
            - **Netflix**: 100+ million Ï‡ÏÎ®ÏƒÏ„ÎµÏ‚, Î´Î¹ÏƒÎµÎºÎ±Ï„Î¿Î¼Î¼ÏÏÎ¹Î± interactions
            - **Tesla**: Î•ÎºÎ±Ï„Î¿Î¼Î¼ÏÏÎ¹Î± miles Î±Ï€ÏŒ Î±Ï…Ï„ÏŒÎ½Î¿Î¼Î· Î¿Î´Î®Î³Î·ÏƒÎ·
            - **Google**: Î¤ÏÎ¹ÏƒÎµÎºÎ±Ï„Î¿Î¼Î¼ÏÏÎ¹Î± Î±Î½Î±Î¶Î·Ï„Î®ÏƒÎµÎ¹Ï‚ ÎµÏ„Î·ÏƒÎ¯Ï‰Ï‚
            - **Healthcare**: Î™Î±Ï„ÏÎ¹ÎºÎ­Ï‚ ÎµÎ¹ÎºÏŒÎ½ÎµÏ‚, patient records
            """
        )
    
    with col2:
        st.markdown("### âš™ï¸ Î‘Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Î¹")
        concept_explainer(
            "Î‘Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Î¹ (Algorithms)",
            "ÎŸÎ¹ Î±Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Î¹ ÎµÎ¯Î½Î±Î¹ Î¿Î¹ **Î¼Î±Î¸Î·Î¼Î±Ï„Î¹ÎºÎ­Ï‚ Î¼Î­Î¸Î¿Î´Î¿Î¹** Ï€Î¿Ï… Î¼ÎµÏ„Î±Ï„ÏÎ­Ï€Î¿Ï…Î½ Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÏƒÎµ Ï‡ÏÎ®ÏƒÎ¹Î¼ÎµÏ‚ Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚ ÎºÎ±Î¹ insights.",
            """
            **ÎšÎ±Ï„Î·Î³Î¿ÏÎ¯ÎµÏ‚ Î‘Î»Î³Î¿ÏÎ¯Î¸Î¼Ï‰Î½:**
            
            **1. Supervised Learning:**
            - **Regression**: Linear, Polynomial, Ridge, Lasso
            - **Classification**: Logistic Regression, SVM, Decision Trees, Random Forest, XGBoost
            - **Neural Networks**: Feedforward, CNN, RNN
            
            **2. Unsupervised Learning:**
            - **Clustering**: K-Means, DBSCAN, Hierarchical
            - **Dimensionality Reduction**: PCA, t-SNE, UMAP
            - **Anomaly Detection**: Isolation Forest, One-Class SVM
            
            **3. Reinforcement Learning:**
            - **Q-Learning**: Value-based methods
            - **Policy Gradients**: REINFORCE, PPO, A3C
            - **Deep RL**: DQN, DDPG, SAC
            
            **Î•Ï€Î¹Î»Î¿Î³Î® Î‘Î»Î³Î¿ÏÎ¯Î¸Î¼Î¿Ï…:**
            - Î¤ÏÏ€Î¿Ï‚ Ï€ÏÎ¿Î²Î»Î®Î¼Î±Ï„Î¿Ï‚ (classification, regression, clustering)
            - ÎœÎ­Î³ÎµÎ¸Î¿Ï‚ dataset
            - Interpretability requirements
            - Computational resources
            - Real-time constraints
            """,
            """
            - **Linear Regression**: Î ÏÏŒÎ²Î»ÎµÏˆÎ· Ï„Î¹Î¼ÏÎ½ Î±ÎºÎ¹Î½Î®Ï„Ï‰Î½
            - **Random Forest**: Credit scoring
            - **CNN**: Face recognition
            - **LSTM**: Stock price prediction
            - **Q-Learning**: Game playing AI
            """
        )
    
    with col3:
        st.markdown("### ğŸ¯ ÎœÎ¿Î½Ï„Î­Î»Î±")
        concept_explainer(
            "ÎœÎ¿Î½Ï„Î­Î»Î± (Models)",
            "Î¤Î± Î¼Î¿Î½Ï„Î­Î»Î± ÎµÎ¯Î½Î±Î¹ Ï„Î± **ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Î¼Î­Î½Î± ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î±** Ï€Î¿Ï… Ï€ÏÎ¿ÎºÏÏ€Ï„Î¿Ï…Î½ Î±Ï€ÏŒ Ï„Î·Î½ ÎµÏ†Î±ÏÎ¼Î¿Î³Î® Î±Î»Î³Î¿ÏÎ¯Î¸Î¼Ï‰Î½ ÏƒÎµ Î´ÎµÎ´Î¿Î¼Î­Î½Î±.",
            """
            **Lifecycle ÎœÎ¿Î½Ï„Î­Î»Î¿Ï…:**
            
            **1. Training Phase:**
            - Feature engineering
            - Model selection
            - Hyperparameter tuning
            - Cross-validation
            - Training data split (train/validation/test)
            
            **2. Evaluation Phase:**
            - Performance metrics (Accuracy, Precision, Recall, F1, AUC)
            - Confusion matrix analysis
            - Learning curves
            - Error analysis
            
            **3. Deployment Phase:**
            - Model serialization (pickle, ONNX, TensorFlow SavedModel)
            - API creation (REST, gRPC)
            - Containerization (Docker)
            - Cloud deployment (AWS SageMaker, Azure ML, Google Vertex AI)
            
            **4. Monitoring Phase:**
            - Performance tracking
            - Data drift detection
            - Model retraining triggers
            - A/B testing
            
            **Model Types:**
            - **White-box**: Interpretable (Linear models, Decision Trees)
            - **Black-box**: High performance (Deep Neural Networks, Ensemble methods)
            - **Gray-box**: Balanced (XGBoost Î¼Îµ SHAP values)
            """,
            """
            - **GPT-4**: 175B+ parameters, text generation
            - **YOLOv8**: Real-time object detection
            - **BERT**: Language understanding
            - **AlphaFold**: Protein structure prediction
            - **Stable Diffusion**: Image generation
            """
        )
    
    with col4:
        st.markdown("### ğŸ’» Î¥Ï€Î¿Î´Î¿Î¼Î­Ï‚")
        concept_explainer(
            "Î¥Ï€Î¿Î´Î¿Î¼Î­Ï‚ (Infrastructure)",
            "Î— Ï…Ï€Î¿Î´Î¿Î¼Î® Ï€ÎµÏÎ¹Î»Î±Î¼Î²Î¬Î½ÎµÎ¹ Ï„Î¿ **hardware ÎºÎ±Î¹ software** Ï€Î¿Ï… Î±Ï€Î±Î¹Ï„Î¿ÏÎ½Ï„Î±Î¹ Î³Î¹Î± training ÎºÎ±Î¹ deployment AI Î¼Î¿Î½Ï„Î­Î»Ï‰Î½.",
            """
            **Hardware:**
            
            **1. CPUs (Central Processing Units)**:
            - General-purpose computing
            - Preprocessing, data loading
            - Inference Î³Î¹Î± Î±Ï€Î»Î¬ Î¼Î¿Î½Ï„Î­Î»Î±
            
            **2. GPUs (Graphics Processing Units)**:
            - **NVIDIA**: A100, V100, RTX 4090
            - Parallel processing (1000s of cores)
            - Deep learning training
            - Speedup: 10-100x vs CPU
            
            **3. TPUs (Tensor Processing Units)**:
            - Google's custom AI chips
            - Optimized Î³Î¹Î± matrix operations
            - Used in Google Cloud
            - Speedup: 15-30x vs GPUs
            
            **4. NPUs (Neural Processing Units)**:
            - Mobile devices (Apple Neural Engine, Qualcomm Hexagon)
            - Edge computing
            - Low power consumption
            
            **Software:**
            
            **Frameworks:**
            - TensorFlow, PyTorch, JAX
            - Keras, MXNet, PaddlePaddle
            
            **Cloud Platforms:**
            - **AWS**: SageMaker, EC2 P4d instances
            - **Google Cloud**: Vertex AI, TPU pods
            - **Azure**: Machine Learning, GPU VMs
            - **Specialized**: Lambda Labs, Paperspace, Vast.ai
            
            **MLOps Tools:**
            - **Experiment Tracking**: MLflow, Weights & Biases, Neptune
            - **Model Versioning**: DVC, Git LFS
            - **Deployment**: Docker, Kubernetes, KubeFlow
            - **Monitoring**: Prometheus, Grafana, Evidently AI
            
            **Storage:**
            - **S3, Google Cloud Storage**: Data lakes
            - **Databases**: PostgreSQL, MongoDB, Elasticsearch
            - **Feature Stores**: Feast, Tecton
            """,
            """
            **ÎšÏŒÏƒÏ„Î¿Ï‚ Training:**
            - **GPT-3 Training**: ~$4.6M (estimated)
            - **Stable Diffusion**: ~$600K
            - **BERT-base**: ~$7K
            
            **Cloud Options:**
            - **Google Colab**: Free GPU/TPU Î³Î¹Î± ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·
            - **Kaggle Kernels**: Free GPU
            - **AWS Free Tier**: Limited credits
            """
        )
    
    st.markdown('---')
    
    st.markdown('---')
    section_title('1.3 Î’Î±ÏƒÎ¹ÎºÎ¬ Î™ÏƒÏ„Î¿ÏÎ¹ÎºÎ¬ Î•Ï€Î¹Ï„ÎµÏÎ³Î¼Î±Ï„Î± ÏƒÏ„Î¿ Î§ÏÏÎ¿ Ï„Î·Ï‚ Î¤ÎµÏ‡Î½Î·Ï„Î®Ï‚ ÎÎ¿Î·Î¼Î¿ÏƒÏÎ½Î·Ï‚')
    
    timeline_data = {
        'ÎˆÏ„Î¿Ï‚': ['1950', '1956', '1997', '2011', '2012', '2016', '2018', '2020', '2022'],
        'Î“ÎµÎ³Î¿Î½ÏŒÏ‚': [
            'Turing Test',
            'Dartmouth Conference - Î“Î­Î½Î½Î·ÏƒÎ· Ï„Î·Ï‚ AI',
            'Deep Blue Î½Î¹ÎºÎ¬ Ï„Î¿Î½ Kasparov',
            'Watson Î½Î¹ÎºÎ¬ ÏƒÏ„Î¿ Jeopardy',
            'AlexNet - Deep Learning Revolution',
            'AlphaGo Î½Î¹ÎºÎ¬ Ï„Î¿Î½ Lee Sedol',
            'GPT-2 - Î“Î»Ï‰ÏƒÏƒÎ¹ÎºÎ¬ Î¼Î¿Î½Ï„Î­Î»Î±',
            'GPT-3 - 175 billion Ï€Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹',
            'ChatGPT - ÎœÎ±Î¶Î¹ÎºÎ® Ï…Î¹Î¿Î¸Î­Ï„Î·ÏƒÎ· AI'
        ]
    }
    
    df_timeline = pd.DataFrame(timeline_data)
    st.dataframe(df_timeline, use_container_width=True, hide_index=True)
    
    with st.expander('ğŸ“– Î”Î¹Î±Î²Î¬ÏƒÏ„Îµ Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎ± Î³Î¹Î± Ï„Î·Î½ Î¹ÏƒÏ„Î¿ÏÎ¯Î±'):
        st.markdown("""
        **1950 - Alan Turing**: Î ÏÏŒÏ„ÎµÎ¹Î½Îµ Ï„Î¿ Turing Test Î³Î¹Î± Î½Î± Î±Î¾Î¹Î¿Î»Î¿Î³Î®ÏƒÎµÎ¹ Î±Î½ Î¼Î¹Î± Î¼Î·Ï‡Î±Î½Î® Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± ÏƒÎºÎ­Ï†Ï„ÎµÏ„Î±Î¹.
        
        **1956 - Dartmouth Conference**: ÎŸ John McCarthy ÎµÏ€Î¹Î½ÏŒÎ·ÏƒÎµ Ï„Î¿Î½ ÏŒÏÎ¿ "Artificial Intelligence".
        
        **1997**: Î¤Î¿ Deep Blue Ï„Î·Ï‚ IBM Î½Î¯ÎºÎ·ÏƒÎµ Ï„Î¿Î½ Ï€Î±Î³ÎºÏŒÏƒÎ¼Î¹Î¿ Ï€ÏÏ‰Ï„Î±Î¸Î»Î·Ï„Î® ÏƒÎºÎ±ÎºÎ¹Î¿Ï Garry Kasparov.
        
        **2012**: Î— ÎµÏ€Î±Î½Î¬ÏƒÏ„Î±ÏƒÎ· Ï„Î¿Ï… Deep Learning Î¼Îµ Ï„Î¿ AlexNet Ï€Î¿Ï… Î½Î¯ÎºÎ·ÏƒÎµ ÏƒÏ„Î¿ ImageNet competition.
        
        **2022-ÏƒÎ®Î¼ÎµÏÎ±**: Î— ÎµÏ€Î¿Ï‡Î® Ï„Ï‰Î½ Large Language Models Î¼Îµ ChatGPT Î½Î± Ï†Î­ÏÎ½ÎµÎ¹ Ï„Î·Î½ AI ÏƒÏ„Î·Î½ ÎºÎ±Î¸Î·Î¼ÎµÏÎ¹Î½ÏŒÏ„Î·Ï„Î±.
        """)
    
    st.markdown('---')
    section_title('1.4 Î¤ÎµÏ‡Î½Î·Ï„Î® ÎÎ¿Î·Î¼Î¿ÏƒÏÎ½Î·: Î•Ï†Î±ÏÎ¼Î¿Î³Î­Ï‚ ÎºÎ±Î¹ Î•Î¾ÎµÎ»Î¯Î¾ÎµÎ¹Ï‚')
    
    app_col1, app_col2 = st.columns(2)
    with app_col1:
        st.markdown("""
        #### ğŸ¥ Î¥Î³ÎµÎ¯Î±
        - Î”Î¹Î¬Î³Î½Ï‰ÏƒÎ· Î±ÏƒÎ¸ÎµÎ½ÎµÎ¹ÏÎ½ Î±Ï€ÏŒ Î¹Î±Ï„ÏÎ¹ÎºÎ­Ï‚ ÎµÎ¹ÎºÏŒÎ½ÎµÏ‚
        - Î‘Î½Î±ÎºÎ¬Î»Ï…ÏˆÎ· Î½Î­Ï‰Î½ Ï†Î±ÏÎ¼Î¬ÎºÏ‰Î½
        - Î ÏÎ¿ÏƒÏ‰Ï€Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î· Î¹Î±Ï„ÏÎ¹ÎºÎ®
        - Î ÏÏŒÎ²Î»ÎµÏˆÎ· ÎµÏ€Î¹Î´Î·Î¼Î¹ÏÎ½
        
        #### ğŸš— ÎœÎµÏ„Î±Ï†Î¿ÏÎ­Ï‚
        - Î‘Ï…Ï„ÏŒÎ½Î¿Î¼Î± Î¿Ï‡Î®Î¼Î±Ï„Î±
        - Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î´Î¹Î±Î´ÏÎ¿Î¼ÏÎ½
        - ÎˆÎ¾Ï…Ï€Î½Î· Î´Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· ÎºÏ…ÎºÎ»Î¿Ï†Î¿ÏÎ¯Î±Ï‚
        - Î ÏÎ¿Î²Î»ÎµÏ€Ï„Î¹ÎºÎ® ÏƒÏ…Î½Ï„Î®ÏÎ·ÏƒÎ·
        """)
    with app_col2:
        st.markdown("""
        #### ğŸ’° Î§ÏÎ·Î¼Î±Ï„Î¿Î¿Î¹ÎºÎ¿Î½Î¿Î¼Î¹ÎºÎ¬
        - Î‘Î½Î¯Ï‡Î½ÎµÏ…ÏƒÎ· Î±Ï€Î¬Ï„Î·Ï‚
        - Î‘Î»Î³Î¿ÏÎ¹Î¸Î¼Î¹ÎºÎ® Î´Î¹Î±Ï€ÏÎ±Î³Î¼Î¬Ï„ÎµÏ…ÏƒÎ·
        - Î Î¹ÏƒÏ„Î¿Î´Î¿Ï„Î¹ÎºÏŒÏ‚ Î­Î»ÎµÎ³Ï‡Î¿Ï‚
        - Robo-advisors
        
        #### ğŸ“ Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·
        - Î ÏÎ¿ÏƒÏ‰Ï€Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î· Î¼Î¬Î¸Î·ÏƒÎ·
        - Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î· Î²Î±Î¸Î¼Î¿Î»ÏŒÎ³Î·ÏƒÎ·
        - Î•Î¹ÎºÎ¿Î½Î¹ÎºÎ¿Î¯ Î²Î¿Î·Î¸Î¿Î¯ Î´Î¹Î´Î±ÏƒÎºÎ±Î»Î¯Î±Ï‚
        - Î ÏÎ¿ÏƒÎ²Î±ÏƒÎ¹Î¼ÏŒÏ„Î·Ï„Î±
        """)
    
    st.markdown('---')
    section_title('1.5 Î’Î±ÏƒÎ¹ÎºÎ­Ï‚ ÎˆÎ½Î½Î¿Î¹ÎµÏ‚ â€” Î Î»Î±Î¯ÏƒÎ¹Î¿ â€” ÎšÎ±Î½ÏŒÎ½ÎµÏ‚')
    
    subsection_title('1.5.1 Î’Î±ÏƒÎ¹ÎºÎ­Ï‚ ÎˆÎ½Î½Î¿Î¹ÎµÏ‚')
    
    concepts_col1, concepts_col2, concepts_col3 = st.columns(3)
    with concepts_col1:
        st.markdown("""
        **Î•Ï€Î¹Î²Î»ÎµÏ€ÏŒÎ¼ÎµÎ½Î· ÎœÎ¬Î¸Î·ÏƒÎ·**
        (Supervised Learning)
        - Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Î¼Îµ labeled data
        - Î ÏÏŒÎ²Î»ÎµÏˆÎ· outcomes
        - Î Î±ÏÎ±Î´ÎµÎ¯Î³Î¼Î±Ï„Î±: Î¤Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ·, Regression
        """)
    with concepts_col2:
        st.markdown("""
        **ÎœÎ· Î•Ï€Î¹Î²Î»ÎµÏ€ÏŒÎ¼ÎµÎ½Î· ÎœÎ¬Î¸Î·ÏƒÎ·**
        (Unsupervised Learning)
        - Î‘Î½Î±ÎºÎ¬Î»Ï…ÏˆÎ· patterns
        - Clustering
        - Î Î±ÏÎ±Î´ÎµÎ¯Î³Î¼Î±Ï„Î±: K-Means, PCA
        """)
    with concepts_col3:
        st.markdown("""
        **Î•Î½Î¹ÏƒÏ‡Ï…Ï„Î¹ÎºÎ® ÎœÎ¬Î¸Î·ÏƒÎ·**
        (Reinforcement Learning)
        - ÎœÎ¬Î¸Î·ÏƒÎ· Î¼Î­ÏƒÏ‰ Î´Î¿ÎºÎ¹Î¼Î®Ï‚-Î»Î¬Î¸Î¿Ï…Ï‚
        - Rewards/Penalties
        - Î Î±ÏÎ±Î´ÎµÎ¯Î³Î¼Î±Ï„Î±: Gaming AI, Î¡Î¿Î¼Ï€Î¿Ï„Î¹ÎºÎ®
        """)
    
    subsection_title('1.5.2 Î Î»Î±Î¯ÏƒÎ¹Î¿ Î•Ï†Î±ÏÎ¼Î¿Î³Î®Ï‚')
    st.markdown("""
    Î— AI ÎµÏ†Î±ÏÎ¼ÏŒÎ¶ÎµÏ„Î±Î¹ ÏƒÎµ Î´Î¹Î¬Ï†Î¿ÏÎ± Ï€Î»Î±Î¯ÏƒÎ¹Î±:
    - **Î•ÏÎµÏ…Î½Î·Ï„Î¹ÎºÏŒ**: Î‘Î½Î¬Ï€Ï„Ï…Î¾Î· Î½Î­Ï‰Î½ Î±Î»Î³Î¿ÏÎ¯Î¸Î¼Ï‰Î½ ÎºÎ±Î¹ Ï„ÎµÏ‡Î½Î¹ÎºÏÎ½
    - **Î’Î¹Î¿Î¼Î·Ï‡Î±Î½Î¹ÎºÏŒ**: Î Î±ÏÎ±Î³Ï‰Î³Î¹ÎºÎ­Ï‚ ÎµÏ†Î±ÏÎ¼Î¿Î³Î­Ï‚ ÏƒÎµ ÎµÏ€Î¹Ï‡ÎµÎ¹ÏÎ®ÏƒÎµÎ¹Ï‚
    - **ÎšÎ¿Î¹Î½Ï‰Î½Î¹ÎºÏŒ**: Î•Ï€Î¯Î»Ï…ÏƒÎ· ÎºÎ¿Î¹Î½Ï‰Î½Î¹ÎºÏÎ½ Ï€ÏÎ¿Î²Î»Î·Î¼Î¬Ï„Ï‰Î½
    - **Î•ÎºÏ€Î±Î¹Î´ÎµÏ…Ï„Î¹ÎºÏŒ**: ÎœÎ¬Î¸Î·ÏƒÎ· ÎºÎ±Î¹ ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·
    """)
    
    subsection_title('1.5.3 ÎšÎ±Î½ÏŒÎ½ÎµÏ‚ ÎºÎ±Î¹ Î—Î¸Î¹ÎºÎ®')
    st.warning("""
    âš ï¸ **Î—Î¸Î¹ÎºÎ­Ï‚ Î‘ÏÏ‡Î­Ï‚ ÏƒÏ„Î·Î½ AI**:
    - Î”Î¹Î±Ï†Î¬Î½ÎµÎ¹Î± (Transparency)
    - Î”Î¹ÎºÎ±Î¹Î¿ÏƒÏÎ½Î· (Fairness)  
    - Î™Î´Î¹Ï‰Ï„Î¹ÎºÏŒÏ„Î·Ï„Î± (Privacy)
    - Î‘ÏƒÏ†Î¬Î»ÎµÎ¹Î± (Safety)
    - Î›Î¿Î³Î¿Î´Î¿ÏƒÎ¯Î± (Accountability)
    """)
    
    st.markdown('---')
    section_title('1.6 Î ÏÏ‚ Î›ÎµÎ¹Ï„Î¿Ï…ÏÎ³ÎµÎ¯ Ï„Î¿ ChatGPT')
    
    st.markdown("""
    ### ğŸ¤– Î¤Î¿ ChatGPT ÎµÎ¯Î½Î±Î¹ Î­Î½Î± Large Language Model (LLM)
    
    **Î’Î±ÏƒÎ¹ÎºÎ¬ Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬:**
    """)
    
    chatgpt_col1, chatgpt_col2 = st.columns(2)
    with chatgpt_col1:
        st.markdown("""
        **Î‘ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ®:**
        - ğŸ”„ Î’Î±ÏƒÎ¯Î¶ÎµÏ„Î±Î¹ ÏƒÏ„Î·Î½ Î±ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ® **Transformer**
        - ğŸ“Š Î•ÎºÏ€Î±Î¹Î´ÎµÏ…Î¼Î­Î½Î¿ ÏƒÎµ Ï„ÎµÏÎ¬ÏƒÏ„Î¹Î¿ ÏŒÎ³ÎºÎ¿ ÎºÎµÎ¹Î¼Î­Î½Ï‰Î½
        - ğŸ§® Î”Î¹ÏƒÎµÎºÎ±Ï„Î¿Î¼Î¼ÏÏÎ¹Î± Ï€Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹
        - ğŸ¯ Fine-tuned Î¼Îµ RLHF (Reinforcement Learning from Human Feedback)
        
        **Î›ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¯Î±:**
        1. Î›Î±Î¼Î²Î¬Î½ÎµÎ¹ Ï„Î¿ input (prompt)
        2. Î¤Î¿ Î¼ÎµÏ„Î±Ï„ÏÎ­Ï€ÎµÎ¹ ÏƒÎµ tokens
        3. Î•Ï€ÎµÎ¾ÎµÏÎ³Î¬Î¶ÎµÏ„Î±Î¹ Î¼Î­ÏƒÏ‰ transformer layers
        4. Î ÏÎ¿Î²Î»Î­Ï€ÎµÎ¹ Ï„Î¿ ÎµÏ€ÏŒÎ¼ÎµÎ½Î¿ token
        5. Î Î±ÏÎ¬Î³ÎµÎ¹ ÏƒÏ…Î½ÎµÏ‡Î® ÎºÎµÎ¯Î¼ÎµÎ½Î¿
        """)
    with chatgpt_col2:
        st.markdown("""
        **Î”Ï…Î½Î±Ï„ÏŒÏ„Î·Ï„ÎµÏ‚:**
        - âœï¸ Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÎºÎµÎ¹Î¼Î­Î½Î¿Ï…
        - ğŸ’¬ Î£Ï…Î½Î¿Î¼Î¹Î»Î¯Î±
        - ğŸ“ Î£ÏÎ½Î¿ÏˆÎ·
        - ğŸ”„ ÎœÎµÏ„Î¬Ï†ÏÎ±ÏƒÎ·
        - ğŸ’» Î ÏÎ¿Î³ÏÎ±Î¼Î¼Î±Ï„Î¹ÏƒÎ¼ÏŒÏ‚
        - ğŸ¨ Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¹ÎºÏŒÏ„Î·Ï„Î±
        - ğŸ“Š Î‘Î½Î¬Î»Ï…ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
        
        **Î ÎµÏÎ¹Î¿ÏÎ¹ÏƒÎ¼Î¿Î¯:**
        - âš ï¸ ÎœÏ€Î¿ÏÎµÎ¯ Î½Î± Ï€Î±ÏÎ¬Î³ÎµÎ¹ Î»Î¬Î¸Î·
        - ğŸ“… Cutoff date Î³Î½ÏÏƒÎ·Ï‚
        - ğŸ” Î”ÎµÎ½ Î±Î½Î±Î¶Î·Ï„Î¬ ÏƒÏ„Î¿ internet (GPT-3.5/4 base)
        - ğŸ¤” Î”ÎµÎ½ ÎºÎ±Ï„Î±Î½Î¿ÎµÎ¯ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ¬
        """)
    
    with st.expander('ğŸ”¬ Î¤ÎµÏ‡Î½Î¹ÎºÎ­Ï‚ Î›ÎµÏ€Ï„Î¿Î¼Î­ÏÎµÎ¹ÎµÏ‚'):
        st.markdown("""
        **Pre-training:**
        - Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· ÏƒÎµ Ï„ÎµÏÎ¬ÏƒÏ„Î¹Î± datasets
        - Unsupervised learning
        - Next token prediction
        
        **Fine-tuning:**
        - Supervised fine-tuning (SFT)
        - Reinforcement Learning from Human Feedback (RLHF)
        - Alignment Î¼Îµ Î±Î½Î¸ÏÏÏ€Î¹Î½ÎµÏ‚ Ï€ÏÎ¿Ï„Î¹Î¼Î®ÏƒÎµÎ¹Ï‚
        
        **Transformer Architecture:**
        ```
        Input â†’ Tokenization â†’ Embeddings â†’ 
        Multi-Head Attention â†’ Feed Forward â†’ 
        Output Layer â†’ Generated Text
        ```
        """)
    
    st.markdown('---')
    section_title('1.7 Î’Î±ÏƒÎ¹ÎºÎ­Ï‚ Î‘ÏÏ‡Î­Ï‚ AI ÎºÎ±Î¹ Î•Ï†Î±ÏÎ¼Î¿Î³Î­Ï‚')
    
    subsection_title('1.7.1 Machine Learning ÎºÎ±Î¹ Deep Learning')
    
    ml_col1, ml_col2 = st.columns(2)
    with ml_col1:
        st.markdown("""
        **Machine Learning (ML)**
        
        Î•Î¯Î½Î±Î¹ Î· Î¹ÎºÎ±Î½ÏŒÏ„Î·Ï„Î± Ï„Ï‰Î½ Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÏ„ÏÎ½ Î½Î± Î¼Î±Î¸Î±Î¯Î½Î¿Ï…Î½ Ï‡Ï‰ÏÎ¯Ï‚ Î½Î± Ï€ÏÎ¿Î³ÏÎ±Î¼Î¼Î±Ï„Î¯Î¶Î¿Î½Ï„Î±Î¹ ÏÎ·Ï„Î¬.
        
        **Î¤ÏÏ€Î¿Î¹:**
        1. **Supervised Learning**
           - Classification
           - Regression
           
        2. **Unsupervised Learning**
           - Clustering
           - Dimensionality Reduction
           
        3. **Reinforcement Learning**
           - Agent-based learning
           - Rewards optimization
        """)
    with ml_col2:
        st.markdown("""
        **Deep Learning (DL)**
        
        Î¥Ï€Î¿ÏƒÏÎ½Î¿Î»Î¿ Ï„Î¿Ï… ML Ï€Î¿Ï… Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯ Î½ÎµÏ…ÏÏ‰Î½Î¹ÎºÎ¬ Î´Î¯ÎºÏ„Ï…Î± Î¼Îµ Ï€Î¿Î»Î»Î¬ ÎµÏ€Î¯Ï€ÎµÎ´Î± (layers).
        
        **Î‘ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ­Ï‚:**
        - **CNN** (Convolutional Neural Networks): Computer Vision
        - **RNN** (Recurrent Neural Networks): Sequences
        - **LSTM**: Long-term dependencies
        - **Transformers**: NLP, GPT, BERT
        - **GANs**: Generative models
        """)
    
    subsection_title('1.7.2 Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¹ÎºÎ® Î¤ÎµÏ‡Î½Î·Ï„Î® ÎÎ¿Î·Î¼Î¿ÏƒÏÎ½Î· (Generative AI)')
    
    st.markdown("""
    Î— **Generative AI** Î±Î½Î±Ï†Î­ÏÎµÏ„Î±Î¹ ÏƒÎµ Î¼Î¿Î½Ï„Î­Î»Î± Ï€Î¿Ï… Î¼Ï€Î¿ÏÎ¿ÏÎ½ Î½Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î®ÏƒÎ¿Ï…Î½ Î½Î­Î¿ Ï€ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿.
    
    **Î¤ÏÏ€Î¿Î¹ Generative AI:**
    """)
    
    gen_col1, gen_col2, gen_col3 = st.columns(3)
    with gen_col1:
        st.markdown("""
        **Text Generation**
        - GPT-4, ChatGPT
        - Claude
        - Gemini
        - LLaMA
        """)
    with gen_col2:
        st.markdown("""
        **Image Generation**
        - DALL-E
        - Midjourney
        - Stable Diffusion
        - Imagen
        """)
    with gen_col3:
        st.markdown("""
        **Other Modalities**
        - Music (MuseNet)
        - Video (Sora)
        - Voice (ElevenLabs)
        - Code (Copilot)
        """)
    
    subsection_title('1.7.3-1.7.7 Î•Ï†Î±ÏÎ¼Î¿Î³Î­Ï‚ AI ÏƒÎµ Î”Î¹Î¬Ï†Î¿ÏÎ¿Ï…Ï‚ Î¤Î¿Î¼ÎµÎ¯Ï‚')
    
    tab1, tab2, tab3, tab4, tab5 = st.tabs(['ğŸª Î Ï‰Î»Î®ÏƒÎµÎ¹Ï‚ & Marketing', 'ğŸ“ Î“ÏÎ±Î¼Î¼Î±Ï„ÎµÎ¯Î±', 'ğŸ’¼ Î•Ï€Î¹Ï‡ÎµÎ¹ÏÎ®ÏƒÎµÎ¹Ï‚', 'ğŸ’µ Î§ÏÎ·Î¼Î±Ï„Î¿Î¿Î¹ÎºÎ¿Î½Î¿Î¼Î¹ÎºÎ¬', 'âš•ï¸ Î¥Î³ÎµÎ¯Î±'])
    
    with tab1:
        st.markdown("""
        **AI ÏƒÏ„Î¹Ï‚ Î Ï‰Î»Î®ÏƒÎµÎ¹Ï‚ ÎºÎ±Î¹ Marketing**
        
        - **Personalization**: Î•Î¾Î±Ï„Î¿Î¼Î¹ÎºÎµÏ…Î¼Î­Î½ÎµÏ‚ Ï€ÏÎ¿Ï„Î¬ÏƒÎµÎ¹Ï‚ Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Ï‰Î½
        - **Chatbots**: Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î· ÎµÎ¾Ï…Ï€Î·ÏÎ­Ï„Î·ÏƒÎ· Ï€ÎµÎ»Î±Ï„ÏÎ½ 24/7
        - **Predictive Analytics**: Î ÏÏŒÎ²Î»ÎµÏˆÎ· ÏƒÏ…Î¼Ï€ÎµÏÎ¹Ï†Î¿ÏÎ¬Ï‚ Ï€ÎµÎ»Î±Ï„ÏÎ½
        - **Content Generation**: Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î· Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î´Î¹Î±Ï†Î·Î¼Î¹ÏƒÏ„Î¹ÎºÎ¿Ï Ï€ÎµÏÎ¹ÎµÏ‡Î¿Î¼Î­Î½Î¿Ï…
        - **Email Marketing**: Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· campaigns
        - **Social Media**: Î‘Î½Î¬Î»Ï…ÏƒÎ· sentiment, targeting
        """)
    
    with tab2:
        st.markdown("""
        **AI ÏƒÏ„Î· Î“ÏÎ±Î¼Î¼Î±Ï„ÎµÎ¯Î± ÎºÎ±Î¹ Î”Î¹Î¿Î¹ÎºÎ·Ï„Î¹ÎºÎ¬ Î£Ï„ÎµÎ»Î­Ï‡Î·**
        
        - **ÎˆÎ¾Ï…Ï€Î½Î· Î”Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· Î•Î³Î³ÏÎ¬Ï†Ï‰Î½**: Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î· Ï„Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ· ÎºÎ±Î¹ Î±ÏÏ‡ÎµÎ¹Î¿Î¸Î­Ï„Î·ÏƒÎ·
        - **Scheduling**: ÎˆÎ¾Ï…Ï€Î½Î· Î´Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· Î·Î¼ÎµÏÎ¿Î»Î¿Î³Î¯Î¿Ï…
        - **Transcription**: ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® Î¿Î¼Î¹Î»Î¯Î±Ï‚ ÏƒÎµ ÎºÎµÎ¯Î¼ÎµÎ½Î¿
        - **Translation**: Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î· Î¼ÎµÏ„Î¬Ï†ÏÎ±ÏƒÎ· ÎµÎ³Î³ÏÎ¬Ï†Ï‰Î½
        - **Data Entry**: Î‘Ï…Ï„Î¿Î¼Î±Ï„Î¿Ï€Î¿Î¯Î·ÏƒÎ· ÎµÎ¹ÏƒÎ±Î³Ï‰Î³Î®Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
        """)
    
    with tab3:
        st.markdown("""
        **AI ÏƒÏ„Î· Î¨Î·Ï†Î¹Î±ÎºÎ® ÎœÎµÏ„Î±ÏƒÏ‡Î·Î¼Î±Ï„Î¹ÏƒÎ¼ÏŒ Î•Ï€Î¹Ï‡ÎµÎ¹ÏÎ®ÏƒÎµÏ‰Î½**
        
        - **Process Automation**: RPA (Robotic Process Automation)
        - **Decision Support**: Î¥Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· Î»Î®ÏˆÎ·Ï‚ Î±Ï€Î¿Ï†Î¬ÏƒÎµÏ‰Î½
        - **Supply Chain**: Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· ÎµÏ†Î¿Î´Î¹Î±ÏƒÏ„Î¹ÎºÎ®Ï‚ Î±Î»Ï…ÏƒÎ¯Î´Î±Ï‚
        - **Quality Control**: Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î¿Ï‚ Î­Î»ÎµÎ³Ï‡Î¿Ï‚ Ï€Î¿Î¹ÏŒÏ„Î·Ï„Î±Ï‚
        - **Predictive Maintenance**: Î ÏÎ¿Î²Î»ÎµÏ€Ï„Î¹ÎºÎ® ÏƒÏ…Î½Ï„Î®ÏÎ·ÏƒÎ· ÎµÎ¾Î¿Ï€Î»Î¹ÏƒÎ¼Î¿Ï
        """)
    
    with tab4:
        st.markdown("""
        **AI ÏƒÏ„Î± Î§ÏÎ·Î¼Î±Ï„Î¿Î¿Î¹ÎºÎ¿Î½Î¿Î¼Î¹ÎºÎ¬**
        
        - **Fraud Detection**: Î‘Î½Î¯Ï‡Î½ÎµÏ…ÏƒÎ· Î±Ï€Î¬Ï„Î·Ï‚ ÏƒÎµ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏŒ Ï‡ÏÏŒÎ½Î¿
        - **Algorithmic Trading**: Î‘Ï…Ï„Î¿Î¼Î±Ï„Î¿Ï€Î¿Î¹Î·Î¼Î­Î½ÎµÏ‚ ÏƒÏ…Î½Î±Î»Î»Î±Î³Î­Ï‚
        - **Credit Scoring**: Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· Ï€Î¹ÏƒÏ„Î¿Î»Î·Ï€Ï„Î¹ÎºÎ®Ï‚ Î¹ÎºÎ±Î½ÏŒÏ„Î·Ï„Î±Ï‚
        - **Risk Management**: Î”Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· ÎºÎ¹Î½Î´ÏÎ½Î¿Ï…
        - **Robo-Advisors**: Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î· ÎµÏ€ÎµÎ½Î´Ï…Ï„Î¹ÎºÎ® ÏƒÏ…Î¼Î²Î¿Ï…Î»ÎµÏ…Ï„Î¹ÎºÎ®
        """)
    
    with tab5:
        st.markdown("""
        **AI ÏƒÏ„Î·Î½ Î¥Î³ÎµÎ¯Î±**
        
        - **Medical Imaging**: Î”Î¹Î¬Î³Î½Ï‰ÏƒÎ· Î±Ï€ÏŒ Î±ÎºÏ„Î¹Î½Î¿Î³ÏÎ±Ï†Î¯ÎµÏ‚, CT, MRI
        - **Drug Discovery**: Î‘Î½Î±ÎºÎ¬Î»Ï…ÏˆÎ· Î½Î­Ï‰Î½ Ï†Î±ÏÎ¼Î¬ÎºÏ‰Î½
        - **Personalized Medicine**: Î•Î¾Î±Ï„Î¿Î¼Î¹ÎºÎµÏ…Î¼Î­Î½Î· Î¸ÎµÏÎ±Ï€ÎµÎ¯Î±
        - **Patient Monitoring**: Î Î±ÏÎ±ÎºÎ¿Î»Î¿ÏÎ¸Î·ÏƒÎ· Î±ÏƒÎ¸ÎµÎ½ÏÎ½
        - **Clinical Decision Support**: Î¥Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· Î¹Î±Ï„ÏÎ¹ÎºÏÎ½ Î±Ï€Î¿Ï†Î¬ÏƒÎµÏ‰Î½
        """)
    
    st.markdown('---')
    st.success("""
    ğŸ“ **Î£Ï…Î³Ï‡Î±ÏÎ·Ï„Î®ÏÎ¹Î±!** ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÏƒÎ±Ï„Îµ Ï„Î¿ Î¸ÎµÏ‰ÏÎ·Ï„Î¹ÎºÏŒ Î¼Î­ÏÎ¿Ï‚. Î£Ï…Î½ÎµÏ‡Î¯ÏƒÏ„Îµ Î¼Îµ Ï„Î± Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ¬ Ï€Î±ÏÎ±Î´ÎµÎ¯Î³Î¼Î±Ï„Î±!
    """)

with tabs[1]:
    section_title('Î Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î± 1: Logistic Regression (Î•Ï€Î¹Î²Î»ÎµÏ€ÏŒÎ¼ÎµÎ½Î· ÎœÎ¬Î¸Î·ÏƒÎ·)')
    
    st.markdown("""
    Î˜Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î®ÏƒÎ¿Ï…Î¼Îµ Î­Î½Î± Î¼Î¿Î½Ï„Î­Î»Î¿ **Logistic Regression** Î³Î¹Î± **binary classification**.
    Î‘Ï…Ï„ÏŒ ÎµÎ¯Î½Î±Î¹ Î­Î½Î± ÎºÎ»Î±ÏƒÎ¹ÎºÏŒ Ï€Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î± ÎµÏ€Î¹Î²Î»ÎµÏ€ÏŒÎ¼ÎµÎ½Î·Ï‚ Î¼Î¬Î¸Î·ÏƒÎ·Ï‚.
    """)
    
    col1, col2 = st.columns([1, 1])
    with col1:
        n = st.slider('ğŸ”¢ Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ Î´ÎµÎ¹Î³Î¼Î¬Ï„Ï‰Î½', 100, 2000, 500, step=100)
        noise = st.slider('ğŸ”Š Î•Ï€Î¯Ï€ÎµÎ´Î¿ Î¸Î¿ÏÏÎ²Î¿Ï…', 0.0, 0.5, 0.1, step=0.05)
    with col2:
        test_size = st.slider('ğŸ“Š Î Î¿ÏƒÎ¿ÏƒÏ„ÏŒ Test Set', 0.1, 0.5, 0.3, step=0.05)
        random_state = st.slider('ğŸ² Random Seed', 1, 100, 42)
    
    X, y = make_classification(n_samples=n, n_features=2, n_redundant=0, 
                                n_clusters_per_class=1, flip_y=noise, random_state=random_state)
    df = pd.DataFrame(X, columns=['Feature 1','Feature 2'])
    df['Target'] = y
    
    tab_viz1, tab_viz2, tab_viz3 = st.tabs(['ğŸ“Š Î”ÎµÎ´Î¿Î¼Î­Î½Î±', 'ğŸ“ˆ ÎŸÏ€Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·', 'ğŸ¯ ÎœÎ¿Î½Ï„Î­Î»Î¿'])
    
    with tab_viz1:
        st.dataframe(df.head(20), use_container_width=True)
        st.markdown(f"**Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬:** {n} Î´ÎµÎ¯Î³Î¼Î±Ï„Î±, {df['Target'].value_counts().to_dict()}")
    
    with tab_viz2:
        fig, ax = plt.subplots(figsize=(10, 6))
        scatter = ax.scatter(X[:,0], X[:,1], c=y, cmap='viridis', alpha=0.6, edgecolors='k')
        ax.set_xlabel('Feature 1', fontsize=12)
        ax.set_ylabel('Feature 2', fontsize=12)
        ax.set_title('Scatter Plot Ï„Ï‰Î½ Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½', fontsize=14, fontweight='bold')
        plt.colorbar(scatter, ax=ax, label='Class')
        st.pyplot(fig)
        plt.close()
    
    with tab_viz3:
        if st.button('ğŸš€ Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Logistic Regression'):
            with st.spinner('Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Î¿Ï…...'):
                time.sleep(1)  # Simulation
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)
                model = LogisticRegression(max_iter=1000).fit(X_train, y_train)
                y_pred = model.predict(X_test)
                acc = accuracy_score(y_test, y_pred)
                
                col_a, col_b = st.columns(2)
                with col_a:
                    st.metric('âœ… Accuracy', f'{acc:.2%}')
                    st.metric('ğŸ“¦ Training Samples', len(X_train))
                with col_b:
                    st.metric('ğŸ“Š Test Samples', len(X_test))
                    st.metric('ğŸ¯ Correct Predictions', int(acc * len(X_test)))
                
                # Confusion Matrix
                cm = confusion_matrix(y_test, y_pred)
                fig_cm, ax_cm = plt.subplots(figsize=(8, 6))
                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax_cm)
                ax_cm.set_title('Confusion Matrix')
                ax_cm.set_xlabel('Predicted')
                ax_cm.set_ylabel('Actual')
                st.pyplot(fig_cm)
                plt.close()
                
                # Visualization
                fig2, ax2 = plt.subplots(figsize=(10, 6))
                scatter = ax2.scatter(X_test[:,0], X_test[:,1], c=y_pred, cmap='coolwarm', 
                                     alpha=0.7, edgecolors='k', s=100)
                ax2.set_xlabel('Feature 1')
                ax2.set_ylabel('Feature 2')
                ax2.set_title('Î ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚ ÎœÎ¿Î½Ï„Î­Î»Î¿Ï…')
                plt.colorbar(scatter, ax=ax2)
                st.pyplot(fig2)
                plt.close()
                
                st.success(f'âœ… Î¤Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ ÎµÎºÏ€Î±Î¹Î´ÎµÏÏ„Î·ÎºÎµ ÎµÏ€Î¹Ï„Ï…Ï‡ÏÏ‚ Î¼Îµ accuracy {acc:.2%}!')

    st.markdown('---')
    section_title('Î Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î± 2: K-Means Clustering (ÎœÎ· Î•Ï€Î¹Î²Î»ÎµÏ€ÏŒÎ¼ÎµÎ½Î· ÎœÎ¬Î¸Î·ÏƒÎ·)')
    
    st.markdown("""
    Î¤Î¿ **K-Means** ÎµÎ¯Î½Î±Î¹ Î­Î½Î±Ï‚ Î´Î·Î¼Î¿Ï†Î¹Î»Î®Ï‚ Î±Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Ï‚ **clustering** (Î¿Î¼Î±Î´Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚) Ï€Î¿Ï… Î±Î½Î®ÎºÎµÎ¹ ÏƒÏ„Î· 
    Î¼Î· ÎµÏ€Î¹Î²Î»ÎµÏ€ÏŒÎ¼ÎµÎ½Î· Î¼Î¬Î¸Î·ÏƒÎ·.
    """)
    
    col_km1, col_km2 = st.columns(2)
    with col_km1:
        n_samples_km = st.slider('ğŸ“¦ Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ Î´ÎµÎ¹Î³Î¼Î¬Ï„Ï‰Î½', 100, 1000, 400, key='km_samples')
        n_clusters = st.slider('ğŸ¯ Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ Clusters (K)', 2, 8, 3, key='kc')
    with col_km2:
        cluster_std = st.slider('ğŸ“ Cluster Standard Deviation', 0.5, 3.0, 1.5, key='km_std')
        random_km = st.slider('ğŸ² Random State', 1, 100, 42, key='km_random')
    
    if st.button('ğŸ”¬ Î•ÎºÏ„Î­Î»ÎµÏƒÎ· K-Means'):
        with st.spinner('Î•ÎºÏ„Î­Î»ÎµÏƒÎ· Î±Î»Î³Î¿ÏÎ¯Î¸Î¼Î¿Ï…...'):
            from sklearn.cluster import KMeans
            Xc, yc = make_blobs(n_samples=n_samples_km, centers=n_clusters, 
                               n_features=2, cluster_std=cluster_std, random_state=random_km)
            km = KMeans(n_clusters=n_clusters, random_state=random_km, n_init=10).fit(Xc)
            labels = km.labels_
            centers = km.cluster_centers_
            
            fig_km, ax_km = plt.subplots(figsize=(10, 6))
            scatter = ax_km.scatter(Xc[:,0], Xc[:,1], c=labels, cmap='tab10', alpha=0.6, edgecolors='k')
            ax_km.scatter(centers[:,0], centers[:,1], c='red', marker='X', s=300, 
                         edgecolors='black', linewidths=2, label='Centroids')
            ax_km.set_xlabel('Feature 1')
            ax_km.set_ylabel('Feature 2')
            ax_km.set_title(f'K-Means Clustering (K={n_clusters})')
            ax_km.legend()
            st.pyplot(fig_km)
            plt.close()
            
            st.success(f'âœ… Î¤Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î¿Î¼Î±Î´Î¿Ï€Î¿Î¹Î®Î¸Î·ÎºÎ±Î½ ÏƒÎµ {n_clusters} clusters!')
            
            # Show cluster sizes
            unique, counts = np.unique(labels, return_counts=True)
            cluster_info = pd.DataFrame({'Cluster': unique, 'Size': counts})
            st.dataframe(cluster_info, use_container_width=True, hide_index=True)
    
    st.markdown('---')
    section_title('Î Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î± 3: ÎÎµÏ…ÏÏ‰Î½Î¹ÎºÏŒ Î”Î¯ÎºÏ„Ï…Î¿ (Deep Learning)')
    
    st.markdown("""
    ÎˆÎ½Î± Î±Ï€Î»ÏŒ **Neural Network** Î³Î¹Î± classification. Î˜Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÎ¿Ï…Î¼Îµ Ï„Î¿ scikit-learn 
    Î³Î¹Î± Î½Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î®ÏƒÎ¿Ï…Î¼Îµ Î­Î½Î± multi-layer perceptron.
    """)
    
    col_nn1, col_nn2 = st.columns(2)
    with col_nn1:
        hidden_layers = st.multiselect('ğŸ§  Hidden Layers (neurons)', 
                                       [10, 20, 50, 100, 200], default=[100, 50])
        activation = st.selectbox('âš¡ Activation Function', ['relu', 'tanh', 'logistic'])
    with col_nn2:
        learning_rate = st.select_slider('ğŸ“ˆ Learning Rate', 
                                         options=[0.0001, 0.001, 0.01, 0.1], value=0.001)
        max_iterations = st.slider('ğŸ”„ Max Iterations', 100, 1000, 200, step=100)
    
    if st.button('ğŸš€ Train Neural Network'):
        from sklearn.neural_network import MLPClassifier
        from sklearn.preprocessing import StandardScaler
        
        with st.spinner('Training Neural Network...'):
            X_nn, y_nn = make_classification(n_samples=1000, n_features=20, n_informative=15,
                                            n_redundant=5, random_state=42)
            X_train_nn, X_test_nn, y_train_nn, y_test_nn = train_test_split(
                X_nn, y_nn, test_size=0.3, random_state=42)
            
            scaler = StandardScaler()
            X_train_nn = scaler.fit_transform(X_train_nn)
            X_test_nn = scaler.transform(X_test_nn)
            
            if hidden_layers:
                mlp = MLPClassifier(hidden_layer_sizes=tuple(hidden_layers),
                                   activation=activation, 
                                   learning_rate_init=learning_rate,
                                   max_iter=max_iterations,
                                   random_state=42)
                mlp.fit(X_train_nn, y_train_nn)
                y_pred_nn = mlp.predict(X_test_nn)
                acc_nn = accuracy_score(y_test_nn, y_pred_nn)
                
                col_nn_a, col_nn_b, col_nn_c = st.columns(3)
                with col_nn_a:
                    st.metric('ğŸ¯ Test Accuracy', f'{acc_nn:.2%}')
                with col_nn_b:
                    st.metric('ğŸ“Š Iterations', mlp.n_iter_)
                with col_nn_c:
                    st.metric('ğŸ“‰ Final Loss', f'{mlp.loss_:.4f}')
                
                # Plot loss curve
                fig_loss, ax_loss = plt.subplots(figsize=(10, 5))
                ax_loss.plot(mlp.loss_curve_, linewidth=2)
                ax_loss.set_xlabel('Iterations')
                ax_loss.set_ylabel('Loss')
                ax_loss.set_title('Training Loss Curve')
                ax_loss.grid(True, alpha=0.3)
                st.pyplot(fig_loss)
                plt.close()
                
                st.success(f'âœ… Neural Network trained with accuracy: {acc_nn:.2%}!')
            else:
                st.error('Î Î±ÏÎ±ÎºÎ±Î»Ï ÎµÏ€Î¹Î»Î­Î¾Ï„Îµ Ï„Î¿Ï…Î»Î¬Ï‡Î¹ÏƒÏ„Î¿Î½ Î­Î½Î± hidden layer!')

with tabs[2]:
    section_title('Î•Î¾Î¿Î¼Î¿Î¹ÏÏƒÎµÎ¹Ï‚ AI â€” Î”Î¹Î±Î´ÏÎ±ÏƒÏ„Î¹ÎºÎ¬ Demos')
    
    st.markdown("""
    Î£Îµ Î±Ï…Ï„Î® Ï„Î·Î½ ÎµÎ½ÏŒÏ„Î·Ï„Î± Î¼Ï€Î¿ÏÎµÎ¯Ï„Îµ Î½Î± Ï€ÎµÎ¹ÏÎ±Î¼Î±Ï„Î¹ÏƒÏ„ÎµÎ¯Ï„Îµ Î¼Îµ Î´Î¹Î¬Ï†Î¿ÏÎµÏ‚ Ï€Î±ÏÎ±Î¼Î­Ï„ÏÎ¿Ï…Ï‚ ÎºÎ±Î¹ Î½Î± Î´ÎµÎ¯Ï„Îµ Ï€ÏÏ‚ 
    ÎµÏ€Î·ÏÎµÎ¬Î¶Î¿Ï…Î½ Ï„Î·Î½ Î±Ï€ÏŒÎ´Î¿ÏƒÎ· Ï„Ï‰Î½ Î¼Î¿Î½Ï„Î­Î»Ï‰Î½ AI.
    """)
    
    sim_option = st.selectbox('ğŸ® Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Î•Î¾Î¿Î¼Î¿Î¯Ï‰ÏƒÎ·:', [
        'Î•Ï€Î¯Î´ÏÎ±ÏƒÎ· Î˜Î¿ÏÏÎ²Î¿Ï… ÏƒÏ„Î·Î½ Î‘ÎºÏÎ¯Î²ÎµÎ¹Î±',
        'Overfitting vs Underfitting',
        'Î•Ï€Î¯Î´ÏÎ±ÏƒÎ· ÎœÎµÎ³Î­Î¸Î¿Ï…Ï‚ Dataset',
        'Decision Boundary Visualization'
    ])
    
    if sim_option == 'Î•Ï€Î¯Î´ÏÎ±ÏƒÎ· Î˜Î¿ÏÏÎ²Î¿Ï… ÏƒÏ„Î·Î½ Î‘ÎºÏÎ¯Î²ÎµÎ¹Î±':
        st.markdown('### ğŸ”Š Î ÏÏ‚ Î¿ Î¸ÏŒÏÏ…Î²Î¿Ï‚ ÎµÏ€Î·ÏÎµÎ¬Î¶ÎµÎ¹ Ï„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿')
        
        noise_level = st.slider('Î•Ï€Î¯Ï€ÎµÎ´Î¿ Î¸Î¿ÏÏÎ²Î¿Ï… (flip_y)', 0.0, 0.5, 0.1, 0.05)
        
        results = []
        for noise in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]:
            X_sim, y_sim = make_classification(n_samples=500, n_features=2, n_redundant=0, 
                                               flip_y=noise, random_state=42)
            X_tr, X_te, y_tr, y_te = train_test_split(X_sim, y_sim, test_size=0.3, random_state=42)
            model_sim = LogisticRegression().fit(X_tr, y_tr)
            acc_sim = accuracy_score(y_te, model_sim.predict(X_te))
            results.append({'Noise': noise, 'Accuracy': acc_sim})
        
        df_results = pd.DataFrame(results)
        
        fig_noise, ax_noise = plt.subplots(figsize=(10, 6))
        ax_noise.plot(df_results['Noise'], df_results['Accuracy'], marker='o', linewidth=2, markersize=8)
        ax_noise.axvline(x=noise_level, color='r', linestyle='--', label=f'Current ({noise_level})')
        ax_noise.set_xlabel('Noise Level', fontsize=12)
        ax_noise.set_ylabel('Accuracy', fontsize=12)
        ax_noise.set_title('Î•Ï€Î¯Î´ÏÎ±ÏƒÎ· Î˜Î¿ÏÏÎ²Î¿Ï… ÏƒÏ„Î·Î½ Î‘ÎºÏÎ¯Î²ÎµÎ¹Î± Ï„Î¿Ï… ÎœÎ¿Î½Ï„Î­Î»Î¿Ï…', fontsize=14, fontweight='bold')
        ax_noise.grid(True, alpha=0.3)
        ax_noise.legend()
        st.pyplot(fig_noise)
        plt.close()
        
        st.info(f'ğŸ“Š ÎœÎµ noise level {noise_level}, Î· Î±ÎºÏÎ¯Î²ÎµÎ¹Î± ÎµÎ¯Î½Î±Î¹ Ï€ÎµÏÎ¯Ï€Î¿Ï… {df_results[df_results["Noise"]==noise_level]["Accuracy"].values[0]:.2%}')
    
    elif sim_option == 'Overfitting vs Underfitting':
        st.markdown('### âš–ï¸ Overfitting vs Underfitting')
        
        st.markdown("""
        - **Underfitting**: Î¤Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ ÎµÎ¯Î½Î±Î¹ Ï€Î¿Î»Ï Î±Ï€Î»ÏŒ ÎºÎ±Î¹ Î´ÎµÎ½ Î¼Î±Î¸Î±Î¯Î½ÎµÎ¹ ÎºÎ±Î»Î¬
        - **Good Fit**: Î¤Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ ÎµÎ¯Î½Î±Î¹ Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î·Î¼Î­Î½Î¿
        - **Overfitting**: Î¤Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ Î­Ï‡ÎµÎ¹ "Î¼Î¬Î¸ÎµÎ¹" Ï„Î¿Î½ training set Î±Ï€' Î­Î¾Ï‰ Î±Î»Î»Î¬ Î´ÎµÎ½ Î³ÎµÎ½Î¹ÎºÎµÏÎµÎ¹
        """)
        
        from sklearn.preprocessing import PolynomialFeatures
        from sklearn.linear_model import LinearRegression
        from sklearn.metrics import mean_squared_error
        
        # Generate data
        np.random.seed(42)
        X_poly = np.sort(np.random.rand(50, 1) * 10, axis=0)
        y_poly = np.sin(X_poly).ravel() + np.random.randn(50) * 0.5
        
        degree = st.slider('ğŸ¯ Polynomial Degree', 1, 15, 3)
        
        poly_features = PolynomialFeatures(degree=degree)
        X_poly_transformed = poly_features.fit_transform(X_poly)
        model_poly = LinearRegression().fit(X_poly_transformed, y_poly)
        
        X_test_poly = np.linspace(0, 10, 100).reshape(-1, 1)
        X_test_poly_transformed = poly_features.transform(X_test_poly)
        y_pred_poly = model_poly.predict(X_test_poly_transformed)
        
        fig_poly, ax_poly = plt.subplots(figsize=(10, 6))
        ax_poly.scatter(X_poly, y_poly, color='blue', s=50, alpha=0.6, label='Data')
        ax_poly.plot(X_test_poly, y_pred_poly, color='red', linewidth=2, label=f'Degree {degree}')
        ax_poly.set_xlabel('X')
        ax_poly.set_ylabel('y')
        ax_poly.set_title(f'Polynomial Regression (Degree={degree})')
        ax_poly.legend()
        ax_poly.grid(True, alpha=0.3)
        st.pyplot(fig_poly)
        plt.close()
        
        mse = mean_squared_error(y_poly, model_poly.predict(X_poly_transformed))
        st.metric('ğŸ“‰ Training MSE', f'{mse:.4f}')
        
        if degree < 3:
            st.warning('âš ï¸ **Underfitting**: Î¤Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ ÎµÎ¯Î½Î±Î¹ Ï€Î¿Î»Ï Î±Ï€Î»ÏŒ!')
        elif degree <= 5:
            st.success('âœ… **Good Fit**: Î¤Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ ÎµÎ¯Î½Î±Î¹ Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î·Î¼Î­Î½Î¿!')
        else:
            st.error('ğŸ”´ **Overfitting**: Î¤Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ ÎµÎ¯Î½Î±Î¹ Ï€Î¿Î»Ï Ï€Î¿Î»ÏÏ€Î»Î¿ÎºÎ¿!')
    
    elif sim_option == 'Î•Ï€Î¯Î´ÏÎ±ÏƒÎ· ÎœÎµÎ³Î­Î¸Î¿Ï…Ï‚ Dataset':
        st.markdown('### ğŸ“Š Î ÏÏ‚ Ï„Î¿ Î¼Î­Î³ÎµÎ¸Î¿Ï‚ Ï„Î¿Ï… dataset ÎµÏ€Î·ÏÎµÎ¬Î¶ÎµÎ¹ Ï„Î·Î½ Î±Ï€ÏŒÎ´Î¿ÏƒÎ·')
        
        sizes = [50, 100, 200, 500, 1000, 2000]
        accuracies = []
        
        with st.spinner('Î•ÎºÏ„Î­Î»ÎµÏƒÎ· Ï€ÎµÎ¹ÏÎ±Î¼Î¬Ï„Ï‰Î½...'):
            for size in sizes:
                X_size, y_size = make_classification(n_samples=size, n_features=10, random_state=42)
                X_tr_s, X_te_s, y_tr_s, y_te_s = train_test_split(X_size, y_size, test_size=0.3, random_state=42)
                model_size = LogisticRegression(max_iter=1000).fit(X_tr_s, y_tr_s)
                acc_size = accuracy_score(y_te_s, model_size.predict(X_te_s))
                accuracies.append(acc_size)
        
        fig_size, ax_size = plt.subplots(figsize=(10, 6))
        ax_size.plot(sizes, accuracies, marker='o', linewidth=2, markersize=10, color='green')
        ax_size.set_xlabel('Dataset Size', fontsize=12)
        ax_size.set_ylabel('Accuracy', fontsize=12)
        ax_size.set_title('Î•Ï€Î¯Î´ÏÎ±ÏƒÎ· ÎœÎµÎ³Î­Î¸Î¿Ï…Ï‚ Dataset ÏƒÏ„Î·Î½ Î‘ÎºÏÎ¯Î²ÎµÎ¹Î±', fontsize=14, fontweight='bold')
        ax_size.grid(True, alpha=0.3)
        st.pyplot(fig_size)
        plt.close()
        
        st.info('ğŸ’¡ **Î Î±ÏÎ±Ï„Î®ÏÎ·ÏƒÎ·**: ÎœÎµ Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎ± Î´ÎµÎ´Î¿Î¼Î­Î½Î±, Ï„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ Î³ÎµÎ½Î¹ÎºÎ¬ Î²ÎµÎ»Ï„Î¹ÏÎ½ÎµÏ„Î±Î¹!')
    
    elif sim_option == 'Decision Boundary Visualization':
        st.markdown('### ğŸ¯ ÎŸÏ€Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Decision Boundary')
        
        from sklearn.svm import SVC
        
        kernel_choice = st.selectbox('Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Kernel:', ['linear', 'rbf', 'poly'])
        
        X_db, y_db = make_classification(n_samples=200, n_features=2, n_redundant=0, 
                                         n_clusters_per_class=1, random_state=42)
        
        model_db = SVC(kernel=kernel_choice, gamma='auto').fit(X_db, y_db)
        
        # Create mesh
        h = 0.02
        x_min, x_max = X_db[:, 0].min() - 1, X_db[:, 0].max() + 1
        y_min, y_max = X_db[:, 1].min() - 1, X_db[:, 1].max() + 1
        xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
        
        Z = model_db.predict(np.c_[xx.ravel(), yy.ravel()])
        Z = Z.reshape(xx.shape)
        
        fig_db, ax_db = plt.subplots(figsize=(10, 8))
        ax_db.contourf(xx, yy, Z, alpha=0.3, cmap='coolwarm')
        scatter = ax_db.scatter(X_db[:, 0], X_db[:, 1], c=y_db, cmap='coolwarm', 
                               edgecolors='k', s=50)
        ax_db.set_xlabel('Feature 1')
        ax_db.set_ylabel('Feature 2')
        ax_db.set_title(f'Decision Boundary (Kernel: {kernel_choice})')
        plt.colorbar(scatter, ax=ax_db)
        st.pyplot(fig_db)
        plt.close()
        
        acc_db = model_db.score(X_db, y_db)
        st.metric('ğŸ¯ Training Accuracy', f'{acc_db:.2%}')

with tabs[3]:
    section_title('ÎšÎ¿Ï…Î¯Î¶ Î‘Ï…Ï„Î¿Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·Ï‚')
    
    st.markdown("""
    Î”Î¿ÎºÎ¹Î¼Î¬ÏƒÏ„Îµ Ï„Î¹Ï‚ Î³Î½ÏÏƒÎµÎ¹Ï‚ ÏƒÎ±Ï‚! Î‘Ï€Î±Î½Ï„Î®ÏƒÏ„Îµ ÏƒÏ„Î¹Ï‚ Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚ Î³Î¹Î± Î½Î± ÎµÎ»Î­Î³Î¾ÎµÏ„Îµ Ï„Î·Î½ ÎºÎ±Ï„Î±Î½ÏŒÎ·ÏƒÎ® ÏƒÎ±Ï‚.
    """)
    
    quiz_category = st.selectbox('ğŸ“š Î•Ï€Î¹Î»Î­Î¾Ï„Îµ ÎšÎ±Ï„Î·Î³Î¿ÏÎ¯Î±:', [
        'Î“ÎµÎ½Î¹ÎºÎ¬ Î³Î¹Î± AI',
        'Machine Learning',
        'ChatGPT & LLMs',
        'Î•Ï†Î±ÏÎ¼Î¿Î³Î­Ï‚ AI',
        'Î—Î¸Î¹ÎºÎ® & ÎšÎ¿Î¹Î½Ï‰Î½Î¯Î±'
    ])
    
    quizzes_general = [
        {
            'id':'q1', 'type':'mcq',
            'question':'Î¤Î¹ ÎµÎ¯Î½Î±Î¹ Î· ÎœÎ·Ï‡Î±Î½Î¹ÎºÎ® ÎœÎ¬Î¸Î·ÏƒÎ· (Machine Learning);',
            'options':[
                'Î“ÏÎ±Ï†Î¹ÎºÎ¬ Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÏ„ÏÎ½',
                'Î¥Ï€Î¿ÎºÎ±Ï„Î·Î³Î¿ÏÎ¯Î± Ï„Î·Ï‚ AI Ï€Î¿Ï… Î¼Î±Î¸Î±Î¯Î½ÎµÎ¹ Î±Ï€ÏŒ Î´ÎµÎ´Î¿Î¼Î­Î½Î±',
                'ÎœÏŒÎ½Î¿ Î´Î¯ÎºÏ„Ï…Î± Î½ÎµÏ…ÏÏÎ½Ï‰Î½',
                'ÎˆÎ½Î± ÎµÎ¯Î´Î¿Ï‚ Î²Î¬ÏƒÎ·Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½'
            ],
            'answer':'Î¥Ï€Î¿ÎºÎ±Ï„Î·Î³Î¿ÏÎ¯Î± Ï„Î·Ï‚ AI Ï€Î¿Ï… Î¼Î±Î¸Î±Î¯Î½ÎµÎ¹ Î±Ï€ÏŒ Î´ÎµÎ´Î¿Î¼Î­Î½Î±',
            'explain':'Î— ML ÎµÎ¯Î½Î±Î¹ Î· Ï…Ï€Î¿ÎºÎ±Ï„Î·Î³Î¿ÏÎ¯Î± Ï„Î·Ï‚ AI Ï€Î¿Ï… ÎµÏ€Î¹Ï„ÏÎ­Ï€ÎµÎ¹ ÏƒÎµ Î±Î»Î³Î¿ÏÎ¯Î¸Î¼Î¿Ï…Ï‚ Î½Î± Î¼Î±Î¸Î±Î¯Î½Î¿Ï…Î½ Î±Ï€ÏŒ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Ï‡Ï‰ÏÎ¯Ï‚ Î½Î± Ï€ÏÎ¿Î³ÏÎ±Î¼Î¼Î±Ï„Î¯Î¶Î¿Î½Ï„Î±Î¹ ÏÎ·Ï„Î¬.'
        },
        {
            'id':'q2', 'type':'tf',
            'question':'Î— Î¤ÎµÏ‡Î½Î·Ï„Î® ÎÎ¿Î·Î¼Î¿ÏƒÏÎ½Î· Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î®Î¸Î·ÎºÎµ Ï„Î¿ 2020.',
            'answer':False,
            'explain':'Î›Î¬Î¸Î¿Ï‚! ÎŸ ÏŒÏÎ¿Ï‚ "Artificial Intelligence" Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®Î¸Î·ÎºÎµ Î³Î¹Î± Ï€ÏÏÏ„Î· Ï†Î¿ÏÎ¬ Ï„Î¿ 1956 ÏƒÏ„Î¿ Dartmouth Conference.'
        },
        {
            'id':'q3', 'type':'mcq',
            'question':'Î Î¿Î¹Î¿ Î±Ï€ÏŒ Ï„Î± Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ Î”Î•Î ÎµÎ¯Î½Î±Î¹ Î²Î±ÏƒÎ¹ÎºÏŒ Î´Î¿Î¼Î¹ÎºÏŒ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î¿ Ï„Î·Ï‚ AI;',
            'options':[
                'Î”ÎµÎ´Î¿Î¼Î­Î½Î±',
                'Î‘Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Î¹',
                'ÎœÎ¿Î½Ï„Î­Î»Î±',
                'Î¤Ï…Ï€Î¿Î³ÏÎ±Ï†Î¯Î±'
            ],
            'answer':'Î¤Ï…Ï€Î¿Î³ÏÎ±Ï†Î¯Î±',
            'explain':'Î¤Î± Î²Î±ÏƒÎ¹ÎºÎ¬ Î´Î¿Î¼Î¹ÎºÎ¬ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î± Ï„Î·Ï‚ AI ÎµÎ¯Î½Î±Î¹: Î”ÎµÎ´Î¿Î¼Î­Î½Î±, Î‘Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Î¹, ÎœÎ¿Î½Ï„Î­Î»Î± ÎºÎ±Î¹ Î¥Ï€Î¿Î´Î¿Î¼Î­Ï‚.'
        }
    ]
    
    quizzes_ml = [
        {
            'id':'q4', 'type':'mcq',
            'question':'Î Î¿Î¹Î¿Ï‚ Ï„ÏÏ€Î¿Ï‚ Î¼Î¬Î¸Î·ÏƒÎ·Ï‚ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯ labeled data;',
            'options':[
                'Unsupervised Learning',
                'Supervised Learning',
                'Reinforcement Learning',
                'Transfer Learning'
            ],
            'answer':'Supervised Learning',
            'explain':'Î— Supervised Learning Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯ labeled data (Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î¼Îµ ÎµÏ„Î¹ÎºÎ­Ï„ÎµÏ‚) Î³Î¹Î± Î½Î± ÎµÎºÏ€Î±Î¹Î´ÎµÏÏƒÎµÎ¹ Î¼Î¿Î½Ï„Î­Î»Î±.'
        },
        {
            'id':'q5', 'type':'tf',
            'question':'Î¤Î¿ K-Means ÎµÎ¯Î½Î±Î¹ Î±Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Ï‚ ÎµÏ€Î¹Î²Î»ÎµÏ€ÏŒÎ¼ÎµÎ½Î·Ï‚ Î¼Î¬Î¸Î·ÏƒÎ·Ï‚.',
            'answer':False,
            'explain':'Î›Î¬Î¸Î¿Ï‚! Î¤Î¿ K-Means ÎµÎ¯Î½Î±Î¹ Î±Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Ï‚ Î¼Î· ÎµÏ€Î¹Î²Î»ÎµÏ€ÏŒÎ¼ÎµÎ½Î·Ï‚ Î¼Î¬Î¸Î·ÏƒÎ·Ï‚ (unsupervised) Ï€Î¿Ï… Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯Ï„Î±Î¹ Î³Î¹Î± clustering.'
        },
        {
            'id':'q6', 'type':'mcq',
            'question':'Î¤Î¹ ÏƒÎ·Î¼Î±Î¯Î½ÎµÎ¹ "Overfitting";',
            'options':[
                'Î¤Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ ÎµÎ¯Î½Î±Î¹ Ï€Î¿Î»Ï Î±Ï€Î»ÏŒ',
                'Î¤Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ Î­Ï‡ÎµÎ¹ Ï…ÏˆÎ·Î»Î® Î±ÎºÏÎ¯Î²ÎµÎ¹Î± ÏƒÏ„Î¿ training set Î±Î»Î»Î¬ Ï‡Î±Î¼Î·Î»Î® ÏƒÏ„Î¿ test set',
                'Î¤Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ ÎµÎºÏ€Î±Î¹Î´ÎµÏÎµÏ„Î±Î¹ Ï€Î¿Î»Ï Î³ÏÎ®Î³Î¿ÏÎ±',
                'Î¤Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ Î­Ï‡ÎµÎ¹ Ï€Î¿Î»Î»Î¬ features'
            ],
            'answer':'Î¤Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ Î­Ï‡ÎµÎ¹ Ï…ÏˆÎ·Î»Î® Î±ÎºÏÎ¯Î²ÎµÎ¹Î± ÏƒÏ„Î¿ training set Î±Î»Î»Î¬ Ï‡Î±Î¼Î·Î»Î® ÏƒÏ„Î¿ test set',
            'explain':'Overfitting ÏƒÎ·Î¼Î±Î¯Î½ÎµÎ¹ ÏŒÏ„Î¹ Ï„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ "Î­Î¼Î±Î¸Îµ" Ï„Î¿Î½ training set Î±Ï€\' Î­Î¾Ï‰ Î±Î»Î»Î¬ Î´ÎµÎ½ Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Î³ÎµÎ½Î¹ÎºÎµÏÏƒÎµÎ¹ ÏƒÎµ Î½Î­Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±.'
        }
    ]
    
    quizzes_chatgpt = [
        {
            'id':'q7', 'type':'tf',
            'question':'Î¤Î¿ ChatGPT ÎµÎ¯Î½Î±Î¹ transformer-based language model.',
            'answer':True,
            'explain':'Î£Ï‰ÏƒÏ„Î¬! Î¤Î¿ ChatGPT Î²Î±ÏƒÎ¯Î¶ÎµÏ„Î±Î¹ ÏƒÏ„Î·Î½ Î±ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ® Transformer Ï€Î¿Ï… ÎµÎ¹ÏƒÎ®Ï‡Î¸Î· Ï„Î¿ 2017.'
        },
        {
            'id':'q8', 'type':'mcq',
            'question':'Î¤Î¹ ÏƒÎ·Î¼Î±Î¯Î½ÎµÎ¹ "LLM";',
            'options':[
                'Large Language Model',
                'Low Level Machine',
                'Linear Learning Method',
                'Logical Language Mechanism'
            ],
            'answer':'Large Language Model',
            'explain':'LLM ÏƒÎ·Î¼Î±Î¯Î½ÎµÎ¹ Large Language Model - Î¼ÎµÎ³Î¬Î»Î± Î³Î»Ï‰ÏƒÏƒÎ¹ÎºÎ¬ Î¼Î¿Î½Ï„Î­Î»Î± ÏŒÏ€Ï‰Ï‚ Ï„Î¿ GPT-4, Claude, ÎºÎ»Ï€.'
        },
        {
            'id':'q9', 'type':'mcq',
            'question':'Î¤Î¹ ÎµÎ¯Î½Î±Î¹ Ï„Î¿ "RLHF" Ï€Î¿Ï… Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯Ï„Î±Î¹ ÏƒÏ„Î¿ ChatGPT;',
            'options':[
                'Random Learning from Humans',
                'Reinforcement Learning from Human Feedback',
                'Rapid Language Handling Function',
                'Real-time Learning for High Frequency'
            ],
            'answer':'Reinforcement Learning from Human Feedback',
            'explain':'RLHF = Reinforcement Learning from Human Feedback. Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯Ï„Î±Î¹ Î³Î¹Î± Î½Î± "ÎµÏ…Î¸Ï…Î³ÏÎ±Î¼Î¼Î¯ÏƒÎµÎ¹" Ï„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ Î¼Îµ Î±Î½Î¸ÏÏÏ€Î¹Î½ÎµÏ‚ Ï€ÏÎ¿Ï„Î¹Î¼Î®ÏƒÎµÎ¹Ï‚.'
        }
    ]
    
    quizzes_applications = [
        {
            'id':'q10', 'type':'mcq',
            'question':'Î£Îµ Ï€Î¿Î¹Î¿Î½ Ï„Î¿Î¼Î­Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯Ï„Î±Î¹ Î· AI Î³Î¹Î± Î±Î½Î¯Ï‡Î½ÎµÏ…ÏƒÎ· Î±Ï€Î¬Ï„Î·Ï‚;',
            'options':[
                'Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·',
                'Î§ÏÎ·Î¼Î±Ï„Î¿Î¿Î¹ÎºÎ¿Î½Î¿Î¼Î¹ÎºÎ¬',
                'Î¨Ï…Ï‡Î±Î³Ï‰Î³Î¯Î±',
                'Î‘Î¸Î»Î·Ï„Î¹ÏƒÎ¼ÏŒÏ‚'
            ],
            'answer':'Î§ÏÎ·Î¼Î±Ï„Î¿Î¿Î¹ÎºÎ¿Î½Î¿Î¼Î¹ÎºÎ¬',
            'explain':'Î— AI Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯Ï„Î±Î¹ ÎµÏ…ÏÎ­Ï‰Ï‚ ÏƒÏ„Î± Ï‡ÏÎ·Î¼Î±Ï„Î¿Î¿Î¹ÎºÎ¿Î½Î¿Î¼Î¹ÎºÎ¬ Î³Î¹Î± Î±Î½Î¯Ï‡Î½ÎµÏ…ÏƒÎ· Î±Ï€Î¬Ï„Î·Ï‚ ÏƒÎµ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏŒ Ï‡ÏÏŒÎ½Î¿.'
        },
        {
            'id':'q11', 'type':'tf',
            'question':'Î— AI Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Î´Î¹Î±Î³Î½ÏÏƒÎµÎ¹ Î±ÏƒÎ¸Î­Î½ÎµÎ¹ÎµÏ‚ Î±Ï€ÏŒ Î¹Î±Ï„ÏÎ¹ÎºÎ­Ï‚ ÎµÎ¹ÎºÏŒÎ½ÎµÏ‚.',
            'answer':True,
            'explain':'Î£Ï‰ÏƒÏ„Î¬! Î— AI (ÎµÎ¹Î´Î¹ÎºÎ¬ Computer Vision) Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯Ï„Î±Î¹ Î³Î¹Î± Î½Î± Î±Î½Î±Î»ÏÏƒÎµÎ¹ Î±ÎºÏ„Î¹Î½Î¿Î³ÏÎ±Ï†Î¯ÎµÏ‚, CT, MRI ÎºÎ»Ï€.'
        },
        {
            'id':'q12', 'type':'mcq',
            'question':'Î Î¿Î¹Î± Î±Ï€ÏŒ Ï„Î¹Ï‚ Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ Î”Î•Î ÎµÎ¯Î½Î±Î¹ ÎµÏ†Î±ÏÎ¼Î¿Î³Î® Generative AI;',
            'options':[
                'DALL-E (Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÎµÎ¹ÎºÏŒÎ½Ï‰Î½)',
                'ChatGPT (Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÎºÎµÎ¹Î¼Î­Î½Î¿Ï…)',
                'Spam Filter (Ï†Î¹Î»Ï„ÏÎ¬ÏÎ¹ÏƒÎ¼Î± email)',
                'Midjourney (Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÎµÎ¹ÎºÏŒÎ½Ï‰Î½)'
            ],
            'answer':'Spam Filter (Ï†Î¹Î»Ï„ÏÎ¬ÏÎ¹ÏƒÎ¼Î± email)',
            'explain':'Î¤Î¿ spam filter ÎµÎ¯Î½Î±Î¹ classification task, ÏŒÏ‡Î¹ generative. Î¤Î± Î¬Î»Î»Î± Ï„ÏÎ¯Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¿ÏÎ½ Î½Î­Î¿ Ï€ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿.'
        }
    ]
    
    quizzes_ethics = [
        {
            'id':'q13', 'type':'tf',
            'question':'Î— AI Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± ÎµÎ¯Î½Î±Î¹ Î¼ÎµÏÎ¿Î»Î·Ï€Ï„Î¹ÎºÎ® (biased) Î±Î½ ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Ï„ÎµÎ¯ ÏƒÎµ Î¼ÎµÏÎ¿Î»Î·Ï€Ï„Î¹ÎºÎ¬ Î´ÎµÎ´Î¿Î¼Î­Î½Î±.',
            'answer':True,
            'explain':'Î£Ï‰ÏƒÏ„Î¬! Î¤Î¿ bias ÏƒÏ„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î¼ÎµÏ„Î±Ï†Î­ÏÎµÏ„Î±Î¹ ÏƒÏ„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿. Î“Î¹\' Î±Ï…Ï„ÏŒ ÎµÎ¯Î½Î±Î¹ ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÎ® Î· Î´Î¹ÎºÎ±Î¹Î¿ÏƒÏÎ½Î· ÎºÎ±Î¹ Î´Î¹Î±Ï†Î¬Î½ÎµÎ¹Î± ÏƒÏ„Î·Î½ AI.'
        },
        {
            'id':'q14', 'type':'mcq',
            'question':'Î Î¿Î¹Î± Î·Î¸Î¹ÎºÎ® Î±ÏÏ‡Î® Î±Ï†Î¿ÏÎ¬ Ï„Î¿ Î´Î¹ÎºÎ±Î¯Ï‰Î¼Î± Ï„Ï‰Î½ Î±Î½Î¸ÏÏÏ€Ï‰Î½ Î½Î± Î³Î½Ï‰ÏÎ¯Î¶Î¿Ï…Î½ Ï€ÏÏ‚ Ï€Î±Î¯ÏÎ½Î¿Î½Ï„Î±Î¹ Î±Ï€Î¿Ï†Î¬ÏƒÎµÎ¹Ï‚ Î±Ï€ÏŒ AI;',
            'options':[
                'Privacy',
                'Transparency',
                'Accountability',
                'Fairness'
            ],
            'answer':'Transparency',
            'explain':'Î— Transparency (Î”Î¹Î±Ï†Î¬Î½ÎµÎ¹Î±) ÏƒÎ·Î¼Î±Î¯Î½ÎµÎ¹ ÏŒÏ„Î¹ Ï„Î± AI ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î± Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± ÎµÎ¯Î½Î±Î¹ ÎºÎ±Ï„Î±Î½Î¿Î·Ï„Î¬ ÎºÎ±Î¹ explainable.'
        },
        {
            'id':'q15', 'type':'mcq',
            'question':'Î Î¿Î¹Î¿ ÎµÎ¯Î½Î±Î¹ Ï„Î¿ Î¼ÎµÎ³Î±Î»ÏÏ„ÎµÏÎ¿ Î·Î¸Î¹ÎºÏŒ Ï€ÏÏŒÎ²Î»Î·Î¼Î± Î¼Îµ Ï„Î± Large Language Models;',
            'options':[
                'ÎšÎ±Ï„Î±Î½Î¬Î»Ï‰ÏƒÎ· ÎµÎ½Î­ÏÎ³ÎµÎ¹Î±Ï‚',
                'Î Î±ÏÎ±Î³Ï‰Î³Î® misinformation ÎºÎ±Î¹ hallucinations',
                'ÎšÏŒÏƒÏ„Î¿Ï‚ training',
                'Î¤Î±Ï‡ÏÏ„Î·Ï„Î± Î±Ï€ÏŒÎºÏÎ¹ÏƒÎ·Ï‚'
            ],
            'answer':'Î Î±ÏÎ±Î³Ï‰Î³Î® misinformation ÎºÎ±Î¹ hallucinations',
            'explain':'Î¤Î± LLMs Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Ï€Î±ÏÎ¬Î³Î¿Ï…Î½ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Ï€Î¿Ï… Î±ÎºÎ¿ÏÎ³Î¿Î½Ï„Î±Î¹ Ï€ÎµÎ¹ÏƒÏ„Î¹ÎºÎ­Ï‚ Î±Î»Î»Î¬ ÎµÎ¯Î½Î±Î¹ Î»Î±Î½Î¸Î±ÏƒÎ¼Î­Î½ÎµÏ‚ (hallucinations).'
        }
    ]
    
    if quiz_category == 'Î“ÎµÎ½Î¹ÎºÎ¬ Î³Î¹Î± AI':
        quizzes_to_show = quizzes_general
    elif quiz_category == 'Machine Learning':
        quizzes_to_show = quizzes_ml
    elif quiz_category == 'ChatGPT & LLMs':
        quizzes_to_show = quizzes_chatgpt
    elif quiz_category == 'Î•Ï†Î±ÏÎ¼Î¿Î³Î­Ï‚ AI':
        quizzes_to_show = quizzes_applications
    else:
        quizzes_to_show = quizzes_ethics
    
    for i, q in enumerate(quizzes_to_show, 1):
        with st.container():
            st.markdown(f"#### Î•ÏÏÏ„Î·ÏƒÎ· {i}")
            show_quiz(q)
            st.markdown('---')

with tabs[4]:
    section_title('Î”Î¹Î±Î´ÏÎ±ÏƒÏ„Î¹ÎºÎ­Ï‚ Î‘ÏƒÎºÎ®ÏƒÎµÎ¹Ï‚')
    
    st.markdown("""
    Î•Î´Ï Î¼Ï€Î¿ÏÎµÎ¯Ï„Îµ Î½Î± Ï€ÎµÎ¹ÏÎ±Î¼Î±Ï„Î¹ÏƒÏ„ÎµÎ¯Ï„Îµ Î¼Îµ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ¬ Ï€ÏÎ¿Î²Î»Î®Î¼Î±Ï„Î± ÎºÎ±Î¹ Î½Î± ÎµÏ†Î±ÏÎ¼ÏŒÏƒÎµÏ„Îµ Ï„Î¹Ï‚ Î³Î½ÏÏƒÎµÎ¹Ï‚ ÏƒÎ±Ï‚!
    
    ğŸ’¡ **Tip**: ÎšÎ¬Î½Ï„Îµ ÎºÎ»Î¹Îº ÏƒÏ„Î¿ "Open in Colab" Î³Î¹Î± Î½Î± Î´Î¿ÎºÎ¹Î¼Î¬ÏƒÎµÏ„Îµ hands-on ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Î¼Îµ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏŒ ÎºÏÎ´Î¹ÎºÎ±!
    """)
    
    # Colab Notebooks Section
    st.markdown('---')
    st.markdown('### ğŸ““ Google Colab Notebooks - Hands-On Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·')
    
    st.info("""
    ğŸ“ **Î¤Î± Google Colab notebooks Ï€ÏÎ¿ÏƒÏ†Î­ÏÎ¿Ï…Î½:**
    - Î”Ï‰ÏÎµÎ¬Î½ GPU/TPU Î³Î¹Î± ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Ï‰Î½
    - Î ÏÎ¿-ÎµÎ³ÎºÎ±Ï„ÎµÏƒÏ„Î·Î¼Î­Î½ÎµÏ‚ Î²Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎµÏ‚ (TensorFlow, PyTorch, scikit-learn)
    - Î’Î®Î¼Î±-Ï€ÏÎ¿Ï‚-Î²Î®Î¼Î± Î¿Î´Î·Î³Î¯ÎµÏ‚ Î¼Îµ ÎµÎ¾Î·Î³Î®ÏƒÎµÎ¹Ï‚
    - ÎˆÏ„Î¿Î¹Î¼Î¿ ÎºÏÎ´Î¹ÎºÎ± Ï€Î¿Ï… Î¼Ï€Î¿ÏÎµÎ¯Ï„Îµ Î½Î± Ï„ÏÎ¿Ï€Î¿Ï€Î¿Î¹Î®ÏƒÎµÏ„Îµ
    - Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÏƒÏ„Î¿ Google Drive ÏƒÎ±Ï‚
    """)
    
    col_c1, col_c2 = st.columns(2)
    
    with col_c1:
        st.markdown("#### ğŸš€ Beginner Level")
        
        colab_button(
            "Linear Regression - Î’Î±ÏƒÎ¹ÎºÎ¬",
            "https://colab.research.google.com/github/ageron/handson-ml2/blob/master/04_training_linear_models.ipynb",
            "ÎœÎ¬Î¸ÎµÏ„Îµ Linear Regression Î±Ï€ÏŒ Ï„Î¿ Î¼Î·Î´Î­Î½ Î¼Îµ scikit-learn"
        )
        
        st.markdown("---")
        
        colab_button(
            "K-Means Clustering",
            "https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.11-K-Means.ipynb",
            "Unsupervised learning Î¼Îµ K-Means algorithm"
        )
        
        st.markdown("---")
        
        colab_button(
            "Decision Trees & Random Forests",
            "https://colab.research.google.com/github/ageron/handson-ml2/blob/master/06_decision_trees.ipynb",
            "Ensemble methods Î³Î¹Î± classification ÎºÎ±Î¹ regression"
        )
    
    with col_c2:
        st.markdown("#### ğŸ”¥ Advanced Level")
        
        colab_button(
            "Neural Networks Î¼Îµ TensorFlow",
            "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb",
            "Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î®ÏƒÏ„Îµ Ï„Î¿ Ï€ÏÏÏ„Î¿ ÏƒÎ±Ï‚ Deep Learning Î¼Î¿Î½Ï„Î­Î»Î¿"
        )
        
        st.markdown("---")
        
        colab_button(
            "CNN Î³Î¹Î± Image Classification",
            "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/cnn.ipynb",
            "Convolutional Neural Networks Î³Î¹Î± Ï„Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ· ÎµÎ¹ÎºÏŒÎ½Ï‰Î½"
        )
        
        st.markdown("---")
        
        colab_button(
            "NLP Î¼Îµ Transformers",
            "https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/text_classification.ipynb",
            "Sentiment analysis Î¼Îµ pre-trained BERT"
        )
    
    st.markdown('---')
    st.markdown('### ğŸ® Î”Î¹Î±Î´ÏÎ±ÏƒÏ„Î¹ÎºÎ­Ï‚ Î•Î¾Î±ÏƒÎºÎ®ÏƒÎµÎ¹Ï‚ (In-App)')
    
    exercise_choice = st.selectbox('ğŸ¯ Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Î†ÏƒÎºÎ·ÏƒÎ·:', [
        'Î ÏÏŒÎ²Î»ÎµÏˆÎ· Î¤Î¹Î¼ÏÎ½ (Regression)',
        'Î¤Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ· Î•Î¹ÎºÏŒÎ½Ï‰Î½ (Image Classification Simulation)',
        'Sentiment Analysis Simulator',
        'Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î£Ï…ÏƒÏ„Î®Î¼Î±Ï„Î¿Ï‚ Î£Ï…ÏƒÏ„Î¬ÏƒÎµÏ‰Î½',
        'ğŸ†• Custom ML Pipeline Builder'
    ])
    
    if exercise_choice == 'Î ÏÏŒÎ²Î»ÎµÏˆÎ· Î¤Î¹Î¼ÏÎ½ (Regression)':
        st.markdown('### ğŸ  Î ÏÏŒÎ²Î»ÎµÏˆÎ· Î¤Î¹Î¼ÏÎ½ Î‘ÎºÎ¹Î½Î®Ï„Ï‰Î½')
        
        st.markdown("""
        Î£Îµ Î±Ï…Ï„Î® Ï„Î·Î½ Î¬ÏƒÎºÎ·ÏƒÎ· Î¸Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î®ÏƒÎµÏ„Îµ Î­Î½Î± Î¼Î¿Î½Ï„Î­Î»Î¿ Ï€Î¿Ï… Ï€ÏÎ¿Î²Î»Î­Ï€ÎµÎ¹ Ï„Î·Î½ Ï„Î¹Î¼Î® ÎµÎ½ÏŒÏ‚ Î±ÎºÎ¹Î½Î®Ï„Î¿Ï… 
        Î²Î¬ÏƒÎµÎ¹ Ï„Ï‰Î½ Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½ Ï„Î¿Ï….
        """)
        
        # Add interactive concept explainer
        concept_explainer(
            "Linear Regression",
            "Î— **Linear Regression** ÎµÎ¯Î½Î±Î¹ Î­Î½Î±Ï‚ Î±Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Ï‚ supervised learning Ï€Î¿Ï… Ï€ÏÎ¿Î²Î»Î­Ï€ÎµÎ¹ Î¼Î¹Î± ÏƒÏ…Î½ÎµÏ‡Î® Ï„Î¹Î¼Î® (continuous value).",
            """
            **ÎœÎ±Î¸Î·Î¼Î±Ï„Î¹ÎºÎ® Î¦ÏŒÏÎ¼Î¿Ï…Î»Î±:**
            ```
            y = Î²â‚€ + Î²â‚xâ‚ + Î²â‚‚xâ‚‚ + ... + Î²â‚™xâ‚™ + Îµ
            ```
            
            ÎŒÏ€Î¿Ï…:
            - y: Target variable (Ï„Î¹Î¼Î®)
            - x: Features (Î¼Î­Î³ÎµÎ¸Î¿Ï‚, Î´Ï‰Î¼Î¬Ï„Î¹Î±, ÎºÎ»Ï€.)
            - Î²: Coefficients (Ï€Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹ Ï€Î¿Ï… Î¼Î±Î¸Î±Î¯Î½ÎµÎ¹ Ï„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿)
            - Îµ: Error term
            
            **Î ÏÏ‚ Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³ÎµÎ¯:**
            1. Î¤Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ Ï€ÏÎ¿ÏƒÏ€Î±Î¸ÎµÎ¯ Î½Î± Î²ÏÎµÎ¹ Ï„Î·Î½ "ÎºÎ±Î»ÏÏ„ÎµÏÎ· Î³ÏÎ±Î¼Î¼Î®" Ï€Î¿Ï… Ï„Î±Î¹ÏÎ¹Î¬Î¶ÎµÎ¹ ÏƒÏ„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±
            2. "ÎšÎ±Î»ÏÏ„ÎµÏÎ·" ÏƒÎ·Î¼Î±Î¯Î½ÎµÎ¹ ÎµÎ»Î±Ï‡Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Ï„Î¿Ï… Mean Squared Error (MSE)
            3. Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯ Gradient Descent Î® Normal Equation
            
            **Î Î»ÎµÎ¿Î½ÎµÎºÏ„Î®Î¼Î±Ï„Î±:**
            - Î‘Ï€Î»ÏŒ ÎºÎ±Î¹ Î³ÏÎ®Î³Î¿ÏÎ¿
            - Interpretable (Î¼Ï€Î¿ÏÎ¿ÏÎ¼Îµ Î½Î± Î´Î¿ÏÎ¼Îµ Ï„Î¹Ï‚ Ï€Î±ÏÎ±Î¼Î­Ï„ÏÎ¿Ï…Ï‚)
            - ÎšÎ±Î»ÏŒ baseline Î¼Î¿Î½Ï„Î­Î»Î¿
            
            **ÎœÎµÎ¹Î¿Î½ÎµÎºÏ„Î®Î¼Î±Ï„Î±:**
            - Î¥Ï€Î¿Î¸Î­Ï„ÎµÎ¹ Î³ÏÎ±Î¼Î¼Î¹ÎºÎ® ÏƒÏ‡Î­ÏƒÎ·
            - Sensitive ÏƒÎµ outliers
            - Î”ÎµÎ½ Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Ï€Î¹Î¬ÏƒÎµÎ¹ Ï€Î¿Î»ÏÏ€Î»Î¿ÎºÎ± patterns
            """,
            """
            - Î ÏÏŒÎ²Î»ÎµÏˆÎ· Ï„Î¹Î¼ÏÎ½ Î±ÎºÎ¹Î½Î®Ï„Ï‰Î½
            - Sales forecasting
            - Stock price trends (short-term)
            - Energy consumption prediction
            """
        )
        
        # Simulate housing data
        np.random.seed(42)
        n_houses = st.slider('Î ÏŒÏƒÎ± Î±ÎºÎ¯Î½Î·Ï„Î± ÏƒÏ„Î¿ dataset;', 50, 500, 200)
        
        size = np.random.randint(50, 300, n_houses)
        rooms = np.random.randint(1, 6, n_houses)
        age = np.random.randint(0, 50, n_houses)
        
        price = (size * 1000 + rooms * 15000 - age * 500 + 
                 np.random.randn(n_houses) * 10000)
        
        df_houses = pd.DataFrame({
            'ÎœÎ­Î³ÎµÎ¸Î¿Ï‚ (Ï„.Î¼.)': size,
            'Î”Ï‰Î¼Î¬Ï„Î¹Î±': rooms,
            'Î—Î»Î¹ÎºÎ¯Î± (Î­Ï„Î·)': age,
            'Î¤Î¹Î¼Î® (â‚¬)': price
        })
        
        st.dataframe(df_houses.head(10))
        
        if st.button('ğŸš€ Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· ÎœÎ¿Î½Ï„Î­Î»Î¿Ï… Î ÏÏŒÎ²Î»ÎµÏˆÎ·Ï‚'):
            from sklearn.linear_model import LinearRegression
            from sklearn.metrics import mean_absolute_error, r2_score
            
            X_houses = df_houses[['ÎœÎ­Î³ÎµÎ¸Î¿Ï‚ (Ï„.Î¼.)', 'Î”Ï‰Î¼Î¬Ï„Î¹Î±', 'Î—Î»Î¹ÎºÎ¯Î± (Î­Ï„Î·)']].values
            y_houses = df_houses['Î¤Î¹Î¼Î® (â‚¬)'].values
            
            X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(
                X_houses, y_houses, test_size=0.3, random_state=42)
            
            model_h = LinearRegression().fit(X_train_h, y_train_h)
            y_pred_h = model_h.predict(X_test_h)
            
            mae = mean_absolute_error(y_test_h, y_pred_h)
            r2 = r2_score(y_test_h, y_pred_h)
            
            col_h1, col_h2 = st.columns(2)
            with col_h1:
                st.metric('ğŸ“Š RÂ² Score', f'{r2:.3f}')
                concept_explainer(
                    "RÂ² Score (Coefficient of Determination)",
                    "Î¤Î¿ RÂ² Î¼ÎµÏ„ÏÎ¬ Ï€ÏŒÏƒÎ¿ ÎºÎ±Î»Î¬ Ï„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ ÎµÎ¾Î·Î³ÎµÎ¯ Ï„Î· Î´Î¹Î±ÎºÏÎ¼Î±Î½ÏƒÎ· Ï„Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½.",
                    """
                    **Î¤Î¹Î¼Î­Ï‚ RÂ²:**
                    - **1.0**: Î¤Î­Î»ÎµÎ¹Î± Ï€ÏÏŒÎ²Î»ÎµÏˆÎ·
                    - **0.8-0.9**: Î Î¿Î»Ï ÎºÎ±Î»ÏŒ Î¼Î¿Î½Ï„Î­Î»Î¿
                    - **0.6-0.8**: ÎšÎ±Î»ÏŒ Î¼Î¿Î½Ï„Î­Î»Î¿
                    - **< 0.5**: Î‘Î´ÏÎ½Î±Î¼Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿
                    - **< 0**: Î§ÎµÎ¹ÏÏŒÏ„ÎµÏÎ¿ Î±Ï€ÏŒ Î±Ï€Î»ÏŒ mean
                    
                    **Î¦ÏŒÏÎ¼Î¿Ï…Î»Î±:**
                    ```
                    RÂ² = 1 - (Î£(y_actual - y_pred)Â²) / (Î£(y_actual - y_mean)Â²)
                    ```
                    """,
                    f"Î¤Î¿ Î´Î¹ÎºÏŒ ÏƒÎ±Ï‚ Î¼Î¿Î½Ï„Î­Î»Î¿ Î¼Îµ RÂ²={r2:.3f} Î¸ÎµÏ‰ÏÎµÎ¯Ï„Î±Î¹ {'ÎµÎ¾Î±Î¹ÏÎµÏ„Î¹ÎºÏŒ!' if r2>0.9 else 'Ï€Î¿Î»Ï ÎºÎ±Î»ÏŒ!' if r2>0.7 else 'ÎºÎ±Î»ÏŒ' if r2>0.5 else 'Î±ÏÎºÎµÏ„ÏŒ Î³Î¹Î± Î²ÎµÎ»Ï„Î¯Ï‰ÏƒÎ·'}"
                )
            with col_h2:
                st.metric('ğŸ’° Mean Absolute Error', f'{mae:,.0f} â‚¬')
                concept_explainer(
                    "Mean Absolute Error (MAE)",
                    "Î¤Î¿ MAE ÎµÎ¯Î½Î±Î¹ Î¿ Î¼Î­ÏƒÎ¿Ï‚ Î±Ï€ÏŒÎ»Ï…Ï„Î¿Ï‚ Î»Î¬Î¸Î¿Ï‚ Ï„Ï‰Î½ Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÏ‰Î½ ÏƒÎµ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ­Ï‚ Î¼Î¿Î½Î¬Î´ÎµÏ‚.",
                    """
                    **Î¤Î¹ ÏƒÎ·Î¼Î±Î¯Î½ÎµÎ¹:**
                    - ÎšÎ±Ï„Î¬ Î¼Î­ÏƒÎ¿ ÏŒÏÎ¿, Î¿Î¹ Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚ Î¼Î±Ï‚ Î±Ï€Î­Ï‡Î¿Ï…Î½ MAE â‚¬ Î±Ï€ÏŒ Ï„Î·Î½ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ® Ï„Î¹Î¼Î®
                    - Î Î¹Î¿ ÎµÏÎºÎ¿Î»Î¿ Î½Î± ÎµÏÎ¼Î·Î½ÎµÏ…Ï„ÎµÎ¯ Î±Ï€ÏŒ MSE (Mean Squared Error)
                    - Î”ÎµÎ½ Ï„Î¹Î¼Ï‰ÏÎµÎ¯ Ï„Î± Î¼ÎµÎ³Î¬Î»Î± Î»Î¬Î¸Î· Ï„ÏŒÏƒÎ¿ ÏŒÏƒÎ¿ Ï„Î¿ MSE
                    
                    **Î¦ÏŒÏÎ¼Î¿Ï…Î»Î±:**
                    ```
                    MAE = (1/n) * Î£|y_actual - y_pred|
                    ```
                    
                    **Î ÏŒÏ„Îµ ÎµÎ¯Î½Î±Î¹ ÎºÎ±Î»ÏŒ:**
                    - ÎŒÏƒÎ¿ Î¼Î¹ÎºÏÏŒÏ„ÎµÏÎ¿ Ï„ÏŒÏƒÎ¿ ÎºÎ±Î»ÏÏ„ÎµÏÎ±
                    - Î£Ï…Î³ÎºÏÎ¯Î½ÎµÏ„Î­ Ï„Î¿ Î¼Îµ Ï„Î¿ range Ï„Ï‰Î½ Ï„Î¹Î¼ÏÎ½
                    - Î‘Î½ MAE << std(y), ÎµÎ¯Î½Î±Î¹ Ï€Î¿Î»Ï ÎºÎ±Î»ÏŒ
                    """,
                    f"ÎœÎµ Î¼Î­ÏƒÎ· Ï„Î¹Î¼Î® {y_houses.mean():,.0f}â‚¬ ÎºÎ±Î¹ MAE {mae:,.0f}â‚¬, Ï„Î¿ ÏƒÏ†Î¬Î»Î¼Î± ÎµÎ¯Î½Î±Î¹ {(mae/y_houses.mean()*100):.1f}% Ï„Î·Ï‚ Î¼Î­ÏƒÎ·Ï‚ Ï„Î¹Î¼Î®Ï‚"
                )
            
            fig_pred, ax_pred = plt.subplots(figsize=(10, 6))
            ax_pred.scatter(y_test_h, y_pred_h, alpha=0.6, edgecolors='k')
            ax_pred.plot([y_test_h.min(), y_test_h.max()], 
                        [y_test_h.min(), y_test_h.max()], 
                        'r--', lw=2, label='Perfect Prediction')
            ax_pred.set_xlabel('Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ® Î¤Î¹Î¼Î® (â‚¬)')
            ax_pred.set_ylabel('Î ÏÎ¿Î²Î»ÎµÏ€ÏŒÎ¼ÎµÎ½Î· Î¤Î¹Î¼Î® (â‚¬)')
            ax_pred.set_title('Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ­Ï‚ vs Î ÏÎ¿Î²Î»ÎµÏ€ÏŒÎ¼ÎµÎ½ÎµÏ‚ Î¤Î¹Î¼Î­Ï‚')
            ax_pred.legend()
            ax_pred.grid(True, alpha=0.3)
            st.pyplot(fig_pred)
            plt.close()
            
            st.success('âœ… ÎœÎ¿Î½Ï„Î­Î»Î¿ ÎµÎºÏ€Î±Î¹Î´ÎµÏÏ„Î·ÎºÎµ ÎµÏ€Î¹Ï„Ï…Ï‡ÏÏ‚!')
            
            # Interactive prediction
            st.markdown('### ğŸ¡ Î”Î¿ÎºÎ¹Î¼Î¬ÏƒÏ„Îµ Î¼Î¹Î± Î ÏÏŒÎ²Î»ÎµÏˆÎ·')
            col_p1, col_p2, col_p3 = st.columns(3)
            with col_p1:
                new_size = st.number_input('ÎœÎ­Î³ÎµÎ¸Î¿Ï‚ (Ï„.Î¼.)', 50, 300, 100)
            with col_p2:
                new_rooms = st.number_input('Î”Ï‰Î¼Î¬Ï„Î¹Î±', 1, 5, 3)
            with col_p3:
                new_age = st.number_input('Î—Î»Î¹ÎºÎ¯Î± (Î­Ï„Î·)', 0, 50, 10)
            
            if st.button('ğŸ”® Î ÏÏŒÎ²Î»ÎµÏˆÎ· Î¤Î¹Î¼Î®Ï‚'):
                new_pred = model_h.predict([[new_size, new_rooms, new_age]])[0]
                st.balloons()
                st.success(f'ğŸ  Î•ÎºÏ„Î¹Î¼ÏÎ¼ÎµÎ½Î· Î¤Î¹Î¼Î®: **{new_pred:,.0f} â‚¬**')
    
    elif exercise_choice == 'Î¤Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ· Î•Î¹ÎºÏŒÎ½Ï‰Î½ (Image Classification Simulation)':
        st.markdown('### ğŸ“¸ Simulation: Î¤Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ· Î•Î¹ÎºÏŒÎ½Ï‰Î½')
        
        st.markdown("""
        Î ÏÎ¿ÏƒÎ¿Î¼Î¿Î¯Ï‰ÏƒÎ· ÎµÎ½ÏŒÏ‚ image classifier. Î£Ï„Î·Î½ Ï€ÏÎ¬Î¾Î· Î¸Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÏƒÎ±Î¼Îµ CNN (Convolutional Neural Networks).
        """)
        
        st.info("""
        **Î Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î± Workflow:**
        1. Load dataset (Ï€.Ï‡. MNIST, CIFAR-10)
        2. Preprocess ÎµÎ¹ÎºÏŒÎ½ÎµÏ‚ (normalization, augmentation)
        3. Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± CNN architecture
        4. Training Î¼Îµ backpropagation
        5. Evaluation ÎºÎ±Î¹ fine-tuning
        """)
        
        # Simulate image classification
        categories = ['Î“Î¬Ï„Î±', 'Î£ÎºÏÎ»Î¿Ï‚', 'Î Î¿Ï…Î»Î¯', 'Î¨Î¬ÏÎ¹', 'Î‘Ï…Ï„Î¿ÎºÎ¯Î½Î·Ï„Î¿']
        
        num_images = st.slider('Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ ÎµÎ¹ÎºÏŒÎ½Ï‰Î½ ÏƒÏ„Î¿ dataset', 100, 1000, 500)
        
        # Simulate accuracy over epochs
        epochs = 20
        train_acc = []
        val_acc = []
        
        for epoch in range(epochs):
            train_acc.append(min(0.5 + epoch * 0.025 + np.random.rand() * 0.02, 0.98))
            val_acc.append(min(0.4 + epoch * 0.022 + np.random.rand() * 0.03, 0.92))
        
        fig_training, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))
        
        ax1.plot(range(1, epochs+1), train_acc, label='Training Accuracy', marker='o')
        ax1.plot(range(1, epochs+1), val_acc, label='Validation Accuracy', marker='s')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Accuracy')
        ax1.set_title('Training Progress')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # Confusion matrix simulation
        cm_sim = np.random.randint(0, 50, (len(categories), len(categories)))
        np.fill_diagonal(cm_sim, np.random.randint(80, 120, len(categories)))
        
        sns.heatmap(cm_sim, annot=True, fmt='d', cmap='Blues', 
                   xticklabels=categories, yticklabels=categories, ax=ax2)
        ax2.set_title('Confusion Matrix')
        ax2.set_xlabel('Predicted')
        ax2.set_ylabel('Actual')
        
        st.pyplot(fig_training)
        plt.close()
        
        st.success(f'âœ… Final Validation Accuracy: {val_acc[-1]:.2%}')
    
    elif exercise_choice == 'Sentiment Analysis Simulator':
        st.markdown('### ğŸ’¬ Î‘Î½Î¬Î»Ï…ÏƒÎ· Î£Ï…Î½Î±Î¹ÏƒÎ¸Î®Î¼Î±Ï„Î¿Ï‚ (Sentiment Analysis)')
        
        st.markdown("""
        Î•Î¹ÏƒÎ¬Î³ÎµÏ„Îµ Î­Î½Î± ÎºÎµÎ¯Î¼ÎµÎ½Î¿ ÎºÎ±Î¹ Ï„Î¿ "Î¼Î¿Î½Ï„Î­Î»Î¿" Î¸Î± Ï€ÏÎ¿ÏƒÏ€Î±Î¸Î®ÏƒÎµÎ¹ Î½Î± ÎµÎ½Ï„Î¿Ï€Î¯ÏƒÎµÎ¹ Ï„Î¿ ÏƒÏ…Î½Î±Î¯ÏƒÎ¸Î·Î¼Î±!
        """)
        
        user_text = st.text_area('âœï¸ Î“ÏÎ¬ÏˆÏ„Îµ Î­Î½Î± ÎºÎµÎ¯Î¼ÎµÎ½Î¿:', 
                                 'Î‘Ï…Ï„Î® Î· ÎµÏ†Î±ÏÎ¼Î¿Î³Î® AI ÎµÎ¯Î½Î±Î¹ Ï†Î±Î½Ï„Î±ÏƒÏ„Î¹ÎºÎ®! ÎœÎ±Î¸Î±Î¯Î½Ï‰ Ï€Î¿Î»Î»Î¬!')
        
        if st.button('ğŸ” Î‘Î½Î¬Î»Ï…ÏƒÎ· Î£Ï…Î½Î±Î¹ÏƒÎ¸Î®Î¼Î±Ï„Î¿Ï‚'):
            # Simple rule-based sentiment (simulation)
            positive_words = ['ÎºÎ±Î»ÏŒ', 'Ï†Î±Î½Ï„Î±ÏƒÏ„Î¹ÎºÏŒ', 'ÎµÎ¾Î±Î¹ÏÎµÏ„Î¹ÎºÏŒ', 'Ï…Ï€Î­ÏÎ¿Ï‡Î¿', 'Î¬ÏÎ¹ÏƒÏ„Î¿', 
                            'Ï‡Î±ÏÎ¿ÏÎ¼ÎµÎ½Î¿Ï‚', 'Î¹ÎºÎ±Î½Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î¿Ï‚', 'Î¼Î±Î¸Î±Î¯Î½Ï‰', 'ÎµÏ…Ï‡Î±ÏÎ¹ÏƒÏ„Ï']
            negative_words = ['ÎºÎ±ÎºÏŒ', 'Î¬ÏƒÏ‡Î·Î¼Î¿', 'Î±Ï€Î±Î¯ÏƒÎ¹Î¿', 'Î´ÏÏƒÎºÎ¿Î»Î¿', 'Ï€ÏÏŒÎ²Î»Î·Î¼Î±',
                            'Î»Ï…Ï€Î·Î¼Î­Î½Î¿Ï‚', 'Î±Ï€Î¿Î³Î¿Î·Ï„ÎµÏ…Î¼Î­Î½Î¿Ï‚', 'Î»Î¬Î¸Î¿Ï‚']
            
            text_lower = user_text.lower()
            pos_count = sum(1 for word in positive_words if word in text_lower)
            neg_count = sum(1 for word in negative_words if word in text_lower)
            
            if pos_count > neg_count:
                sentiment = 'ğŸ˜Š Î˜ÎµÏ„Î¹ÎºÏŒ'
                color = 'green'
                score = min((pos_count / (pos_count + neg_count + 1)) * 100, 95)
            elif neg_count > pos_count:
                sentiment = 'ğŸ˜ Î‘ÏÎ½Î·Ï„Î¹ÎºÏŒ'
                color = 'red'
                score = min((neg_count / (pos_count + neg_count + 1)) * 100, 95)
            else:
                sentiment = 'ğŸ˜ ÎŸÏ…Î´Î­Ï„ÎµÏÎ¿'
                color = 'gray'
                score = 50
            
            col_s1, col_s2 = st.columns(2)
            with col_s1:
                st.markdown(f'### Î£Ï…Î½Î±Î¯ÏƒÎ¸Î·Î¼Î±: {sentiment}')
            with col_s2:
                st.metric('Î’Î±Î¸Î¼Î¿Î»Î¿Î³Î¯Î± Î’ÎµÎ²Î±Î¹ÏŒÏ„Î·Ï„Î±Ï‚', f'{score:.0f}%')
            
            st.progress(score / 100)
            
            st.info("""
            **Î£Î·Î¼ÎµÎ¯Ï‰ÏƒÎ·**: Î‘Ï…Ï„ÏŒ ÎµÎ¯Î½Î±Î¹ Î­Î½Î± Î±Ï€Î»Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î¿ Ï€Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î±. Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ¬ sentiment analysis 
            Î¼Î¿Î½Ï„Î­Î»Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ½:
            - Deep Learning (LSTM, Transformers)
            - Pre-trained models (BERT, RoBERTa)
            - Context understanding
            - Multilingual support
            """)
    
    elif exercise_choice == 'Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î£Ï…ÏƒÏ„Î®Î¼Î±Ï„Î¿Ï‚ Î£Ï…ÏƒÏ„Î¬ÏƒÎµÏ‰Î½':
        st.markdown('### ğŸ¬ Î£ÏÏƒÏ„Î·Î¼Î± Î£Ï…ÏƒÏ„Î¬ÏƒÎµÏ‰Î½ (Recommendation System)')
        
        st.markdown("""
        Î ÏÎ¿ÏƒÎ¿Î¼Î¿Î¯Ï‰ÏƒÎ· ÎµÎ½ÏŒÏ‚ recommendation system Î³Î¹Î± Ï„Î±Î¹Î½Î¯ÎµÏ‚.
        """)
        
        # Sample movies
        movies = {
            'Action': ['Mad Max', 'John Wick', 'Die Hard', 'Terminator'],
            'Drama': ['The Godfather', 'Schindler\'s List', 'Forrest Gump'],
            'Comedy': ['The Hangover', 'Superbad', 'Bridesmaids'],
            'Sci-Fi': ['Inception', 'Interstellar', 'The Matrix', 'Blade Runner']
        }
        
        st.markdown('#### Î’Î®Î¼Î± 1: Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Ï„Î±Î¹Î½Î¯ÎµÏ‚ Ï€Î¿Ï… ÏƒÎ±Ï‚ Î±ÏÎ­ÏƒÎ¿Ï…Î½')
        
        liked_movies = []
        for genre, movie_list in movies.items():
            selected = st.multiselect(f'{genre}:', movie_list, key=genre)
            liked_movies.extend([(movie, genre) for movie in selected])
        
        if st.button('ğŸ¯ Î›Î®ÏˆÎ· Î£Ï…ÏƒÏ„Î¬ÏƒÎµÏ‰Î½') and liked_movies:
            st.markdown('#### ğŸ¬ Î ÏÎ¿Ï„ÎµÎ¹Î½ÏŒÎ¼ÎµÎ½ÎµÏ‚ Î¤Î±Î¹Î½Î¯ÎµÏ‚:')
            
            # Count genres
            from collections import Counter
            genres_count = Counter([genre for _, genre in liked_movies])
            top_genre = genres_count.most_common(1)[0][0] if genres_count else 'Action'
            
            # Recommend from top genre
            recommendations = [m for m in movies[top_genre] 
                             if m not in [movie for movie, _ in liked_movies]][:3]
            
            for rec in recommendations:
                st.success(f'âœ¨ {rec} ({top_genre})')
            
            st.info(f'ğŸ’¡ Î’Î±ÏƒÎ¹ÏƒÎ¼Î­Î½Î¿ ÏƒÏ„Î¹Ï‚ Ï€ÏÎ¿Ï„Î¹Î¼Î®ÏƒÎµÎ¹Ï‚ ÏƒÎ±Ï‚ Î³Î¹Î± {top_genre}!')
            
            # Visualize preferences
            fig_pref, ax_pref = plt.subplots(figsize=(8, 5))
            genres = list(genres_count.keys())
            counts = list(genres_count.values())
            ax_pref.bar(genres, counts, color='skyblue', edgecolor='black')
            ax_pref.set_xlabel('Genre')
            ax_pref.set_ylabel('Number of Liked Movies')
            ax_pref.set_title('Your Genre Preferences')
            st.pyplot(fig_pref)
            plt.close()

with tabs[5]:
    # Import Î•ÎœÎ Î›ÎŸÎ¥Î¤Î™Î£ÎœÎ•ÎÎŸ chatbot module Î¼Îµ Î Î›Î—Î¡Î— Î³Î½ÏÏƒÎ·
    try:
        from chatbot_simple import create_chatbot_interface as create_enriched_chatbot_interface
        
        section_title('ğŸŒŸ AI Knowledge Assistant - Î•Î¼Ï€Î»Î¿Ï…Ï„Î¹ÏƒÎ¼Î­Î½Î· ÎˆÎºÎ´Î¿ÏƒÎ·')
        
        st.markdown("""
        ### ÎšÎ±Î»ÏÏ‚ Î®ÏÎ¸Î±Ï„Îµ ÏƒÏ„Î¿Î½ **Î•Î¼Ï€Î»Î¿Ï…Ï„Î¹ÏƒÎ¼Î­Î½Î¿ AI Knowledge Assistant**! ğŸ¤–âœ¨
        
        Î‘Ï…Ï„ÏŒÏ‚ Î¿ Ï€ÏÎ¿Î·Î³Î¼Î­Î½Î¿Ï‚ intelligent chatbot Î­Ï‡ÎµÎ¹:
        - ğŸ“š **Î ÏÏŒÏƒÎ²Î±ÏƒÎ· ÏƒÏ„Î¿ Î Î›Î—Î¡Î•Î£ ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Ï„Î¹ÎºÏŒ Ï…Î»Î¹ÎºÏŒ** (957 ÏƒÎµÎ»Î¯Î´ÎµÏ‚ PDF)
        - ğŸŒ **Internet access** ÏƒÎµ Wikipedia, ArXiv, ÎºÎ±Î¹ curated AI resources
        - ğŸ§  **Î’Î±Î¸Î¹Î¬ ÎºÎ±Ï„Î±Î½ÏŒÎ·ÏƒÎ·** ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ ÎµÎ½Î¿Ï„Î®Ï„Ï‰Î½ (1.1-1.7)
        - ğŸ’¬ **Î”Î¹Î±Î´ÏÎ±ÏƒÏ„Î¹ÎºÎ® ÏƒÏ…Î½Î¿Î¼Î¹Î»Î¯Î±** Î¼Îµ context awareness
        
        ### ğŸ¯ ÎÎ­ÎµÏ‚ Î”Ï…Î½Î±Ï„ÏŒÏ„Î·Ï„ÎµÏ‚:
    
        
        - âœ… **ÎŸÎ»Î¿ÎºÎ»Î·ÏÏ‰Î¼Î­Î½ÎµÏ‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚** Î¼Îµ Ï€Î±ÏÎ±Î´ÎµÎ¯Î³Î¼Î±Ï„Î± ÎºÎ±Î¹ use cases
        - âœ… **Î™ÏƒÏ„Î¿ÏÎ¹ÎºÎ® Ï€ÏÎ¿Î¿Ï€Ï„Î¹ÎºÎ®** Ï„Î·Ï‚ AI
        - âœ… **Î£ÏÎ³ÎºÏÎ¹ÏƒÎ· Ï„ÎµÏ‡Î½Î¿Î»Î¿Î³Î¹ÏÎ½** (CNN vs RNN vs Transformers)
        - âœ… **Î—Î¸Î¹ÎºÎ¬ Î¶Î·Ï„Î®Î¼Î±Ï„Î±** ÎºÎ±Î¹ Ï€ÏÎ¿ÎºÎ»Î®ÏƒÎµÎ¹Ï‚
        - âœ… **Î ÏÎ±ÎºÏ„Î¹ÎºÎ¿Î¯ Ï€ÏŒÏÎ¿Î¹** (documentation, courses, papers)
        
        ### ğŸ“š Î˜Î­Î¼Î±Ï„Î± Ï€Î¿Ï… ÎºÎ±Î»ÏÏ€Ï„ÎµÎ¹:
        
        **Î˜ÎµÏ‰ÏÎ¯Î±:**
        - ÎŸÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÎºÎ±Î¹ Ï„ÏÏ€Î¿Î¹ AI (Narrow, General, Super)
        - Î’Î±ÏƒÎ¹ÎºÎ¬ Î´Î¿Î¼Î¹ÎºÎ¬ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î± (Î”ÎµÎ´Î¿Î¼Î­Î½Î±, Î‘Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Î¹, ÎœÎ¿Î½Ï„Î­Î»Î±, Computing)
        - Machine Learning (Supervised, Unsupervised, Reinforcement)
        - Deep Learning (CNN, RNN, LSTM, Transformers)
        - ChatGPT ÎºÎ±Î¹ Large Language Models
        - Generative AI (GANs, VAEs, Diffusion Models)
        
        **Î ÏÎ¬Î¾Î·:**
        - Î•Ï†Î±ÏÎ¼Î¿Î³Î­Ï‚ ÏƒÎµ Î¥Î³ÎµÎ¯Î±, Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·, Finance, Marketing
        - Python & ML frameworks (TensorFlow, PyTorch)
        - Google Colab notebooks
        - Î ÏÎ±ÎºÏ„Î¹ÎºÎ¬ Ï€Î±ÏÎ±Î´ÎµÎ¯Î³Î¼Î±Ï„Î±
        
        **Î—Î¸Î¹ÎºÎ®:**
        - Bias & Fairness
        - Privacy & Security (GDPR)
        - Transparency & Explainability
        - Job displacement & Future of work
        
        ---
        """)
        
        # Create ENRICHED chatbot interface
        create_enriched_chatbot_interface()
        
        st.markdown("---")
        
        col1, col2 = st.columns(2)
        with col1:
            st.success("""
            âœ… **Î Î»ÎµÎ¿Î½ÎµÎºÏ„Î®Î¼Î±Ï„Î±:**
            - Î ÏÏŒÏƒÎ²Î±ÏƒÎ· ÏƒÎµ 957 ÏƒÎµÎ»Î¯Î´ÎµÏ‚ ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Ï„Î¹ÎºÎ¿Ï Ï…Î»Î¹ÎºÎ¿Ï
            - Online resources Î±Ï€ÏŒ Î±Î¾Î¹ÏŒÏ€Î¹ÏƒÏ„ÎµÏ‚ Ï€Î·Î³Î­Ï‚
            - Î”Î¹Î±Î´ÏÎ±ÏƒÏ„Î¹ÎºÎ® Î¼Î¬Î¸Î·ÏƒÎ·
            - Î†Î¼ÎµÏƒÎµÏ‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚
            """)
        with col2:
            st.info("""
            ğŸ’¡ **Tip**: 
            ÎšÎ¬Î½Ï„Îµ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½ÎµÏ‚ ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚ Î³Î¹Î± ÎºÎ±Î»ÏÏ„ÎµÏÎ± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±!
            
            Î .Ï‡. "Î•Î¾Î®Î³Î·ÏƒÎµ Ï„Î·Î½ Î±ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ® Transformer" 
            Î±Î½Ï„Î¯ Î³Î¹Î± "Î ÎµÏ‚ Î¼Î¿Ï… Î³Î¹Î± AI"
            """)
        
    except (ImportError, Exception) as e:
        # Fallback to old chatbot
        from chatbot import create_chatbot_interface
        
        section_title('AI Knowledge Assistant - Î¡Ï‰Ï„Î®ÏƒÏ„Îµ Î¼Îµ Î¿Ï„Î¹Î´Î®Ï€Î¿Ï„Îµ!')
        
        st.warning(f"âš ï¸ Î¤Î¿ ÎµÎ¼Ï€Î»Î¿Ï…Ï„Î¹ÏƒÎ¼Î­Î½Î¿ chatbot Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î¿. Î§ÏÎ®ÏƒÎ· Î²Î±ÏƒÎ¹ÎºÎ®Ï‚ Î­ÎºÎ´Î¿ÏƒÎ·Ï‚...")
        
        st.markdown("""
        ÎšÎ±Î»ÏÏ‚ Î®ÏÎ¸Î±Ï„Îµ ÏƒÏ„Î¿Î½ **AI Knowledge Assistant**! ğŸ¤–
        
        Î‘Ï…Ï„ÏŒÏ‚ Î¿ intelligent chatbot Î­Ï‡ÎµÎ¹ Ï€ÏÏŒÏƒÎ²Î±ÏƒÎ· ÏƒÏ„Î¿ Ï€Î»Î®ÏÎµÏ‚ ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Ï„Î¹ÎºÏŒ Ï…Î»Î¹ÎºÏŒ ÎºÎ±Î¹ Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹
        ÏƒÎµ ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚ ÏƒÏ‡ÎµÏ„Î¹ÎºÎ¬ Î¼Îµ Ï„Î·Î½ Î¤ÎµÏ‡Î½Î·Ï„Î® ÎÎ¿Î·Î¼Î¿ÏƒÏÎ½Î·.
        
        ### ğŸ’¡ Î¤Î¹ Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± ÎºÎ¬Î½ÎµÎ¹:
    
        - âœ… Î‘Ï€Î±Î½Ï„Î¬ ÏƒÎµ ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚ Î³Î¹Î± AI concepts
        - âœ… Î•Î¾Î·Î³ÎµÎ¯ Ï„ÎµÏ‡Î½Î¹ÎºÎ¿ÏÏ‚ ÏŒÏÎ¿Ï…Ï‚ Î¼Îµ Ï€Î±ÏÎ±Î´ÎµÎ¯Î³Î¼Î±Ï„Î±
        - âœ… Î Î±ÏÎ­Ï‡ÎµÎ¹ ÎµÎ¹Ï‚ Î²Î¬Î¸Î¿Ï‚ Î±Î½Î±Î»ÏÏƒÎµÎ¹Ï‚
        - âœ… Î£Ï…Î½Î´Î­ÎµÎ¹ Î´Î¹Î¬Ï†Î¿ÏÎµÏ‚ Î­Î½Î½Î¿Î¹ÎµÏ‚ Î¼ÎµÏ„Î±Î¾Ï Ï„Î¿Ï…Ï‚
        
        ### ğŸ¯ Î˜Î­Î¼Î±Ï„Î± Ï€Î¿Ï… ÎºÎ±Î»ÏÏ€Ï„ÎµÎ¹:
        
        - Î’Î±ÏƒÎ¹ÎºÎ¬ Î´Î¿Î¼Î¹ÎºÎ¬ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î± Ï„Î·Ï‚ AI
        - Machine Learning (Supervised, Unsupervised, Reinforcement)
        - Deep Learning ÎºÎ±Î¹ Î±ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ­Ï‚
        - ChatGPT ÎºÎ±Î¹ Large Language Models
        - Î ÏÎ±ÎºÏ„Î¹ÎºÎ­Ï‚ ÎµÏ†Î±ÏÎ¼Î¿Î³Î­Ï‚ ÏƒÎµ Î´Î¹Î¬Ï†Î¿ÏÎ¿Ï…Ï‚ Ï„Î¿Î¼ÎµÎ¯Ï‚
        - Î‘Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Î¹ ÎºÎ±Î¹ Ï„ÎµÏ‡Î½Î¹ÎºÎ­Ï‚
        
        ---
        """)
        
        # Create chatbot interface
        create_chatbot_interface()
        
        st.markdown("---")
        st.info("""
        ğŸ’¡ **Tip**: Î¤Î¿ chatbot Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯ Ï„Î¿ ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Ï„Î¹ÎºÏŒ Ï…Î»Î¹ÎºÏŒ Î±Ï€ÏŒ Ï„Î¿ PDF Î³Î¹Î± Î½Î± Ï€Î±ÏÎ­Ï‡ÎµÎ¹ Î±ÎºÏÎ¹Î²ÎµÎ¯Ï‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚.
        Î“Î¹Î± Ï€Î¹Î¿ Ï€ÏÎ¿Î·Î³Î¼Î­Î½ÎµÏ‚ ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚, Î´ÎµÎ¯Ï„Îµ Ï„Î¹Ï‚ ÎµÎ½ÏŒÏ„Î·Ï„ÎµÏ‚ "Î ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿" ÎºÎ±Î¹ "Concept Explainers".
        """)

with tabs[6]:
    section_title('Î ÏŒÏÎ¿Î¹ & ÎŸÎ´Î·Î³Î¯ÎµÏ‚')
    
    st.markdown("""
    ## ğŸ“š Î ÏÏŒÏƒÎ¸ÎµÏ„Î¿Î¹ Î ÏŒÏÎ¿Î¹ Î³Î¹Î± ÎœÎ¬Î¸Î·ÏƒÎ·
    
    ### ğŸŒ Online Courses
    - **Coursera**: Machine Learning by Andrew Ng
    - **Fast.ai**: Practical Deep Learning
    - **DeepLearning.AI**: Deep Learning Specialization
    - **Udacity**: AI Programming with Python
    
    ### ğŸ“– Î’Î¹Î²Î»Î¯Î±
    - "Hands-On Machine Learning" - AurÃ©lien GÃ©ron
    - "Deep Learning" - Ian Goodfellow
    - "Pattern Recognition and Machine Learning" - Christopher Bishop
    - "AI: A Modern Approach" - Russell & Norvig
    
    ### ğŸ’» Frameworks & Tools
    - **TensorFlow**: Deep learning framework by Google
    - **PyTorch**: Deep learning framework by Meta
    - **Scikit-learn**: Machine learning library
    - **Keras**: High-level neural networks API
    - **Hugging Face**: Pre-trained models
    
    ### ğŸ“ Î Î±Î½ÎµÏ€Î¹ÏƒÏ„Î·Î¼Î¹Î±ÎºÎ¬ ÎœÎ±Î¸Î®Î¼Î±Ï„Î± (Free)
    - MIT OpenCourseWare: Introduction to AI
    - Stanford CS229: Machine Learning
    - Berkeley CS188: Introduction to AI
    
    ### ğŸ¤ Communities
    - **Kaggle**: Competitions & Datasets
    - **GitHub**: Open source projects
    - **Stack Overflow**: Q&A
    - **Reddit**: r/MachineLearning, r/artificial
    
    ### ğŸ“Š Datasets
    - **UCI Machine Learning Repository**
    - **Kaggle Datasets**
    - **Google Dataset Search**
    - **ImageNet**
    - **COCO Dataset**
    
    ---
    
    ## ğŸš€ ÎŸÎ´Î·Î³Î¯ÎµÏ‚ Î§ÏÎ®ÏƒÎ·Ï‚ Î•Ï†Î±ÏÎ¼Î¿Î³Î®Ï‚
    
    1. **Î ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿**: Î”Î¹Î±Î²Î¬ÏƒÏ„Îµ Ï„Î· Î¸ÎµÏ‰ÏÎ¯Î± Î³Î¹Î± Ï„Î¹Ï‚ ÎµÎ½ÏŒÏ„Î·Ï„ÎµÏ‚ 1.1-1.7
    2. **Î Î±ÏÎ±Î´ÎµÎ¯Î³Î¼Î±Ï„Î± Python**: Î ÎµÎ¹ÏÎ±Î¼Î±Ï„Î¹ÏƒÏ„ÎµÎ¯Ï„Îµ Î¼Îµ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ¬ Ï€Î±ÏÎ±Î´ÎµÎ¯Î³Î¼Î±Ï„Î± ML
    3. **Î•Î¾Î¿Î¼Î¿Î¹ÏÏƒÎµÎ¹Ï‚**: Î”ÎµÎ¯Ï„Îµ Ï€ÏÏ‚ Î¿Î¹ Ï€Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹ ÎµÏ€Î·ÏÎµÎ¬Î¶Î¿Ï…Î½ Ï„Î± Î¼Î¿Î½Ï„Î­Î»Î±
    4. **ÎšÎ¿Ï…Î¯Î¶**: Î•Î»Î­Î³Î¾Ï„Îµ Ï„Î¹Ï‚ Î³Î½ÏÏƒÎµÎ¹Ï‚ ÏƒÎ±Ï‚
    5. **Î”Î¹Î±Î´ÏÎ±ÏƒÏ„Î¹ÎºÎ­Ï‚ Î‘ÏƒÎºÎ®ÏƒÎµÎ¹Ï‚**: Î•Ï†Î±ÏÎ¼ÏŒÏƒÏ„Îµ Ï„Î¹Ï‚ Î³Î½ÏÏƒÎµÎ¹Ï‚ ÏƒÎ±Ï‚ ÏƒÎµ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ¬ Ï€ÏÎ¿Î²Î»Î®Î¼Î±Ï„Î±
    
    ---
    
    ## ğŸ“ Î“Î¹Î± Offline Î§ÏÎ®ÏƒÎ·
    
    Î‘Ï…Ï„Î® Î· ÎµÏ†Î±ÏÎ¼Î¿Î³Î® Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Ï„ÏÎ­Î¾ÎµÎ¹ ÎµÎ½Ï„ÎµÎ»ÏÏ‚ offline. Î“Î¹Î± Î½Î± Ï„Î·Î½ ÎµÎ³ÎºÎ±Ï„Î±ÏƒÏ„Î®ÏƒÎµÏ„Îµ:
    
    ```bash
    # Î•Î³ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ· dependencies
    pip install streamlit scikit-learn matplotlib numpy pandas seaborn
    
    # Î•ÎºÏ„Î­Î»ÎµÏƒÎ· ÎµÏ†Î±ÏÎ¼Î¿Î³Î®Ï‚
    streamlit run ai_training_app.py
    ```
    
    ---
    
    ## ğŸ¯ Î•Ï€ÏŒÎ¼ÎµÎ½Î± Î’Î®Î¼Î±Ï„Î±
    
    1. ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÏƒÏ„Îµ ÏŒÎ»Î± Ï„Î± ÎºÎ¿Ï…Î¯Î¶
    2. Î”Î¿ÎºÎ¹Î¼Î¬ÏƒÏ„Îµ ÏŒÎ»ÎµÏ‚ Ï„Î¹Ï‚ ÎµÎ¾Î¿Î¼Î¿Î¹ÏÏƒÎµÎ¹Ï‚
    3. ÎšÎ¬Î½Ï„Îµ Ï„Î¹Ï‚ Î´Î¹Î±Î´ÏÎ±ÏƒÏ„Î¹ÎºÎ­Ï‚ Î±ÏƒÎºÎ®ÏƒÎµÎ¹Ï‚
    4. Î•Î¾ÎµÏÎµÏ…Î½Î®ÏƒÏ„Îµ Ï„Î¿Ï…Ï‚ Ï€ÏÎ¿Ï„ÎµÎ¹Î½ÏŒÎ¼ÎµÎ½Î¿Ï…Ï‚ Ï€ÏŒÏÎ¿Ï…Ï‚
    5. ÎÎµÎºÎ¹Î½Î®ÏƒÏ„Îµ Ï„Î¿ Î´Î¹ÎºÏŒ ÏƒÎ±Ï‚ AI project!
    
    ---
    
    ## ğŸ“§ Î•Ï€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¯Î± & Î¥Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î·
    
    Î“Î¹Î± ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚ ÎºÎ±Î¹ Ï…Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î·, Î±Î½Î±Ï„ÏÎ­Î¾Ï„Îµ ÏƒÏ„Î¿ ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Ï„Î¹ÎºÏŒ Ï…Î»Î¹ÎºÏŒ ÎºÎ±Î¹ Ï„Î¿Ï…Ï‚ Ï€ÏŒÏÎ¿Ï…Ï‚ Ï€Î¿Ï… Ï€Î±ÏÎ­Ï‡Î¿Î½Ï„Î±Î¹.
    
    **ÎšÎ±Î»Î® ÎµÏ€Î¹Ï„Ï…Ï‡Î¯Î± ÏƒÏ„Î·Î½ ÎµÎºÎ¼Î¬Î¸Î·ÏƒÎ· AI!** ğŸš€ğŸ¤–
    """)
    
    # Footer
    st.markdown('---')
    st.markdown("""
    <div style='text-align: center; color: gray; padding: 20px;'>
        <p>ğŸ¤– AI Training Application v2.0</p>
        <p>Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î®Î¸Î·ÎºÎµ Î¼Îµ â¤ï¸ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏÎ½Ï„Î±Ï‚ Streamlit</p>
        <p>Î’Î±ÏƒÎ¹ÏƒÎ¼Î­Î½Î¿ ÏƒÏ„Î¿ ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Ï„Î¹ÎºÏŒ Ï…Î»Î¹ÎºÏŒ: "Î•Ï†Î±ÏÎ¼Î¿Î³Î­Ï‚ Î¤ÎµÏ‡Î½Î·Ï„Î®Ï‚ ÎÎ¿Î·Î¼Î¿ÏƒÏÎ½Î·Ï‚ ÎºÎ±Î¹ ChatGPT ÏƒÎµ ÎšÏÎ¯ÏƒÎ¹Î¼Î¿Ï…Ï‚ Î¤Î¿Î¼ÎµÎ¯Ï‚"</p>
    </div>
    """, unsafe_allow_html=True)
